{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emanueltay/Optimal_Subtitle_Placement/blob/main/caption_placement_preposition_testing_18_mar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/optimal_subtitle_copied.zip -d /content/\n",
        "\n",
        "# !unzip /content/test_long_video.zip -d /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tqdsIMOQ4XH",
        "outputId": "a868f8b3-329b-4c41-bdd3-316f2d635854"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/optimal_subtitle_copied.zip\n",
            "   creating: /content/optimal_subtitle_copied/\n",
            "   creating: /content/optimal_subtitle_copied/TTML_file/\n",
            "  inflating: /content/optimal_subtitle_copied/TTML_file/test_video_3_eng.ttml  \n",
            "  inflating: /content/optimal_subtitle_copied/subtitle_positions_ttml.json  \n",
            "   creating: /content/optimal_subtitle_copied/Font/\n",
            "  inflating: /content/optimal_subtitle_copied/Font/GoNotoKurrent-Regular.ttf  \n",
            "  inflating: /content/optimal_subtitle_copied/Font/OpenSans-Italic-VariableFont_wdth,wght.ttf  \n",
            "  inflating: /content/optimal_subtitle_copied/Font/OpenSans-VariableFont_wdth,wght.ttf  \n",
            "  inflating: /content/optimal_subtitle_copied/Font/DejaVuSans-Bold.ttf  \n",
            "  inflating: /content/optimal_subtitle_copied/Font/NotoNaskhArabic-Regular.ttf  \n",
            "  inflating: /content/optimal_subtitle_copied/Font/NotoSansDevanagari-Regular.ttf  \n",
            "  inflating: /content/optimal_subtitle_copied/Font/NotoSansCJK-Regular.ttc  \n",
            "  inflating: /content/optimal_subtitle_copied/Font/NotoSansThai-Regular.ttf  \n",
            "  inflating: /content/optimal_subtitle_copied/Font/NotoSans-Regular.ttf  \n",
            "  inflating: /content/optimal_subtitle_copied/test_video_1.mp4  \n",
            "  inflating: /content/optimal_subtitle_copied/caption_placement_preposition.ipynb  \n",
            "   creating: /content/optimal_subtitle_copied/SRT_file/\n",
            "  inflating: /content/optimal_subtitle_copied/SRT_file/test_video_4_chinese.srt  \n",
            "  inflating: /content/optimal_subtitle_copied/SRT_file/test_video_3_eng.srt  \n",
            "  inflating: /content/optimal_subtitle_copied/SRT_file/test_video_4_hebrew.srt  \n",
            "  inflating: /content/optimal_subtitle_copied/SRT_file/test_video_4_thai.srt  \n",
            "  inflating: /content/optimal_subtitle_copied/SRT_file/test_video_4_eng.srt  \n",
            "  inflating: /content/optimal_subtitle_copied/SRT_file/test_long_video_17_eng.srt  \n",
            "  inflating: /content/optimal_subtitle_copied/SRT_file/test_video_4_japan.srt  \n",
            "  inflating: /content/optimal_subtitle_copied/SRT_file/test_video_4_korea.srt  \n",
            "  inflating: /content/optimal_subtitle_copied/SRT_file/test_video_4_arabic.srt  \n",
            "  inflating: /content/optimal_subtitle_copied/news_video_subtitle_positions.json  \n",
            "  inflating: /content/optimal_subtitle_copied/best.pt  \n",
            "  inflating: /content/optimal_subtitle_copied/test_video_3.mp4  \n",
            "  inflating: /content/optimal_subtitle_copied/test_video_5.mp4  \n",
            "  inflating: /content/optimal_subtitle_copied/test_video_4.mp4  \n",
            "  inflating: /content/optimal_subtitle_copied/test_video_2.mp4  \n",
            "  inflating: /content/optimal_subtitle_copied/subtitle_positions_updated.json  \n",
            "  inflating: /content/optimal_subtitle_copied/subtitle_pre_positions(updated).json  \n",
            "  inflating: /content/optimal_subtitle_copied/best_100.pt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LG33s7ssRHhK",
        "outputId": "cd351f31-7750-467a-9230-73804b73524a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.93-py3-none-any.whl.metadata (35 kB)\n",
            "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.14.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.93-py3-none-any.whl (949 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m949.3/949.3 kB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m115.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m84.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.93 ultralytics-thop-2.0.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJUwKTrUQgiY"
      },
      "source": [
        "### Detect Key Objects in the Frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "C5j6zUvEQgib",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "638fd6cf-a99b-4695-db70-e40a754c3821"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ],
      "source": [
        "# ! pip install ultralytics\n",
        "\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import torch\n",
        "\n",
        "# Load the trained model\n",
        "model = YOLO(\"/content/optimal_subtitle_copied/best_100.pt\")\n",
        "# model = YOLO(\"/content/optimal_subtitle_copied/best.pt\")\n",
        "\n",
        "# # ✅ Automatically select GPU if available\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# # ✅ Move model to the selected device\n",
        "model.to(device).float()  # Use FP32 (FP16 can cause issues on CPU)\n",
        "\n",
        "# ✅ Optimize PyTorch settings\n",
        "torch.backends.cudnn.benchmark = True  # Optimize for fixed-size inputs\n",
        "torch.backends.cudnn.enabled = True\n",
        "torch.set_num_threads(torch.get_num_threads())  # Use optimal number of CPU threads\n",
        "\n",
        "\n",
        "def detect_objects(frames):\n",
        "    \"\"\"\n",
        "    Perform batch object detection on multiple frames.\n",
        "\n",
        "    Parameters:\n",
        "        frames (list): List of frames (each a NumPy array).\n",
        "\n",
        "    Returns:\n",
        "        list: A list containing detections for each frame.\n",
        "              Each element is a NumPy array of detections.\n",
        "    \"\"\"\n",
        "    # ✅ Run the model in batch mode\n",
        "    results = model(frames, batch=len(frames), imgsz=640, verbose=True)  # Run batch inference\n",
        "\n",
        "    # ✅ Extract detections for each frame\n",
        "    batch_detections = []\n",
        "    for result in results:\n",
        "        detections = result.boxes.data.cpu().numpy()  # Convert detections to NumPy array\n",
        "        batch_detections.append(detections)\n",
        "\n",
        "    return batch_detections  # List of detections per frame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eEdf6AYQgie"
      },
      "source": [
        "### Define Safe Zones for Subtitle Placement"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# ✅ Global in-memory cache for dynamic & shifted safe zones\n",
        "safe_zone_cache = {}\n",
        "used_safe_zones = {}  # Dictionary to store all assigned safe zones\n",
        "\n",
        "def calculate_safe_zone_with_prepositions_test_new(frame_width, frame_height, detections, pre_positions, subtitle_height=30, margin=10, shift_x=20):\n",
        "    \"\"\"\n",
        "    Calculate the safe zone for subtitle placement using pre-defined positions.\n",
        "    If blocked, it attempts to shift left/right before moving vertically.\n",
        "    If no predefined position works, falls back to a dynamic safe zone and caches it in memory.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (position_name, coordinates)\n",
        "    \"\"\"\n",
        "\n",
        "    def zones_overlap(zone1, zone2):\n",
        "        \"\"\"Checks if two zones overlap.\"\"\"\n",
        "        x1a, y1a, x2a, y2a = zone1\n",
        "        x1b, y1b, x2b, y2b = zone2\n",
        "        return not (x2a < x1b or x1a > x2b or y2a < y1b or y1a > y2b)\n",
        "\n",
        "    # ✅ Step 1: Check if we already computed a safe zone for this frame in memory\n",
        "    cache_key = (frame_width, frame_height, tuple(tuple(d) for d in detections))  # Unique key per resolution + detections\n",
        "    if cache_key in safe_zone_cache:\n",
        "        return safe_zone_cache[cache_key]  # Return cached value\n",
        "\n",
        "    # ✅ Step 2: Try Predefined Positions\n",
        "    for position_name, position in sorted(pre_positions.items(), key=lambda x: x[1].get(\"priority\", 0), reverse=True):\n",
        "        x1, y1, x2, y2 = position[\"coordinates\"]\n",
        "\n",
        "        # Check if the original pre-position is available\n",
        "        if not any(zones_overlap((x1, y1, x2, y2), detection[:4]) for detection in detections):\n",
        "            safe_zone_cache[cache_key] = (position_name, (x1, y1, x2, y2))  # ✅ Store in cache\n",
        "\n",
        "            # ✅ Store in used safe zones for JSON output\n",
        "            used_safe_zones[position_name] = {\n",
        "                \"coordinates\": [x1, y1, x2, y2]\n",
        "            }\n",
        "            return (position_name, (x1, y1, x2, y2))\n",
        "\n",
        "        min_width = max(0.6 * frame_width, 600)  # 60% of frame width, but at least 600px\n",
        "\n",
        "        # ✅ Try shifting left and right before moving to fallback\n",
        "        for shift_dir in [\"left\", \"right\"]:\n",
        "            shift_attempts = 0\n",
        "            while shift_attempts < 10:  # Try shifting multiple times\n",
        "                if shift_dir == \"left\":\n",
        "                    new_x1, new_x2 = max(0, x1 - shift_x), max(min_width, x2 - shift_x)\n",
        "                else:\n",
        "                    new_x1, new_x2 = min(frame_width - min_width, x1 + shift_x), min(frame_width, x2 + shift_x)\n",
        "\n",
        "                shifted_zone = (new_x1, y1, new_x2, y2)\n",
        "\n",
        "                if new_x2 > new_x1 and not any(zones_overlap(shifted_zone, detection[:4]) for detection in detections):\n",
        "                    safe_zone_cache[cache_key] = (f\"shifted_{position_name}\", shifted_zone)  # ✅ Store shifted result in cache\n",
        "\n",
        "                    # ✅ Store in used safe zones with \"shifted_\" prefix\n",
        "                    used_safe_zones[f\"shifted_{position_name}\"] = {\n",
        "                        \"coordinates\": [new_x1, y1, new_x2, y2]\n",
        "                    }\n",
        "                    return (f\"shifted_{position_name}\", shifted_zone)  # Return valid shifted zone\n",
        "\n",
        "                shift_attempts += 1\n",
        "                shift_x *= 1.5  # Increase shift size if first shift attempt fails\n",
        "\n",
        "    # ✅ Step 3: No Predefined Positions Worked, Try Dynamic Safe Zone\n",
        "    fallback_position_name = \"fallback_bottom\"\n",
        "    proposed_safe_zone = (0, frame_height - subtitle_height - margin, frame_width, frame_height - margin)\n",
        "\n",
        "    while True:\n",
        "        if all(not zones_overlap(proposed_safe_zone, (int(d[0]), int(d[1]), int(d[2]), int(d[3]))) for d in detections):\n",
        "            safe_zone_cache[cache_key] = (fallback_position_name, proposed_safe_zone)  # ✅ Store in cache\n",
        "\n",
        "            # ✅ Store dynamic position as \"fallback_bottom\"\n",
        "            used_safe_zones[fallback_position_name] = {\n",
        "                \"coordinates\": list(proposed_safe_zone)\n",
        "            }\n",
        "            return (fallback_position_name, proposed_safe_zone)\n",
        "\n",
        "        # Try shifting up\n",
        "        x1, y1, x2, y2 = proposed_safe_zone\n",
        "        new_y1 = y1 - subtitle_height - margin\n",
        "        new_y2 = y2 - subtitle_height - margin\n",
        "\n",
        "        if new_y1 < 0:\n",
        "            break  # No valid space above, fallback required\n",
        "\n",
        "        proposed_safe_zone = (x1, new_y1, x2, new_y2)\n",
        "\n",
        "    # ✅ Step 4: Final Fallback to Top and Cache It\n",
        "    fallback_position_name = \"fallback_top\"\n",
        "    final_safe_zone = (0, margin, frame_width, subtitle_height + margin)\n",
        "    safe_zone_cache[cache_key] = (fallback_position_name, final_safe_zone)  # ✅ Store fallback result in cache\n",
        "\n",
        "    # ✅ Store fallback position as \"fallback_top\"\n",
        "    used_safe_zones[fallback_position_name] = {\n",
        "        \"coordinates\": list(final_safe_zone)\n",
        "    }\n",
        "\n",
        "    return (fallback_position_name, final_safe_zone)\n",
        "\n",
        "def get_used_safe_zones():\n",
        "    \"\"\"\n",
        "    Returns the used safe zones as a dictionary without the \"priority\" field.\n",
        "    This can be directly used for updating the TTML layout.\n",
        "    \"\"\"\n",
        "    return {\n",
        "        key: {\"coordinates\": value[\"coordinates\"]}\n",
        "        for key, value in used_safe_zones.items()\n",
        "    }"
      ],
      "metadata": {
        "id": "RaWDhrEmYXq5"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import textwrap\n",
        "\n",
        "def calculate_safe_zone_with_prepositions_test(frame_width, frame_height, detections, pre_positions, subtitle_height=30, margin=10, shift_x=20):\n",
        "    \"\"\"\n",
        "    Calculate the safe zone for subtitle placement using pre-defined positions.\n",
        "    If blocked, it attempts to shift left/right before moving vertically.\n",
        "\n",
        "    Returns:\n",
        "        tuple: Coordinates of the safe zone (x1, y1, x2, y2).\n",
        "    \"\"\"\n",
        "\n",
        "    def zones_overlap(zone1, zone2):\n",
        "        \"\"\"Checks if two zones overlap.\"\"\"\n",
        "        x1a, y1a, x2a, y2a = zone1\n",
        "        x1b, y1b, x2b, y2b = zone2\n",
        "        return not (x2a < x1b or x1a > x2b or y2a < y1b or y1a > y2b)\n",
        "\n",
        "    # Step 1: Try Predefined Positions\n",
        "    for position_name, position in sorted(pre_positions.items(), key=lambda x: x[1].get(\"priority\", 0), reverse=True):\n",
        "        x1, y1, x2, y2 = position[\"coordinates\"]\n",
        "        # print(position[\"coordinates\"])\n",
        "        # print(f\"Checking {position_name}...\")\n",
        "\n",
        "        # Check if the original pre-position is available\n",
        "        if not any(zones_overlap((x1, y1, x2, y2), detection[:4]) for detection in detections):\n",
        "            # print(f\"✅ Using original {position_name}\")\n",
        "            return (x1, y1, x2, y2)  # Return if it's available\n",
        "\n",
        "        min_width = max(0.6 * frame_width, 600)  # 60% of frame width, but at least 600px\n",
        "        for shift_dir in [\"left\", \"right\"]:\n",
        "            shift_attempts = 0\n",
        "            while shift_attempts < 10:  # Try shifting multiple times\n",
        "                if shift_dir == \"left\":\n",
        "                    new_x1, new_x2 = max(x1*10, x1 - shift_x), max(min_width, x2 - shift_x)\n",
        "                else:\n",
        "                    new_x1, new_x2 = min(frame_width - min_width, x1 + shift_x), min(frame_width, x2 + shift_x)\n",
        "\n",
        "                shifted_zone = (new_x1, y1, new_x2, y2)\n",
        "\n",
        "                if new_x2 > new_x1 and not any(zones_overlap(shifted_zone, detection[:4]) for detection in detections):\n",
        "                    print(f\"✅ Shifted {position_name} {shift_dir} and found a free spot.\")\n",
        "                    return shifted_zone  # Found a valid shifted zone\n",
        "\n",
        "                shift_attempts += 1\n",
        "                shift_x *= 1.5  # Increase shift size if first shift attempt fails\n",
        "\n",
        "    # Step 2: Fallback to Dynamic Safe Zone Calculation (Starting from Bottom)\n",
        "    # print(\"⚠ No predefined positions worked. Trying dynamic safe zone...\")\n",
        "    proposed_safe_zone = (0, frame_height - subtitle_height - margin, frame_width, frame_height - margin)\n",
        "\n",
        "    while True:\n",
        "        if all(not zones_overlap(proposed_safe_zone, (int(d[0]), int(d[1]), int(d[2]), int(d[3]))) for d in detections):\n",
        "            # print(\"✅ Dynamic safe zone found.\")\n",
        "            return proposed_safe_zone  # Found a safe area\n",
        "\n",
        "        # Try shifting up\n",
        "        x1, y1, x2, y2 = proposed_safe_zone\n",
        "        new_y1 = y1 - subtitle_height - margin\n",
        "        new_y2 = y2 - subtitle_height - margin\n",
        "\n",
        "        if new_y1 < 0:\n",
        "            break  # No valid space above, fallback required\n",
        "\n",
        "        proposed_safe_zone = (x1, new_y1, x2, new_y2)\n",
        "\n",
        "    # Step 3: Final fallback to the top of the frame\n",
        "    # print(\"⚠ No valid spaces found, defaulting to top position.\")\n",
        "    return (0, margin, frame_width, subtitle_height + margin)"
      ],
      "metadata": {
        "id": "5ptqdgCSshaJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42kgNBk0Qgif"
      },
      "source": [
        "### Subtitle size and margin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8mVacuTdQgif"
      },
      "outputs": [],
      "source": [
        "def get_subtitle_size(frame_height):\n",
        "    \"\"\"\n",
        "    Dynamically calculate subtitle height and margin based on frame resolution.\n",
        "\n",
        "    Parameters:\n",
        "        frame_height (int): Height of the video frame.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (subtitle_height, margin)\n",
        "    \"\"\"\n",
        "    subtitle_height = max(0.05 * frame_height, 18)  # Minimum 18px for readability\n",
        "    margin = max(0.02 * frame_height, 5)  # Minimum 5px to avoid text touching edges\n",
        "\n",
        "    return int(subtitle_height), int(margin)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EvQkMeKQgig"
      },
      "source": [
        "### Subtitle character calculation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install arabic-reshaper"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yc53x_yQR8hq",
        "outputId": "e8bcdac4-e16a-41aa-e013-1a957c2bcad4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting arabic-reshaper\n",
            "  Downloading arabic_reshaper-3.0.0-py3-none-any.whl.metadata (12 kB)\n",
            "Downloading arabic_reshaper-3.0.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: arabic-reshaper\n",
            "Successfully installed arabic-reshaper-3.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-bidi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_ndbnMMTJqr",
        "outputId": "ac0c5aca-f35f-4329-c08d-678ff3b8530c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-bidi\n",
            "  Downloading python_bidi-0.6.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Downloading python_bidi-0.6.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (292 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.9/292.9 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-bidi\n",
            "Successfully installed python-bidi-0.6.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ML2qsOboQgig"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import re\n",
        "import textwrap\n",
        "import numpy as np\n",
        "import arabic_reshaper\n",
        "from bidi.algorithm import get_display\n",
        "from PIL import ImageFont, ImageDraw, Image\n",
        "\n",
        "## universal font that fits all languages\n",
        "def get_font(font_size):\n",
        "    \"\"\"\n",
        "    Loads the universal OpenSans font.\n",
        "\n",
        "    Parameters:\n",
        "        font_size (int): The desired font size.\n",
        "\n",
        "    Returns:\n",
        "        PIL.ImageFont: The loaded font.\n",
        "    \"\"\"\n",
        "    font_path = \"/content/optimal_subtitle_copied/Font/GoNotoKurrent-Regular.ttf\"\n",
        "    return ImageFont.truetype(font_path, font_size)\n",
        "\n",
        "# **2️⃣ Function to Detect Language Type**\n",
        "def detect_language(text):\n",
        "    \"\"\"\n",
        "    Detects if the text contains Latin, CJK, Arabic, or Indic characters.\n",
        "\n",
        "    Returns:\n",
        "        str: \"latin\", \"cjk\", \"arabic\", \"indic\", \"thai\" based on detected script.\n",
        "    \"\"\"\n",
        "\n",
        "    # Extract the first two words\n",
        "    words = re.findall(r'\\b\\w+\\b', text)  # Split text into words\n",
        "    text_snippet = \" \".join(words[:2])  # Take only the first two words\n",
        "\n",
        "    if any(\"\\u0600\" <= ch <= \"\\u06FF\" for ch in text_snippet):  # Arabic script range\n",
        "        return \"arabic\"\n",
        "    elif any(\"\\u4E00\" <= ch <= \"\\u9FFF\" for ch in text_snippet):  # Chinese script range\n",
        "        return \"cjk\"\n",
        "    elif any(\"\\u3040\" <= ch <= \"\\u30FF\" for ch in text_snippet):  # Japanese script range\n",
        "        return \"cjk\"\n",
        "    elif any(\"\\uAC00\" <= ch <= \"\\uD7AF\" for ch in text_snippet):  # Korean script range\n",
        "        return \"cjk\"\n",
        "    elif any(\"\\u0900\" <= ch <= \"\\u097F\" for ch in text_snippet):  # Devanagari script (Hindi, Marathi, Sanskrit)\n",
        "        return \"indic\"\n",
        "    elif any(\"\\u0E00\" <= ch <= \"\\u0E7F\" for ch in text_snippet):  # Thai script\n",
        "        return \"thai\"\n",
        "    return \"latin\"  # Default to Latin if nothing is detected\n",
        "\n",
        "# **3️⃣ Main Subtitle Rendering Function**\n",
        "def render_subtitle_multi_new(frame, subtitle_text, safe_zone, frame_width, frame_height, max_chars_per_line=40, opacity=0.8):\n",
        "    \"\"\"\n",
        "    Render multi-line subtitles centered within the safe zone with a semi-transparent background.\n",
        "\n",
        "    Parameters:\n",
        "        frame (numpy array): The frame on which to render subtitles.\n",
        "        subtitle_text (str): The text to display.\n",
        "        safe_zone (tuple): (x1, y1, x2, y2) defining subtitle placement.\n",
        "        frame_width (int): Width of the frame.\n",
        "        frame_height (int): Height of the frame.\n",
        "        opacity (float): Background opacity (0 = fully transparent, 1 = fully opaque).\n",
        "\n",
        "    Returns:\n",
        "        numpy array: The frame with subtitles rendered at an optimal position.\n",
        "    \"\"\"\n",
        "    x1, y1, x2, y2 = safe_zone\n",
        "    language = detect_language(subtitle_text)  # **Detect language**\n",
        "    font_size = 28 if language == \"cjk\" else 26  # Adjust font size for CJK characters\n",
        "    font = get_font(font_size)\n",
        "\n",
        "    # **Handle Right-to-Left (RTL) text (e.g., Arabic)**\n",
        "    if language == \"arabic\":\n",
        "        subtitle_text = get_display(arabic_reshaper.reshape(subtitle_text))\n",
        "\n",
        "    # **Calculate max width available for text**\n",
        "    max_text_width = x2 - x1 - 30  # Ensure padding (30)\n",
        "    # print(\"Max width in pixels:\", max_text_width)\n",
        "\n",
        "    # **Estimate Average Character Width Dynamically Using Subtitle Text**\n",
        "    if len(subtitle_text) > 0:\n",
        "        char_width = sum(font.getbbox(char)[2] - font.getbbox(char)[0] for char in subtitle_text) / len(subtitle_text)\n",
        "    else:\n",
        "        char_width = font_size // 2  # Fallback for empty text\n",
        "\n",
        "    # **Determine Maximum Characters That Fit in Safe Zone**\n",
        "    estimated_max_chars = max_text_width // char_width\n",
        "\n",
        "    # **Use the Minimum of User-Defined or Estimated Max Chars**\n",
        "    final_max_chars_per_line = min(estimated_max_chars, max_chars_per_line)\n",
        "\n",
        "    # **Dynamically wrap text based on max character limit**\n",
        "    wrapped_lines = []\n",
        "    for line in subtitle_text.split(\"\\n\"):  # Handle existing line breaks\n",
        "        new_lines = textwrap.wrap(line, width=int(final_max_chars_per_line))\n",
        "        if new_lines:  # Only extend if wrapping produced text\n",
        "            wrapped_lines.extend(new_lines)\n",
        "\n",
        "    # **Fallback to prevent empty wrapped_lines**\n",
        "    if not wrapped_lines:\n",
        "        wrapped_lines = [\" \"]  # Ensures at least one blank line\n",
        "\n",
        "    # **Measure Text Size**\n",
        "    text_sizes = [font.getbbox(line) for line in wrapped_lines]\n",
        "    text_width = max(size[2] - size[0] for size in text_sizes)  # Width (right - left)\n",
        "    text_height = text_sizes[0][3] - text_sizes[0][1]  # Height (bottom - top)\n",
        "    total_text_height = sum(size[3] - size[1] for size in text_sizes) + (len(wrapped_lines) - 1) * 10  # Extra spacing\n",
        "\n",
        "    # **Center Text Within Safe Zone**\n",
        "    text_x = x1 + (x2 - x1 - text_width) // 2  # **Horizontally centered**\n",
        "    text_y = y1 + (y2 - y1 - total_text_height) // 2 - 20# **Vertically centered**\n",
        "\n",
        "    # **Define Background Box**\n",
        "    bg_x1 = max(text_x - 15, 0)\n",
        "    bg_y1 = max(text_y - 5, 0)\n",
        "    bg_x2 = min(text_x + text_width + 15, frame_width - 1)\n",
        "    bg_y2 = min(text_y + total_text_height + 15, frame_height - 1)\n",
        "\n",
        "    # **Create Semi-Transparent Background**\n",
        "    overlay = frame.copy()\n",
        "    cv2.rectangle(overlay, (bg_x1, bg_y1), (bg_x2, bg_y2), (0, 0, 0), -1)  # Black background\n",
        "    cv2.addWeighted(overlay, opacity, frame, 1 - opacity, 0, frame)  # Blend overlay with frame\n",
        "\n",
        "    # **Render Text Using PIL (for better font handling)**\n",
        "    frame_pil = Image.fromarray(frame)\n",
        "    draw = ImageDraw.Draw(frame_pil)\n",
        "\n",
        "    y_offset = text_y\n",
        "    for line in wrapped_lines:\n",
        "        line_width = font.getbbox(line)[2] - font.getbbox(line)[0]  # Measure width\n",
        "        line_x = x1 + (x2 - x1 - line_width) // 2  # Center per line\n",
        "        draw.text((line_x, y_offset), line, font=font, fill=(255, 255, 255))  # White text\n",
        "        y_offset += text_height + 10  # Extra line spacing\n",
        "\n",
        "    return np.array(frame_pil)  # Convert back to OpenCV format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7LgkgGkQgij"
      },
      "source": [
        "### Complete Pipeline for frames batch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from collections import Counter, deque\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "safe_zone_history = deque(maxlen=10)  # Stores past safe zones for consistency (4)\n",
        "\n",
        "def process_frames_batch_3fps_processed(frames, subtitles, process_fps=3, video_fps=30):\n",
        "    \"\"\"\n",
        "    Process a batch of frames at 3 FPS:\n",
        "    - Detects objects in frames sampled at 3 FPS\n",
        "    - Computes one safe zone for the batch\n",
        "    - Overlays subtitles using the same safe zone\n",
        "\n",
        "    Parameters:\n",
        "        frames (list): List of frames (NumPy arrays).\n",
        "        subtitles (list): List of subtitles corresponding to each frame.\n",
        "        video_fps (int): Original FPS of the video.\n",
        "        process_fps (int): FPS at which YOLO will run.\n",
        "\n",
        "    Returns:\n",
        "        list: Processed frames with subtitles.\n",
        "    \"\"\"\n",
        "\n",
        "    # ✅ Step 1: Select Frames at 3 FPS for YOLO Detection\n",
        "    frame_interval = video_fps // process_fps  # Process every `frame_interval` frames\n",
        "    selected_indices = list(range(0, len(frames), frame_interval))\n",
        "\n",
        "    if not selected_indices:  # Prevent empty selection\n",
        "        selected_indices = [0]  # Process at least one frame\n",
        "\n",
        "    selected_frames = [frames[i] for i in selected_indices]  # Sampled frames for YOLO\n",
        "\n",
        "    # ✅ Step 2: Batch Object Detection on Selected Frames\n",
        "    batch_detections = detect_objects(selected_frames)  # YOLO runs only on sampled frames\n",
        "    frame_height, frame_width = frames[0].shape[:2]\n",
        "\n",
        "    # ✅ Load Predefined Safe Zones (JSON file loaded once)\n",
        "    with open(\"/content/optimal_subtitle_copied/news_video_subtitle_positions.json\", \"r\") as file:\n",
        "        pre_positions = json.load(file).get(f\"{frame_width}x{frame_height}\", {})\n",
        "\n",
        "    # ✅ Step 3: Compute Safe Zone for Each Sampled Frame\n",
        "    subtitle_height, margin = get_subtitle_size(frame_height)\n",
        "    # batch_safe_zones = [\n",
        "    #     tuple(map(int, calculate_safe_zone_with_prepositions_test_new(\n",
        "    #         frame_width, frame_height, batch_detections[i], pre_positions, subtitle_height, margin\n",
        "    #     ))) for i in range(len(selected_frames))\n",
        "    # ]\n",
        "\n",
        "    # # ✅ Step 4: Determine a Common Safe Zone for the Batch\n",
        "    # combined_safe_zones = batch_safe_zones + list(safe_zone_history)  # Merge with history\n",
        "    # most_common_zone, count = Counter(combined_safe_zones).most_common(1)[0]\n",
        "\n",
        "    # # ✅ Choose the Final Safe Zone\n",
        "    # final_safe_zone = (\n",
        "    #     most_common_zone if count >= len(combined_safe_zones) * 0.6\n",
        "    #     else tuple(map(int, np.mean(batch_safe_zones, axis=0)))\n",
        "    # )\n",
        "\n",
        "    # ✅ Step 3: Collect Safe Zone Positions for Each Frame in Batch\n",
        "    batch_safe_zones = [\n",
        "        calculate_safe_zone_with_prepositions_test_new(\n",
        "            frame_width, frame_height, batch_detections[i], pre_positions, subtitle_height, margin\n",
        "        )[0]  # ✅ Extract only the position name\n",
        "        for i in range(len(selected_frames))\n",
        "    ]\n",
        "\n",
        "    # ✅ Step 4: Determine the Most Used Safe Zone\n",
        "    combined_safe_zones = batch_safe_zones + list(safe_zone_history)  # Merge with history\n",
        "    zone_counts = Counter(combined_safe_zones)  # Count occurrences\n",
        "\n",
        "    # ✅ Assign the most frequently used zone as the final safe zone\n",
        "    if zone_counts:\n",
        "        final_safe_zone = max(zone_counts, key=zone_counts.get)  # ✅ Find the most used zone\n",
        "    else:\n",
        "        final_safe_zone = \"bottomCenter\"  # ✅ Default fallback\n",
        "\n",
        "    print(f\"✅ Final Safe Zone: {final_safe_zone}\")\n",
        "\n",
        "\n",
        "\n",
        "    # ✅ Store the final safe zone for future frames\n",
        "    safe_zone_history.append(final_safe_zone)\n",
        "\n",
        "    # ✅ Step 5: Apply Safe Zone to All Frames in the Batch\n",
        "    # return [\n",
        "    #     cv2.rectangle(frames[i], (final_safe_zone[0], final_safe_zone[1]),\n",
        "    #                   (final_safe_zone[2], final_safe_zone[3]), (255, 0, 0), 3)\n",
        "\n",
        "    #     for i in range(len(frames))\n",
        "    # ]\n",
        "\n",
        "    # processed_frames = []\n",
        "    # for i, frame in enumerate(frames):\n",
        "    #     subtitle_text = subtitles[i]\n",
        "    #     processed_frame = render_subtitle_multi_new(frame, subtitle_text, final_safe_zone, frame_width, frame_height)\n",
        "    #     processed_frames.append(processed_frame)\n",
        "\n",
        "    return final_safe_zone"
      ],
      "metadata": {
        "id": "FAPdtoMltqAT"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "def print_ttml_with_updated_regions(ttml_file_path, subtitle_data):\n",
        "    \"\"\"\n",
        "    Prints the TTML <p> elements with updated regions, removing 'region' if it's None.\n",
        "\n",
        "    Parameters:\n",
        "        ttml_file_path (str): Path to the TTML file.\n",
        "        subtitle_data (list): List of subtitles in the format:\n",
        "            [{\"start\": start_time, \"end\": end_time, \"text\": text, \"region\": \"region_id\"}]\n",
        "    \"\"\"\n",
        "\n",
        "    # ✅ Load TTML File\n",
        "    tree = ET.parse(ttml_file_path)\n",
        "    root = tree.getroot()\n",
        "    ns = {'ttml': 'http://www.w3.org/ns/ttml'}\n",
        "\n",
        "    # ✅ Find All <p> Elements (Subtitles) and Update Regions\n",
        "    for p in root.findall('.//ttml:p', ns):\n",
        "        start_time = convert_ttml_time_to_seconds(p.attrib.get(\"begin\", \"0.0s\"))\n",
        "        end_time = convert_ttml_time_to_seconds(p.attrib.get(\"end\", \"0.0s\"))\n",
        "\n",
        "        # ✅ Find Matching Subtitle\n",
        "        matched_subtitle = next((sub for sub in subtitle_data if sub[\"start\"] <= start_time <= sub[\"end\"]), None)\n",
        "\n",
        "        if matched_subtitle:\n",
        "            if matched_subtitle[\"region\"] is not None:\n",
        "                p.attrib[\"region\"] = matched_subtitle[\"region\"]  # ✅ Assign Correct Region\n",
        "            elif \"region\" in p.attrib:\n",
        "                del p.attrib[\"region\"]  # ✅ Remove `region` if it's None\n",
        "\n",
        "    # ✅ Print Updated TTML Content\n",
        "    updated_ttml = ET.tostring(root, encoding=\"utf-8\").decode(\"utf-8\")\n",
        "    print(updated_ttml)  # ✅ Print instead of writing to a file"
      ],
      "metadata": {
        "id": "gqHAFmFGkCY1"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import json\n",
        "\n",
        "def generate_ttml_layout(ttml_file_path, json_data, frame_width, frame_height):\n",
        "    \"\"\"\n",
        "    Generates an updated TTML <layout> section with subtitle positions from JSON and prints the result.\n",
        "\n",
        "    Parameters:\n",
        "        ttml_file_path (str): Path to the TTML file.\n",
        "        json_data (dict): JSON data containing subtitle positions.\n",
        "        frame_width (int): Width of the video frame.\n",
        "        frame_height (int): Height of the video frame.\n",
        "\n",
        "    Returns:\n",
        "        None (Prints updated TTML layout)\n",
        "    \"\"\"\n",
        "\n",
        "    # ✅ Load TTML File\n",
        "    tree = ET.parse(ttml_file_path)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    # ✅ Define namespace for TTML (ensure correct XML parsing)\n",
        "    ns = {'ttml': 'http://www.w3.org/ns/ttml'}\n",
        "    ET.register_namespace(\"\", ns[\"ttml\"])\n",
        "\n",
        "    # ✅ Find or Create the <layout> Element\n",
        "    layout_element = root.find('.//ttml:layout', ns)\n",
        "    if layout_element is None:\n",
        "        layout_element = ET.Element(\"{http://www.w3.org/ns/ttml}layout\")\n",
        "        root.insert(0, layout_element)\n",
        "    else:\n",
        "        # ✅ Remove ALL existing <region> elements inside <layout>\n",
        "        for region in list(layout_element):\n",
        "            layout_element.remove(region)\n",
        "\n",
        "    # ✅ Insert Subtitle Regions from JSON (Predefined & Dynamic)\n",
        "    for region_name, region_data in json_data.items():\n",
        "        x1, y1, x2, y2 = region_data[\"coordinates\"]\n",
        "\n",
        "        # Convert absolute pixel values to TTML percentages\n",
        "        origin_x = (x1 / frame_width) * 100\n",
        "        origin_y = (y1 / frame_height) * 100\n",
        "        extent_x = ((x2 - x1) / frame_width) * 100\n",
        "        extent_y = ((y2 - y1) / frame_height) * 100\n",
        "\n",
        "        # Construct the region XML element\n",
        "        region_element = ET.Element(\"{http://www.w3.org/ns/ttml}region\", attrib={\n",
        "            \"tts:origin\": f\"{origin_x:.2f}% {origin_y:.2f}%\",\n",
        "            \"tts:extent\": f\"{extent_x:.2f}% {extent_y:.2f}%\",\n",
        "            \"tts:displayAlign\": \"center\",\n",
        "            \"tts:textAlign\": \"center\",\n",
        "            \"xml:id\": region_name\n",
        "        })\n",
        "\n",
        "        # Add new regions to the layout\n",
        "        layout_element.append(region_element)\n",
        "\n",
        "    # ✅ Print Updated TTML Layout (Without Writing to File)\n",
        "    updated_layout = ET.tostring(layout_element, encoding=\"utf-8\").decode(\"utf-8\")\n",
        "    print(updated_layout)"
      ],
      "metadata": {
        "id": "4Fzxr5YMkVOb"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import json\n",
        "from collections import Counter, deque\n",
        "import numpy as np\n",
        "\n",
        "safe_zone_history = deque(maxlen=10)  # Stores past safe zones for consistency\n",
        "\n",
        "def process_frames_batch_3fps(frames, subtitles, ttml_file_path, json_file_path, video_fps=30, process_fps=3):\n",
        "    \"\"\"\n",
        "    Processes a batch of frames at 3 FPS:\n",
        "    - Detects objects in sampled frames using YOLO\n",
        "    - Computes one safe zone for the batch\n",
        "    - Updates the TTML file with the computed subtitle region\n",
        "\n",
        "    Parameters:\n",
        "        frames (list): List of frames (NumPy arrays).\n",
        "        subtitles (list): List of subtitles corresponding to each frame.\n",
        "        ttml_file_path (str): Path to the TTML file.\n",
        "        json_file_path (str): Path to the JSON file with predefined subtitle positions.\n",
        "        video_fps (int): Original FPS of the video.\n",
        "        process_fps (int): FPS at which YOLO will run.\n",
        "\n",
        "    Returns:\n",
        "        None (Modifies TTML file in-place)\n",
        "    \"\"\"\n",
        "\n",
        "    # ✅ Step 1: Select Frames at 3 FPS for YOLO Detection\n",
        "    frame_interval = video_fps // process_fps  # Process every `frame_interval` frames\n",
        "    selected_indices = list(range(0, len(frames), frame_interval))\n",
        "\n",
        "    if not selected_indices:  # Prevent empty selection\n",
        "        selected_indices = [0]  # Process at least one frame\n",
        "\n",
        "    selected_frames = [frames[i] for i in selected_indices]  # Sampled frames for YOLO\n",
        "\n",
        "    # ✅ Step 2: Batch Object Detection on Selected Frames\n",
        "    batch_detections = detect_objects(selected_frames)  # YOLO runs only on sampled frames\n",
        "    frame_height, frame_width = frames[0].shape[:2]\n",
        "\n",
        "    # ✅ Load Predefined Safe Zones (JSON file)\n",
        "    with open(json_file_path, \"r\") as file:\n",
        "        pre_positions = json.load(file).get(f\"{frame_width}x{frame_height}\", {})\n",
        "\n",
        "    # ✅ Step 3: Compute Safe Zone for Each Sampled Frame\n",
        "    subtitle_height, margin = get_subtitle_size(frame_height)\n",
        "    batch_safe_zones = [\n",
        "        tuple(map(int, calculate_safe_zone_with_prepositions_test(\n",
        "            frame_width, frame_height, batch_detections[i], pre_positions, subtitle_height, margin\n",
        "        ))) for i in range(len(selected_frames))\n",
        "    ]\n",
        "\n",
        "    # ✅ Step 4: Determine a Common Safe Zone for the Batch\n",
        "    combined_safe_zones = batch_safe_zones + list(safe_zone_history)  # Merge with history\n",
        "    most_common_zone, count = Counter(combined_safe_zones).most_common(1)[0]\n",
        "\n",
        "    # ✅ Choose the Final Safe Zone\n",
        "    final_safe_zone = (\n",
        "        most_common_zone if count >= len(combined_safe_zones) * 0.6\n",
        "        else tuple(map(int, np.mean(batch_safe_zones, axis=0)))\n",
        "    )\n",
        "\n",
        "    # ✅ Keep all computed dynamic regions in a global dictionary\n",
        "    all_dynamic_regions = {}\n",
        "\n",
        "    # ✅ Store the final safe zone for future frames\n",
        "    safe_zone_history.append(final_safe_zone)\n",
        "\n",
        "    # ✅ Generate unique dynamic region ID for each subtitle segment\n",
        "    dynamic_region_name = f\"dynamic_{int(final_safe_zone[0])}_{int(final_safe_zone[1])}\"\n",
        "    all_dynamic_regions[dynamic_region_name] = final_safe_zone  # ✅ Store multiple dynamic regions\n",
        "\n",
        "    # ✅ Update TTML Layout to Include All Detected Dynamic Regions\n",
        "    update_ttml_layout(ttml_file_path, json_file_path, frame_width, frame_height, all_dynamic_regions)\n",
        "\n",
        "    # ✅ Update Subtitle `<p>` Elements with Individual Dynamic Regions\n",
        "    update_ttml_subtitle_regions(ttml_file_path, subtitle_data)\n",
        "\n",
        "    print(f\"Updated TTML with region {dynamic_region_name}\")"
      ],
      "metadata": {
        "id": "wUP7adUoj_BA"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDwa2goMQgik"
      },
      "source": [
        "## Testing the Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoWr2HYHQgik"
      },
      "source": [
        "### Integrate with srt file and video fps"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pysrt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc0SuEOLTtPo",
        "outputId": "15ad58f1-5ee5-4b4f-fa59-743a46c24ee2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pysrt\n",
            "  Downloading pysrt-1.1.2.tar.gz (104 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/104.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.4/104.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.11/dist-packages (from pysrt) (5.2.0)\n",
            "Building wheels for collected packages: pysrt\n",
            "  Building wheel for pysrt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pysrt: filename=pysrt-1.1.2-py3-none-any.whl size=13443 sha256=cb1897037971453d015b82c6464bc9752a79bfdf150ac9c4a1ba5c2e5f1312ba\n",
            "  Stored in directory: /root/.cache/pip/wheels/2d/b2/df/ea10959920533975b4a74a25a35e6d79655b63f3006611a99f\n",
            "Successfully built pysrt\n",
            "Installing collected packages: pysrt\n",
            "Successfully installed pysrt-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "HNDyfzysQgik"
      },
      "outputs": [],
      "source": [
        "import pysrt\n",
        "from collections import defaultdict\n",
        "\n",
        "def parse_srt_file(srt_file):\n",
        "    \"\"\"\n",
        "    Reads and parses an SRT file, pre-indexing subtitles for fast lookup.\n",
        "\n",
        "    Parameters:\n",
        "        srt_file (str): Path to the .srt file.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary where keys are integer timestamps (seconds),\n",
        "              and values are subtitle texts.\n",
        "    \"\"\"\n",
        "    subs = pysrt.open(srt_file)\n",
        "    subtitle_dict = defaultdict(lambda: None)  # Default to None for missing frames\n",
        "\n",
        "    for sub in subs:\n",
        "        start_time = int(sub.start.minutes * 60 + sub.start.seconds)  # Round to nearest second\n",
        "        end_time = int(sub.end.minutes * 60 + sub.end.seconds)\n",
        "        subtitle_text = sub.text.replace(\"\\n\", \" \")  # Convert newlines to spaces\n",
        "\n",
        "        # ✅ Store subtitles for all frames in the time range\n",
        "        for t in range(start_time, end_time + 1):\n",
        "            subtitle_dict[t] = subtitle_text\n",
        "\n",
        "    return subtitle_dict  # Faster lookups using a dictionary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_subtitles_for_frames(frame_times, subtitle_data):\n",
        "    \"\"\"\n",
        "    Retrieves subtitle texts for a batch of frame timestamps.\n",
        "\n",
        "    Parameters:\n",
        "        frame_times (list): List of timestamps (in seconds).\n",
        "        subtitle_data (list): List of subtitles in the format:\n",
        "            [{\"start\": start_time, \"end\": end_time, \"text\": text, \"region\": region}, ...]\n",
        "\n",
        "    Returns:\n",
        "        list: List of subtitle texts corresponding to each frame timestamp.\n",
        "    \"\"\"\n",
        "    frame_subtitles = []\n",
        "\n",
        "    for time in frame_times:\n",
        "        subtitle_text = \"\"  # Default to empty string\n",
        "\n",
        "        for subtitle in subtitle_data:\n",
        "            if subtitle[\"start\"] <= time <= subtitle[\"end\"]:\n",
        "                subtitle_text = subtitle[\"text\"].replace(\"\\n\", \" \")  # Remove newlines\n",
        "                break  # Stop once we find a match\n",
        "\n",
        "        frame_subtitles.append(subtitle_text)\n",
        "\n",
        "    return frame_subtitles"
      ],
      "metadata": {
        "id": "g8EqZoCLY49C"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_video_fps(video_path):\n",
        "    \"\"\"Extracts FPS from a video using FFmpeg.\"\"\"\n",
        "    cmd = [\"ffmpeg\", \"-i\", video_path]\n",
        "\n",
        "    # ✅ Use stdout and stderr explicitly\n",
        "    result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "\n",
        "    # ✅ Parse FPS from FFmpeg output\n",
        "    for line in result.stderr.split(\"\\n\"):\n",
        "        if \"Stream\" in line and \"Video\" in line and \"fps\" in line:\n",
        "            fps_value = float(line.split(\"fps\")[0].strip().split()[-1])  # Extract FPS\n",
        "            return fps_value\n",
        "\n",
        "    return 30  # Default to 30 FPS if not found"
      ],
      "metadata": {
        "id": "bDPjN9-7b5sS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def should_process_frame(frame_time, subtitle_timestamps, fps, tolerance=0.01):\n",
        "    \"\"\"\n",
        "    Checks if a frame's timestamp falls within any subtitle duration, with a small tolerance.\n",
        "\n",
        "    Returns True if the frame should be processed, False otherwise.\n",
        "    \"\"\"\n",
        "    frame_tolerance = 1 / fps  # The duration of a single frame in seconds\n",
        "    adjusted_tolerance = min(tolerance, 2 * frame_tolerance)  # Limit to 2 frames\n",
        "\n",
        "    result = any((start - adjusted_tolerance) <= frame_time <= (end + adjusted_tolerance)\n",
        "                 for start, end in subtitle_timestamps)\n",
        "\n",
        "    # print(f\"Frame Time: {frame_time:.3f}s | Process: {result}\")  # ✅ Print Result\n",
        "    return result"
      ],
      "metadata": {
        "id": "14jJVl3dVi9y"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## combined srt and ttml timestamp\n",
        "\n",
        "import pysrt\n",
        "import xml.etree.ElementTree as ET\n",
        "import re\n",
        "\n",
        "def get_subtitle_timestamps(subtitle_file, file_type=\"auto\"):\n",
        "    \"\"\"\n",
        "    Extracts subtitle timestamps from an SRT or TTML file.\n",
        "\n",
        "    Parameters:\n",
        "        subtitle_file (str): Path to the subtitle file.\n",
        "        file_type (str): \"srt\" for SRT, \"ttml\" for TTML, or \"auto\" to detect from extension.\n",
        "\n",
        "    Returns:\n",
        "        list of tuples: Each tuple contains (start_time, end_time) in seconds.\n",
        "    \"\"\"\n",
        "    # Auto-detect file type\n",
        "    if file_type == \"auto\":\n",
        "        if subtitle_file.endswith(\".srt\"):\n",
        "            file_type = \"srt\"\n",
        "        elif subtitle_file.endswith(\".ttml\") or subtitle_file.endswith(\".xml\"):\n",
        "            file_type = \"ttml\"\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported subtitle file format. Use 'srt' or 'ttml'.\")\n",
        "\n",
        "    # Process SRT\n",
        "    if file_type == \"srt\":\n",
        "        return get_srt_timestamps(subtitle_file)\n",
        "\n",
        "    # Process TTML\n",
        "    elif file_type == \"ttml\":\n",
        "        return get_ttml_timestamps(subtitle_file)\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"Invalid file type specified. Use 'srt' or 'ttml'.\")\n",
        "\n",
        "def get_srt_timestamps(srt_file):\n",
        "    \"\"\"Extracts subtitle timestamps from an SRT file.\"\"\"\n",
        "    subs = pysrt.open(srt_file)\n",
        "    subtitle_timestamps = []\n",
        "\n",
        "    for sub in subs:\n",
        "        start_time = sub.start.hours * 3600 + sub.start.minutes * 60 + sub.start.seconds + sub.start.milliseconds / 1000\n",
        "        end_time = sub.end.hours * 3600 + sub.end.minutes * 60 + sub.end.seconds + sub.end.milliseconds / 1000\n",
        "        subtitle_timestamps.append((start_time, end_time))\n",
        "\n",
        "    return subtitle_timestamps\n",
        "\n",
        "def get_ttml_timestamps(ttml_file):\n",
        "    \"\"\"Extracts subtitle timestamps from a TTML file.\"\"\"\n",
        "    tree = ET.parse(ttml_file)\n",
        "    root = tree.getroot()\n",
        "    ns = {'ttml': 'http://www.w3.org/ns/ttml'}\n",
        "\n",
        "    subtitle_timestamps = []\n",
        "\n",
        "    for p in root.findall('.//ttml:p', ns):\n",
        "        start_time = p.attrib.get(\"begin\", \"0.0s\")\n",
        "        end_time = p.attrib.get(\"end\", \"0.0s\")\n",
        "\n",
        "        start_seconds = convert_ttml_time_to_seconds(start_time)\n",
        "        end_seconds = convert_ttml_time_to_seconds(end_time)\n",
        "\n",
        "        subtitle_timestamps.append((start_seconds, end_seconds))\n",
        "\n",
        "    return subtitle_timestamps\n",
        "\n",
        "def convert_ttml_time_to_seconds(ttml_time):\n",
        "    \"\"\"\n",
        "    Converts TTML time format (HH:MM:SS.mmm or MM:SS.mmm or SS.mmm or SS.mmm's') to seconds.\n",
        "\n",
        "    Parameters:\n",
        "        ttml_time (str): TTML-formatted time.\n",
        "\n",
        "    Returns:\n",
        "        float: Time in seconds.\n",
        "    \"\"\"\n",
        "    ttml_time = ttml_time.rstrip('s')  # Remove trailing 's' if present\n",
        "    parts = ttml_time.split(\":\")\n",
        "\n",
        "    if len(parts) == 3:  # HH:MM:SS.mmm\n",
        "        hours, minutes, seconds = map(float, parts)\n",
        "    elif len(parts) == 2:  # MM:SS.mmm\n",
        "        hours, minutes, seconds = 0, *map(float, parts)\n",
        "    else:  # SS.mmm\n",
        "        hours, minutes, seconds = 0, 0, float(parts[0])\n",
        "\n",
        "    return hours * 3600 + minutes * 60 + seconds"
      ],
      "metadata": {
        "id": "bUdSYW-RZTx4"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import pysrt\n",
        "import os\n",
        "\n",
        "def parse_subtitle_file(file_path):\n",
        "    \"\"\"\n",
        "    Parses either an SRT or TTML subtitle file and extracts subtitles.\n",
        "\n",
        "    Parameters:\n",
        "        file_path (str): Path to the subtitle file.\n",
        "\n",
        "    Returns:\n",
        "        list: List of subtitles in the format:\n",
        "            [\n",
        "                {\"start\": start_time, \"end\": end_time, \"text\": \"subtitle text\", \"region\": \"region_id\"}\n",
        "            ]\n",
        "    \"\"\"\n",
        "    extension = os.path.splitext(file_path)[-1].lower()\n",
        "    subtitle_data = []\n",
        "\n",
        "    if extension == \".srt\":\n",
        "        subs = pysrt.open(file_path)\n",
        "        for sub in subs:\n",
        "            start_time = (\n",
        "                sub.start.hours * 3600 + sub.start.minutes * 60 + sub.start.seconds + sub.start.milliseconds / 1000\n",
        "            )\n",
        "            end_time = (\n",
        "                sub.end.hours * 3600 + sub.end.minutes * 60 + sub.end.seconds + sub.end.milliseconds / 1000\n",
        "            )\n",
        "            text = sub.text.replace(\"\\n\", \" \")  # Convert newlines to spaces\n",
        "\n",
        "            subtitle_data.append({\n",
        "                \"start\": start_time,\n",
        "                \"end\": end_time,\n",
        "                \"text\": text,\n",
        "                \"region\": None  # SRT doesn't support regions\n",
        "            })\n",
        "\n",
        "    elif extension == \".ttml\":\n",
        "        # ✅ Register TTML Namespaces\n",
        "        ET.register_namespace('', \"http://www.w3.org/ns/ttml\")  # Default TTML namespace\n",
        "        ET.register_namespace('ttp', \"http://www.w3.org/ns/ttml#parameter\")\n",
        "        ET.register_namespace('tts', \"http://www.w3.org/ns/ttml#styling\")\n",
        "        ET.register_namespace('ttm', \"http://www.w3.org/ns/ttml#metadata\")\n",
        "\n",
        "        # ✅ Parse TTML File\n",
        "        tree = ET.parse(file_path)\n",
        "        root = tree.getroot()\n",
        "        ns = {'ttml': 'http://www.w3.org/ns/ttml'}\n",
        "\n",
        "        # ✅ Extract Subtitle Data\n",
        "        for p in root.findall('.//ttml:p', ns):\n",
        "            start_time = convert_ttml_time_to_seconds(p.attrib.get(\"begin\", \"0.0s\"))\n",
        "            end_time = convert_ttml_time_to_seconds(p.attrib.get(\"end\", \"0.0s\"))\n",
        "            text = \" \".join(p.itertext()).strip()\n",
        "            region = p.attrib.get(\"region\", None)\n",
        "\n",
        "            subtitle_data.append({\n",
        "                \"start\": start_time,\n",
        "                \"end\": end_time,\n",
        "                \"text\": text,\n",
        "                \"region\": region\n",
        "            })\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported subtitle format. Only SRT and TTML are supported.\")\n",
        "\n",
        "    return subtitle_data"
      ],
      "metadata": {
        "id": "GgMktVeZcXhH"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## current main test\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import subprocess\n",
        "\n",
        "# ✅ Define file paths in /content/\n",
        "video_input_path = \"/content/optimal_subtitle_copied/test_video_3.mp4\"\n",
        "final_video_path = \"/content/optimal_subtitle_copied/test_video_with_audio.mp4\"\n",
        "file_path = \"/content/optimal_subtitle_copied/TTML_file/test_video_3_eng.ttml\"\n",
        "# json_path = \"/content/optimal_subtitle_copied/subtitle_positions_ttml.json\"\n",
        "\n",
        "subtitle_data_updated = []\n",
        "\n",
        "# ✅ Extract FPS dynamically\n",
        "fps = get_video_fps(video_input_path)\n",
        "print(f\"✅ Corrected FPS: {fps}\")\n",
        "\n",
        "# ✅ Load Pre-indexed Subtitles\n",
        "subtitle_data = parse_subtitle_file(file_path)\n",
        "\n",
        "# ✅ Load Subtitle Timestamps\n",
        "subtitle_timestamps = get_subtitle_timestamps(file_path)\n",
        "\n",
        "# ✅ Open Video File\n",
        "cap = cv2.VideoCapture(video_input_path)\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "print(f\"Frame Width: {frame_width}, Frame Height: {frame_height}\")\n",
        "\n",
        "# ✅ Initialize Video Writer\n",
        "# fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "# out = cv2.VideoWriter(final_video_path, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "# ✅ Process Video Based on Subtitle Timeframes\n",
        "frame_buffer = []\n",
        "timestamp_buffer = []\n",
        "subtitle_index = 0  # Track current subtitle\n",
        "frame_number = 0\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break  # Exit if no more frames\n",
        "\n",
        "    frame_time = frame_number / fps  # Convert frame number to timestamp\n",
        "\n",
        "    # ✅ Ensure we have a valid subtitle to match\n",
        "    if subtitle_index < len(subtitle_data):\n",
        "        current_subtitle = subtitle_data[subtitle_index]\n",
        "        # print(current_subtitle)\n",
        "        current_start = current_subtitle[\"start\"]\n",
        "        # print(current_start)\n",
        "        current_end = current_subtitle[\"end\"]\n",
        "        # print(current_end)\n",
        "        subtitle_text = current_subtitle[\"text\"]\n",
        "\n",
        "        # ✅ Collect frames only within the current subtitle's timestamp range\n",
        "        if current_start <= frame_time <= current_end:\n",
        "            frame_buffer.append(frame)\n",
        "            timestamp_buffer.append(frame_time)\n",
        "\n",
        "        # ✅ When the last frame of the subtitle is reached, process the batch\n",
        "        if frame_time > current_end:\n",
        "            if frame_buffer:  # Ensure we have frames to process\n",
        "                subtitles = [current_subtitle]  # Use only the current subtitle's data\n",
        "\n",
        "                processed_frames = process_frames_batch_3fps_processed(frame_buffer, subtitles)\n",
        "                current_subtitle[\"region\"] = processed_frames\n",
        "                # print(processed_frames)\n",
        "\n",
        "                # ✅ Append processed subtitle data dynamically\n",
        "                # subtitle_data.append({\n",
        "                #     \"start\": current_start,\n",
        "                #     \"end\": current_end,\n",
        "                #     \"text\": subtitle_text,\n",
        "                #     \"region\": processed_frames  # ✅ Dynamically determined region\n",
        "                # })\n",
        "\n",
        "                # ✅ Write processed frames to the output video\n",
        "                # for processed_frame in processed_frames:\n",
        "                #     print(processed_frame)\n",
        "\n",
        "                # ✅ Clear buffers and move to the next subtitle\n",
        "                frame_buffer.clear()\n",
        "                timestamp_buffer.clear()\n",
        "                subtitle_index += 1\n",
        "\n",
        "    frame_number += 1\n",
        "\n",
        "# ✅ Process remaining frames if any subtitles are left\n",
        "if frame_buffer:\n",
        "    subtitles = [subtitle_data[subtitle_index]]  # Process last remaining batch\n",
        "    processed_frames = process_frames_batch_3fps_processed(frame_buffer, subtitles)\n",
        "    print(processed_frames)\n",
        "    # for processed_frame in processed_frames:\n",
        "    #     print(processed_frame)\n",
        "\n",
        "cap.release()\n",
        "print(subtitle_data)\n",
        "print_ttml_with_updated_regions(file_path, subtitle_data)\n",
        "layout = get_used_safe_zones()\n",
        "generate_ttml_layout(file_path, layout, frame_width, frame_height)\n",
        "# out.release()\n",
        "# print(f\"✅ Video processing completed: {final_video_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8pqRIWGV96H",
        "outputId": "a0ccd277-94e0-48bd-e4be-5917da96c683"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Corrected FPS: 29.97\n",
            "Frame Width: 1280, Frame Height: 720\n",
            "\n",
            "0: 384x640 2 faces, 11.0ms\n",
            "1: 384x640 2 faces, 11.0ms\n",
            "Speed: 2.0ms preprocess, 11.0ms inference, 1.1ms postprocess per image at shape (2, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 2 faces, 3.9ms\n",
            "1: 384x640 2 faces, 3.9ms\n",
            "2: 384x640 2 faces, 1 text, 3.9ms\n",
            "3: 384x640 2 faces, 1 text, 3.9ms\n",
            "4: 384x640 2 faces, 1 text, 3.9ms\n",
            "5: 384x640 2 faces, 1 text, 3.9ms\n",
            "6: 384x640 2 faces, 3.9ms\n",
            "7: 384x640 2 faces, 1 logo, 1 news-ticker, 1 text, 3.9ms\n",
            "8: 384x640 2 faces, 2 logos, 2 news-tickers, 2 texts, 3.9ms\n",
            "9: 384x640 2 faces, 2 logos, 1 news-ticker, 2 texts, 3.9ms\n",
            "10: 384x640 2 faces, 2 logos, 1 news-ticker, 2 texts, 3.9ms\n",
            "11: 384x640 2 faces, 2 logos, 1 news-ticker, 2 texts, 3.9ms\n",
            "12: 384x640 2 faces, 2 logos, 1 news-ticker, 2 texts, 3.9ms\n",
            "Speed: 1.7ms preprocess, 3.9ms inference, 0.8ms postprocess per image at shape (13, 3, 384, 640)\n",
            "✅ Final Safe Zone: middle3\n",
            "\n",
            "0: 384x640 2 faces, 2 logos, 1 news-ticker, 3 texts, 4.8ms\n",
            "1: 384x640 2 faces, 2 logos, 1 news-ticker, 3 texts, 4.8ms\n",
            "2: 384x640 2 faces, 2 logos, 2 news-tickers, 1 text, 4.8ms\n",
            "3: 384x640 2 faces, 2 logos, 1 news-ticker, 3 texts, 4.8ms\n",
            "Speed: 1.8ms preprocess, 4.8ms inference, 1.3ms postprocess per image at shape (4, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 2 faces, 2 logos, 2 news-tickers, 3 texts, 4.7ms\n",
            "1: 384x640 2 faces, 2 logos, 1 news-ticker, 3 texts, 4.7ms\n",
            "2: 384x640 2 faces, 2 logos, 1 news-ticker, 3 texts, 4.7ms\n",
            "3: 384x640 2 faces, 2 logos, 2 news-tickers, 2 texts, 4.7ms\n",
            "Speed: 2.3ms preprocess, 4.7ms inference, 0.9ms postprocess per image at shape (4, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 2 faces, 2 logos, 2 news-tickers, 3 texts, 4.6ms\n",
            "1: 384x640 2 faces, 1 logo, 1 news-ticker, 1 text, 4.6ms\n",
            "2: 384x640 3 texts, 4.6ms\n",
            "3: 384x640 2 texts, 4.6ms\n",
            "4: 384x640 2 texts, 4.6ms\n",
            "5: 384x640 2 texts, 4.6ms\n",
            "Speed: 1.7ms preprocess, 4.6ms inference, 0.9ms postprocess per image at shape (6, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 2 texts, 4.8ms\n",
            "1: 384x640 2 texts, 4.8ms\n",
            "2: 384x640 2 texts, 4.8ms\n",
            "3: 384x640 2 texts, 4.8ms\n",
            "Speed: 1.8ms preprocess, 4.8ms inference, 0.9ms postprocess per image at shape (4, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 2 texts, 4.6ms\n",
            "1: 384x640 1 news-ticker, 2 texts, 4.6ms\n",
            "2: 384x640 1 news-ticker, 2 texts, 4.6ms\n",
            "3: 384x640 1 news-ticker, 2 texts, 4.6ms\n",
            "Speed: 2.2ms preprocess, 4.6ms inference, 0.9ms postprocess per image at shape (4, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 1 news-ticker, 2 texts, 4.5ms\n",
            "1: 384x640 1 news-ticker, 2 texts, 4.5ms\n",
            "2: 384x640 1 news-ticker, 2 texts, 4.5ms\n",
            "3: 384x640 2 news-tickers, 2 texts, 4.5ms\n",
            "4: 384x640 2 news-tickers, 2 texts, 4.5ms\n",
            "5: 384x640 1 news-ticker, 2 texts, 4.5ms\n",
            "Speed: 1.7ms preprocess, 4.5ms inference, 0.8ms postprocess per image at shape (6, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 2 news-tickers, 2 texts, 4.1ms\n",
            "1: 384x640 1 news-ticker, 2 texts, 4.1ms\n",
            "2: 384x640 2 news-tickers, 2 texts, 4.1ms\n",
            "3: 384x640 2 news-tickers, 2 texts, 4.1ms\n",
            "4: 384x640 2 news-tickers, 2 texts, 4.1ms\n",
            "5: 384x640 2 news-tickers, 2 texts, 4.1ms\n",
            "6: 384x640 1 news-ticker, 2 texts, 4.1ms\n",
            "7: 384x640 2 news-tickers, 2 texts, 4.1ms\n",
            "8: 384x640 3 news-tickers, 2 texts, 4.1ms\n",
            "Speed: 1.8ms preprocess, 4.1ms inference, 0.9ms postprocess per image at shape (9, 3, 384, 640)\n",
            "✅ Final Safe Zone: middle3\n",
            "\n",
            "0: 384x640 2 news-tickers, 2 texts, 5.7ms\n",
            "1: 384x640 3 news-tickers, 2 texts, 5.7ms\n",
            "2: 384x640 3 news-tickers, 2 texts, 5.7ms\n",
            "Speed: 1.9ms preprocess, 5.7ms inference, 0.9ms postprocess per image at shape (3, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 2 news-tickers, 2 texts, 7.1ms\n",
            "1: 384x640 3 news-tickers, 2 texts, 7.1ms\n",
            "2: 384x640 3 news-tickers, 2 texts, 7.1ms\n",
            "Speed: 2.1ms preprocess, 7.1ms inference, 1.0ms postprocess per image at shape (3, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 3 news-tickers, 2 texts, 4.4ms\n",
            "1: 384x640 3 news-tickers, 2 texts, 4.4ms\n",
            "2: 384x640 1 logo, 1 news-ticker, 4.4ms\n",
            "3: 384x640 1 news-ticker, 4.4ms\n",
            "4: 384x640 2 news-tickers, 4.4ms\n",
            "5: 384x640 1 news-ticker, 2 texts, 4.4ms\n",
            "6: 384x640 4 faces, 1 logo, 1 news-ticker, 4 texts, 4.4ms\n",
            "Speed: 1.7ms preprocess, 4.4ms inference, 0.8ms postprocess per image at shape (7, 3, 384, 640)\n",
            "✅ Final Safe Zone: middle3\n",
            "\n",
            "0: 384x640 4 faces, 2 logos, 1 news-ticker, 3 texts, 4.8ms\n",
            "1: 384x640 2 faces, 2 logos, 1 news-ticker, 4 texts, 4.8ms\n",
            "2: 384x640 4 faces, 1 logo, 2 news-tickers, 5 texts, 4.8ms\n",
            "3: 384x640 3 faces, 1 logo, 2 news-tickers, 6 texts, 4.8ms\n",
            "Speed: 1.9ms preprocess, 4.8ms inference, 0.9ms postprocess per image at shape (4, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 3 faces, 1 logo, 1 news-ticker, 5 texts, 4.6ms\n",
            "1: 384x640 4 faces, 1 logo, 1 news-ticker, 4 texts, 4.6ms\n",
            "2: 384x640 3 faces, 1 logo, 2 news-tickers, 4 texts, 4.6ms\n",
            "3: 384x640 3 faces, 1 logo, 2 news-tickers, 5 texts, 4.6ms\n",
            "4: 384x640 4 faces, 2 logos, 2 news-tickers, 5 texts, 4.6ms\n",
            "5: 384x640 4 faces, 2 logos, 1 news-ticker, 5 texts, 4.6ms\n",
            "Speed: 1.7ms preprocess, 4.6ms inference, 0.9ms postprocess per image at shape (6, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 3 faces, 2 logos, 1 news-ticker, 4 texts, 5.6ms\n",
            "1: 384x640 3 faces, 2 logos, 1 news-ticker, 5 texts, 5.6ms\n",
            "2: 384x640 3 faces, 2 logos, 1 news-ticker, 5 texts, 5.6ms\n",
            "Speed: 1.9ms preprocess, 5.6ms inference, 0.9ms postprocess per image at shape (3, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 3 faces, 3 logos, 1 news-ticker, 5 texts, 8.0ms\n",
            "1: 384x640 3 faces, 3 logos, 1 news-ticker, 4 texts, 8.0ms\n",
            "Speed: 1.7ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (2, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 3 faces, 2 logos, 1 news-ticker, 4 texts, 4.4ms\n",
            "1: 384x640 3 faces, 1 logo, 1 news-ticker, 5 texts, 4.4ms\n",
            "2: 384x640 4 faces, 1 logo, 1 news-ticker, 6 texts, 4.4ms\n",
            "3: 384x640 3 faces, 1 logo, 1 news-ticker, 5 texts, 4.4ms\n",
            "4: 384x640 3 faces, 1 logo, 1 news-ticker, 5 texts, 4.4ms\n",
            "5: 384x640 4 faces, 1 logo, 1 news-ticker, 5 texts, 4.4ms\n",
            "6: 384x640 3 faces, 1 logo, 2 news-tickers, 5 texts, 4.4ms\n",
            "Speed: 1.7ms preprocess, 4.4ms inference, 0.8ms postprocess per image at shape (7, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 4 faces, 1 logo, 1 news-ticker, 5 texts, 4.8ms\n",
            "1: 384x640 4 faces, 1 logo, 1 news-ticker, 5 texts, 4.8ms\n",
            "2: 384x640 3 faces, 1 logo, 2 news-tickers, 6 texts, 4.8ms\n",
            "3: 384x640 3 faces, 1 logo, 2 news-tickers, 5 texts, 4.8ms\n",
            "Speed: 1.7ms preprocess, 4.8ms inference, 0.9ms postprocess per image at shape (4, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 4 faces, 1 logo, 2 news-tickers, 5 texts, 4.1ms\n",
            "1: 384x640 4 faces, 1 logo, 2 news-tickers, 5 texts, 4.1ms\n",
            "2: 384x640 4 faces, 1 logo, 2 news-tickers, 5 texts, 4.1ms\n",
            "3: 384x640 1 face, 1 logo, 2 news-tickers, 3 texts, 4.1ms\n",
            "4: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 4.1ms\n",
            "5: 384x640 1 face, 2 logos, 3 news-tickers, 4.1ms\n",
            "6: 384x640 1 face, 2 logos, 2 news-tickers, 1 text, 4.1ms\n",
            "7: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 4.1ms\n",
            "Speed: 1.7ms preprocess, 4.1ms inference, 0.8ms postprocess per image at shape (8, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 8.9ms\n",
            "1: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 8.9ms\n",
            "Speed: 2.0ms preprocess, 8.9ms inference, 1.3ms postprocess per image at shape (2, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 8.3ms\n",
            "1: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 8.3ms\n",
            "Speed: 2.1ms preprocess, 8.3ms inference, 1.0ms postprocess per image at shape (2, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 3.8ms\n",
            "1: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 3.8ms\n",
            "2: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 3.8ms\n",
            "3: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 3.8ms\n",
            "4: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 3.8ms\n",
            "5: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 3.8ms\n",
            "6: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 3.8ms\n",
            "7: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 3.8ms\n",
            "8: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.8ms\n",
            "9: 384x640 1 face, 2 logos, 2 news-tickers, 3.8ms\n",
            "10: 384x640 1 face, 2 logos, 3 news-tickers, 2 texts, 3.8ms\n",
            "11: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.8ms\n",
            "12: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.8ms\n",
            "13: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.8ms\n",
            "14: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.8ms\n",
            "Speed: 1.6ms preprocess, 3.8ms inference, 0.8ms postprocess per image at shape (15, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 7.9ms\n",
            "1: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 7.9ms\n",
            "Speed: 2.2ms preprocess, 7.9ms inference, 1.1ms postprocess per image at shape (2, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 5.9ms\n",
            "1: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 5.9ms\n",
            "2: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 5.9ms\n",
            "3: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 5.9ms\n",
            "Speed: 2.1ms preprocess, 5.9ms inference, 1.4ms postprocess per image at shape (4, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 1 face, 2 logos, 2 news-tickers, 4 texts, 6.1ms\n",
            "1: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 6.1ms\n",
            "2: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 6.1ms\n",
            "3: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 6.1ms\n",
            "Speed: 2.4ms preprocess, 6.1ms inference, 1.3ms postprocess per image at shape (4, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 4.6ms\n",
            "1: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 4.6ms\n",
            "2: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 4.6ms\n",
            "3: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 4.6ms\n",
            "4: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 4.6ms\n",
            "5: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 4.6ms\n",
            "Speed: 2.7ms preprocess, 4.6ms inference, 1.1ms postprocess per image at shape (6, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 1 face, 2 logos, 3 news-tickers, 3 texts, 4.4ms\n",
            "1: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 4.4ms\n",
            "2: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 4.4ms\n",
            "3: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 4.4ms\n",
            "4: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 4.4ms\n",
            "5: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 4.4ms\n",
            "6: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 4.4ms\n",
            "Speed: 2.0ms preprocess, 4.4ms inference, 1.0ms postprocess per image at shape (7, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 4.1ms\n",
            "1: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 4.1ms\n",
            "2: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 4.1ms\n",
            "3: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 4.1ms\n",
            "4: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 4.1ms\n",
            "5: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 4.1ms\n",
            "6: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 4.1ms\n",
            "7: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 4.1ms\n",
            "8: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 4.1ms\n",
            "Speed: 2.7ms preprocess, 4.1ms inference, 1.0ms postprocess per image at shape (9, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 8.5ms\n",
            "1: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 8.5ms\n",
            "2: 384x640 2 logos, 2 news-tickers, 3 texts, 8.5ms\n",
            "Speed: 2.0ms preprocess, 8.5ms inference, 1.5ms postprocess per image at shape (3, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 8.1ms\n",
            "1: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 8.1ms\n",
            "2: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 8.1ms\n",
            "Speed: 2.3ms preprocess, 8.1ms inference, 1.5ms postprocess per image at shape (3, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 9.3ms\n",
            "1: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 9.3ms\n",
            "2: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 9.3ms\n",
            "Speed: 3.1ms preprocess, 9.3ms inference, 1.2ms postprocess per image at shape (3, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "1: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "2: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "3: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "4: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "5: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "6: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 3.9ms\n",
            "7: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "8: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 3.9ms\n",
            "9: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "10: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "11: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "12: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "Speed: 1.6ms preprocess, 3.9ms inference, 0.8ms postprocess per image at shape (13, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 4.4ms\n",
            "1: 384x640 1 face, 2 logos, 2 news-tickers, 4 texts, 4.4ms\n",
            "2: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 4.4ms\n",
            "3: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 4.4ms\n",
            "4: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 4.4ms\n",
            "5: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 4.4ms\n",
            "6: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 4.4ms\n",
            "Speed: 1.7ms preprocess, 4.4ms inference, 0.9ms postprocess per image at shape (7, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 4.1ms\n",
            "1: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 4.1ms\n",
            "2: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 4.1ms\n",
            "3: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 4.1ms\n",
            "4: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 4.1ms\n",
            "5: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 4.1ms\n",
            "6: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 4.1ms\n",
            "7: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 4.1ms\n",
            "8: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 4.1ms\n",
            "Speed: 1.6ms preprocess, 4.1ms inference, 0.8ms postprocess per image at shape (9, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 6.2ms\n",
            "1: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 6.2ms\n",
            "2: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 6.2ms\n",
            "Speed: 2.0ms preprocess, 6.2ms inference, 1.5ms postprocess per image at shape (3, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 2 logos, 2 news-tickers, 3 texts, 5.5ms\n",
            "1: 384x640 2 logos, 2 news-tickers, 3 texts, 5.5ms\n",
            "2: 384x640 1 logo, 2 news-tickers, 3 texts, 5.5ms\n",
            "Speed: 2.0ms preprocess, 5.5ms inference, 0.9ms postprocess per image at shape (3, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 1 logo, 2 news-tickers, 3 texts, 4.5ms\n",
            "1: 384x640 1 logo, 2 news-tickers, 4 texts, 4.5ms\n",
            "2: 384x640 1 logo, 2 news-tickers, 3 texts, 4.5ms\n",
            "3: 384x640 1 logo, 2 news-tickers, 3 texts, 4.5ms\n",
            "4: 384x640 1 logo, 2 news-tickers, 3 texts, 4.5ms\n",
            "Speed: 1.8ms preprocess, 4.5ms inference, 1.0ms postprocess per image at shape (5, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 1 logo, 2 news-tickers, 3 texts, 4.6ms\n",
            "1: 384x640 1 logo, 2 news-tickers, 3 texts, 4.6ms\n",
            "2: 384x640 2 logos, 2 news-tickers, 3 texts, 4.6ms\n",
            "3: 384x640 2 logos, 2 news-tickers, 3 texts, 4.6ms\n",
            "4: 384x640 2 logos, 2 news-tickers, 4 texts, 4.6ms\n",
            "5: 384x640 2 logos, 2 news-tickers, 3 texts, 4.6ms\n",
            "Speed: 1.7ms preprocess, 4.6ms inference, 0.9ms postprocess per image at shape (6, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 2 logos, 2 news-tickers, 2 texts, 5.6ms\n",
            "1: 384x640 2 logos, 2 news-tickers, 2 texts, 5.6ms\n",
            "2: 384x640 2 logos, 2 news-tickers, 2 texts, 5.6ms\n",
            "Speed: 1.9ms preprocess, 5.6ms inference, 0.9ms postprocess per image at shape (3, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 2 logos, 2 news-tickers, 3 texts, 4.0ms\n",
            "1: 384x640 2 logos, 2 news-tickers, 3 texts, 4.0ms\n",
            "2: 384x640 2 logos, 2 news-tickers, 4 texts, 4.0ms\n",
            "3: 384x640 2 logos, 2 news-tickers, 3 texts, 4.0ms\n",
            "4: 384x640 1 logo, 2 news-tickers, 3 texts, 4.0ms\n",
            "5: 384x640 1 logo, 2 news-tickers, 2 texts, 4.0ms\n",
            "6: 384x640 1 logo, 2 news-tickers, 2 texts, 4.0ms\n",
            "7: 384x640 1 logo, 2 news-tickers, 3 texts, 4.0ms\n",
            "8: 384x640 1 logo, 2 news-tickers, 4 texts, 4.0ms\n",
            "9: 384x640 1 logo, 2 news-tickers, 3 texts, 4.0ms\n",
            "Speed: 1.7ms preprocess, 4.0ms inference, 0.8ms postprocess per image at shape (10, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 1 logo, 2 news-tickers, 3 texts, 4.8ms\n",
            "1: 384x640 1 logo, 2 news-tickers, 2 texts, 4.8ms\n",
            "2: 384x640 1 logo, 2 news-tickers, 4 texts, 4.8ms\n",
            "3: 384x640 1 logo, 2 news-tickers, 3 texts, 4.8ms\n",
            "Speed: 1.9ms preprocess, 4.8ms inference, 0.9ms postprocess per image at shape (4, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 1 logo, 2 news-tickers, 3 texts, 10.4ms\n",
            "1: 384x640 1 logo, 2 news-tickers, 3 texts, 10.4ms\n",
            "Speed: 2.1ms preprocess, 10.4ms inference, 1.5ms postprocess per image at shape (2, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 1 logo, 2 news-tickers, 3 texts, 4.1ms\n",
            "1: 384x640 1 logo, 2 news-tickers, 2 texts, 4.1ms\n",
            "2: 384x640 1 logo, 2 news-tickers, 3 texts, 4.1ms\n",
            "3: 384x640 1 logo, 2 news-tickers, 3 texts, 4.1ms\n",
            "4: 384x640 1 logo, 2 news-tickers, 3 texts, 4.1ms\n",
            "5: 384x640 1 logo, 2 news-tickers, 3 texts, 4.1ms\n",
            "6: 384x640 1 logo, 2 news-tickers, 3 texts, 4.1ms\n",
            "7: 384x640 1 logo, 2 news-tickers, 2 texts, 4.1ms\n",
            "8: 384x640 1 logo, 2 news-tickers, 4 texts, 4.1ms\n",
            "Speed: 1.7ms preprocess, 4.1ms inference, 0.8ms postprocess per image at shape (9, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 1 logo, 2 news-tickers, 3 texts, 4.8ms\n",
            "1: 384x640 1 logo, 2 news-tickers, 4 texts, 4.8ms\n",
            "2: 384x640 1 logo, 2 news-tickers, 4 texts, 4.8ms\n",
            "3: 384x640 1 logo, 2 news-tickers, 3 texts, 4.8ms\n",
            "Speed: 1.9ms preprocess, 4.8ms inference, 0.9ms postprocess per image at shape (4, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 1 logo, 2 news-tickers, 4 texts, 4.6ms\n",
            "1: 384x640 1 logo, 2 news-tickers, 4 texts, 4.6ms\n",
            "2: 384x640 1 logo, 2 news-tickers, 4 texts, 4.6ms\n",
            "3: 384x640 1 logo, 2 news-tickers, 4 texts, 4.6ms\n",
            "4: 384x640 1 logo, 2 news-tickers, 3 texts, 4.6ms\n",
            "5: 384x640 1 logo, 2 news-tickers, 4 texts, 4.6ms\n",
            "Speed: 1.8ms preprocess, 4.6ms inference, 0.8ms postprocess per image at shape (6, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 1 logo, 2 news-tickers, 4 texts, 4.8ms\n",
            "1: 384x640 1 logo, 2 news-tickers, 4 texts, 4.8ms\n",
            "2: 384x640 1 logo, 2 news-tickers, 4 texts, 4.8ms\n",
            "3: 384x640 1 logo, 2 news-tickers, 4 texts, 4.8ms\n",
            "Speed: 1.7ms preprocess, 4.8ms inference, 0.9ms postprocess per image at shape (4, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 1 logo, 1 news-ticker, 4 texts, 4.1ms\n",
            "1: 384x640 1 logo, 1 news-ticker, 4 texts, 4.1ms\n",
            "2: 384x640 1 logo, 1 news-ticker, 4 texts, 4.1ms\n",
            "3: 384x640 1 logo, 2 news-tickers, 4 texts, 4.1ms\n",
            "4: 384x640 1 logo, 2 news-tickers, 4 texts, 4.1ms\n",
            "5: 384x640 1 logo, 2 news-tickers, 4 texts, 4.1ms\n",
            "6: 384x640 1 logo, 1 news-ticker, 4 texts, 4.1ms\n",
            "7: 384x640 1 logo, 2 news-tickers, 3 texts, 4.1ms\n",
            "8: 384x640 1 logo, 2 news-tickers, 4 texts, 4.1ms\n",
            "Speed: 1.6ms preprocess, 4.1ms inference, 0.8ms postprocess per image at shape (9, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 1 logo, 2 news-tickers, 4 texts, 5.6ms\n",
            "1: 384x640 1 logo, 2 news-tickers, 3 texts, 5.6ms\n",
            "2: 384x640 1 logo, 1 news-ticker, 3 texts, 5.6ms\n",
            "Speed: 2.0ms preprocess, 5.6ms inference, 1.3ms postprocess per image at shape (3, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 1 logo, 2 news-tickers, 3 texts, 4.5ms\n",
            "1: 384x640 1 logo, 2 news-tickers, 3 texts, 4.5ms\n",
            "2: 384x640 1 logo, 2 news-tickers, 3 texts, 4.5ms\n",
            "3: 384x640 1 logo, 2 news-tickers, 3 texts, 4.5ms\n",
            "4: 384x640 1 logo, 2 news-tickers, 3 texts, 4.5ms\n",
            "Speed: 1.9ms preprocess, 4.5ms inference, 0.9ms postprocess per image at shape (5, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 1 logo, 2 news-tickers, 4 texts, 4.1ms\n",
            "1: 384x640 1 logo, 2 news-tickers, 3 texts, 4.1ms\n",
            "2: 384x640 1 logo, 2 news-tickers, 3 texts, 4.1ms\n",
            "3: 384x640 1 logo, 2 news-tickers, 3 texts, 4.1ms\n",
            "4: 384x640 1 logo, 2 news-tickers, 3 texts, 4.1ms\n",
            "5: 384x640 1 logo, 2 news-tickers, 3 texts, 4.1ms\n",
            "6: 384x640 1 logo, 2 news-tickers, 3 texts, 4.1ms\n",
            "7: 384x640 1 logo, 2 news-tickers, 3 texts, 4.1ms\n",
            "8: 384x640 1 logo, 2 news-tickers, 3 texts, 4.1ms\n",
            "Speed: 1.7ms preprocess, 4.1ms inference, 0.8ms postprocess per image at shape (9, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 1 logo, 2 news-tickers, 3 texts, 4.1ms\n",
            "1: 384x640 1 logo, 2 news-tickers, 3 texts, 4.1ms\n",
            "2: 384x640 1 logo, 2 news-tickers, 3 texts, 4.1ms\n",
            "3: 384x640 1 logo, 2 news-tickers, 3 texts, 4.1ms\n",
            "4: 384x640 1 logo, 2 news-tickers, 3 texts, 4.1ms\n",
            "5: 384x640 1 logo, 2 news-tickers, 3 texts, 4.1ms\n",
            "6: 384x640 1 logo, 2 news-tickers, 4 texts, 4.1ms\n",
            "7: 384x640 1 logo, 2 news-tickers, 4 texts, 4.1ms\n",
            "Speed: 1.7ms preprocess, 4.1ms inference, 0.8ms postprocess per image at shape (8, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 1 logo, 2 news-tickers, 4 texts, 4.8ms\n",
            "1: 384x640 1 logo, 2 news-tickers, 3 texts, 4.8ms\n",
            "2: 384x640 1 logo, 2 news-tickers, 3 texts, 4.8ms\n",
            "3: 384x640 1 logo, 2 news-tickers, 3 texts, 4.8ms\n",
            "Speed: 1.9ms preprocess, 4.8ms inference, 0.9ms postprocess per image at shape (4, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 1 logo, 2 news-tickers, 3 texts, 5.6ms\n",
            "1: 384x640 1 logo, 2 news-tickers, 2 texts, 5.6ms\n",
            "2: 384x640 1 logo, 2 news-tickers, 3 texts, 5.6ms\n",
            "Speed: 1.9ms preprocess, 5.6ms inference, 0.9ms postprocess per image at shape (3, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 1 logo, 2 news-tickers, 2 texts, 5.5ms\n",
            "1: 384x640 1 logo, 2 news-tickers, 2 texts, 5.5ms\n",
            "2: 384x640 1 logo, 3 news-tickers, 2 texts, 5.5ms\n",
            "3: 384x640 1 logo, 2 news-tickers, 2 texts, 5.5ms\n",
            "Speed: 2.0ms preprocess, 5.5ms inference, 0.9ms postprocess per image at shape (4, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 1 logo, 2 news-tickers, 2 texts, 4.1ms\n",
            "1: 384x640 1 logo, 2 news-tickers, 3 texts, 4.1ms\n",
            "2: 384x640 1 logo, 2 news-tickers, 3 texts, 4.1ms\n",
            "3: 384x640 1 logo, 2 news-tickers, 3 texts, 4.1ms\n",
            "4: 384x640 1 logo, 1 news-ticker, 4 texts, 4.1ms\n",
            "5: 384x640 1 logo, 1 news-ticker, 4 texts, 4.1ms\n",
            "6: 384x640 1 logo, 1 news-ticker, 4 texts, 4.1ms\n",
            "7: 384x640 1 logo, 2 news-tickers, 4 texts, 4.1ms\n",
            "8: 384x640 1 logo, 2 news-tickers, 4 texts, 4.1ms\n",
            "Speed: 1.7ms preprocess, 4.1ms inference, 0.8ms postprocess per image at shape (9, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 1 logo, 2 news-tickers, 3 texts, 4.6ms\n",
            "1: 384x640 1 logo, 2 news-tickers, 4 texts, 4.6ms\n",
            "2: 384x640 1 logo, 2 news-tickers, 4 texts, 4.6ms\n",
            "3: 384x640 1 logo, 2 news-tickers, 4 texts, 4.6ms\n",
            "4: 384x640 1 logo, 2 news-tickers, 4 texts, 4.6ms\n",
            "5: 384x640 1 logo, 2 news-tickers, 4 texts, 4.6ms\n",
            "Speed: 1.8ms preprocess, 4.6ms inference, 0.8ms postprocess per image at shape (6, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "1: 384x640 1 logo, 2 news-tickers, 2 texts, 3.9ms\n",
            "2: 384x640 1 logo, 2 news-tickers, 2 texts, 3.9ms\n",
            "3: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "4: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "5: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "6: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "7: 384x640 1 logo, 2 news-tickers, 4 texts, 3.9ms\n",
            "8: 384x640 1 logo, 1 news-ticker, 4 texts, 3.9ms\n",
            "9: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "10: 384x640 1 logo, 2 news-tickers, 4 texts, 3.9ms\n",
            "11: 384x640 1 logo, 2 news-tickers, 4 texts, 3.9ms\n",
            "12: 384x640 1 logo, 2 news-tickers, 4 texts, 3.9ms\n",
            "Speed: 1.6ms preprocess, 3.9ms inference, 0.8ms postprocess per image at shape (13, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 1 logo, 2 news-tickers, 4 texts, 4.8ms\n",
            "1: 384x640 1 logo, 2 news-tickers, 3 texts, 4.8ms\n",
            "2: 384x640 1 logo, 2 news-tickers, 4 texts, 4.8ms\n",
            "3: 384x640 1 logo, 1 news-ticker, 4 texts, 4.8ms\n",
            "Speed: 1.8ms preprocess, 4.8ms inference, 0.9ms postprocess per image at shape (4, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 1 logo, 2 news-tickers, 4 texts, 4.0ms\n",
            "1: 384x640 2 logos, 1 news-ticker, 4 texts, 4.0ms\n",
            "2: 384x640 2 logos, 2 news-tickers, 4 texts, 4.0ms\n",
            "3: 384x640 2 logos, 2 news-tickers, 4 texts, 4.0ms\n",
            "4: 384x640 2 logos, 2 news-tickers, 4 texts, 4.0ms\n",
            "5: 384x640 2 logos, 2 news-tickers, 4 texts, 4.0ms\n",
            "6: 384x640 2 logos, 2 news-tickers, 3 texts, 4.0ms\n",
            "7: 384x640 2 logos, 2 news-tickers, 4 texts, 4.0ms\n",
            "8: 384x640 2 logos, 2 news-tickers, 4 texts, 4.0ms\n",
            "9: 384x640 2 logos, 2 news-tickers, 3 texts, 4.0ms\n",
            "10: 384x640 2 logos, 2 news-tickers, 3 texts, 4.0ms\n",
            "11: 384x640 2 logos, 2 news-tickers, 3 texts, 4.0ms\n",
            "Speed: 1.6ms preprocess, 4.0ms inference, 0.8ms postprocess per image at shape (12, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 2 logos, 2 news-tickers, 3 texts, 4.4ms\n",
            "1: 384x640 2 logos, 2 news-tickers, 3 texts, 4.4ms\n",
            "2: 384x640 2 logos, 2 news-tickers, 3 texts, 4.4ms\n",
            "3: 384x640 2 logos, 2 news-tickers, 2 texts, 4.4ms\n",
            "4: 384x640 2 logos, 2 news-tickers, 4 texts, 4.4ms\n",
            "5: 384x640 2 logos, 2 news-tickers, 3 texts, 4.4ms\n",
            "6: 384x640 2 logos, 2 news-tickers, 2 texts, 4.4ms\n",
            "Speed: 1.9ms preprocess, 4.4ms inference, 0.8ms postprocess per image at shape (7, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 2 logos, 2 news-tickers, 3 texts, 7.9ms\n",
            "1: 384x640 2 logos, 2 news-tickers, 3 texts, 7.9ms\n",
            "Speed: 2.0ms preprocess, 7.9ms inference, 1.0ms postprocess per image at shape (2, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 2 logos, 2 news-tickers, 3 texts, 7.8ms\n",
            "1: 384x640 2 logos, 2 news-tickers, 3 texts, 7.8ms\n",
            "Speed: 2.0ms preprocess, 7.8ms inference, 1.0ms postprocess per image at shape (2, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 3 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "1: 384x640 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "2: 384x640 2 logos, 2 news-tickers, 2 texts, 3.9ms\n",
            "3: 384x640 2 logos, 1 news-ticker, 2 texts, 3.9ms\n",
            "4: 384x640 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "5: 384x640 2 logos, 1 news-ticker, 3 texts, 3.9ms\n",
            "6: 384x640 2 logos, 2 news-tickers, 4 texts, 3.9ms\n",
            "7: 384x640 2 logos, 2 news-tickers, 4 texts, 3.9ms\n",
            "8: 384x640 2 logos, 2 news-tickers, 4 texts, 3.9ms\n",
            "9: 384x640 2 logos, 1 news-ticker, 4 texts, 3.9ms\n",
            "Speed: 1.6ms preprocess, 3.9ms inference, 0.8ms postprocess per image at shape (10, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 2 logos, 2 news-tickers, 4 texts, 8.0ms\n",
            "1: 384x640 2 logos, 2 news-tickers, 3 texts, 8.0ms\n",
            "Speed: 2.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (2, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 2 logos, 2 news-tickers, 4 texts, 5.6ms\n",
            "1: 384x640 2 logos, 2 news-tickers, 3 texts, 5.6ms\n",
            "2: 384x640 2 logos, 2 news-tickers, 4 texts, 5.6ms\n",
            "Speed: 1.8ms preprocess, 5.6ms inference, 0.9ms postprocess per image at shape (3, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 2 logos, 2 news-tickers, 3 texts, 4.1ms\n",
            "1: 384x640 2 logos, 2 news-tickers, 4 texts, 4.1ms\n",
            "2: 384x640 2 logos, 2 news-tickers, 3 texts, 4.1ms\n",
            "3: 384x640 2 logos, 2 news-tickers, 4 texts, 4.1ms\n",
            "4: 384x640 2 logos, 3 news-tickers, 4 texts, 4.1ms\n",
            "5: 384x640 2 logos, 2 news-tickers, 3 texts, 4.1ms\n",
            "6: 384x640 2 logos, 1 news-ticker, 3 texts, 4.1ms\n",
            "7: 384x640 2 logos, 2 news-tickers, 3 texts, 4.1ms\n",
            "8: 384x640 2 logos, 2 news-tickers, 4 texts, 4.1ms\n",
            "Speed: 1.6ms preprocess, 4.1ms inference, 0.8ms postprocess per image at shape (9, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 2 logos, 2 news-tickers, 4 texts, 4.1ms\n",
            "1: 384x640 2 logos, 2 news-tickers, 4 texts, 4.1ms\n",
            "2: 384x640 2 logos, 2 news-tickers, 4 texts, 4.1ms\n",
            "3: 384x640 2 logos, 2 news-tickers, 4 texts, 4.1ms\n",
            "4: 384x640 2 logos, 2 news-tickers, 3 texts, 4.1ms\n",
            "5: 384x640 2 logos, 2 news-tickers, 2 texts, 4.1ms\n",
            "6: 384x640 2 logos, 2 news-tickers, 2 texts, 4.1ms\n",
            "7: 384x640 2 logos, 2 news-tickers, 4 texts, 4.1ms\n",
            "Speed: 1.7ms preprocess, 4.1ms inference, 0.8ms postprocess per image at shape (8, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 2 logos, 2 news-tickers, 3 texts, 7.7ms\n",
            "1: 384x640 2 logos, 2 news-tickers, 3 texts, 7.7ms\n",
            "Speed: 1.9ms preprocess, 7.7ms inference, 1.0ms postprocess per image at shape (2, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 2 logos, 2 news-tickers, 4 texts, 8.3ms\n",
            "1: 384x640 2 logos, 2 news-tickers, 2 texts, 8.3ms\n",
            "2: 384x640 2 logos, 2 news-tickers, 3 texts, 8.3ms\n",
            "Speed: 2.0ms preprocess, 8.3ms inference, 0.9ms postprocess per image at shape (3, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "\n",
            "0: 384x640 2 logos, 2 news-tickers, 3 texts, 4.5ms\n",
            "1: 384x640 2 logos, 2 news-tickers, 3 texts, 4.5ms\n",
            "2: 384x640 2 logos, 2 news-tickers, 3 texts, 4.5ms\n",
            "3: 384x640 2 logos, 2 news-tickers, 3 texts, 4.5ms\n",
            "4: 384x640 2 logos, 2 news-tickers, 3 texts, 4.5ms\n",
            "Speed: 1.8ms preprocess, 4.5ms inference, 0.9ms postprocess per image at shape (5, 3, 384, 640)\n",
            "✅ Final Safe Zone: shifted_middle3\n",
            "shifted_middle3\n",
            "[{'start': 0.45, 'end': 1.08, 'text': 'THE FOX 5 NEWS AT ONE', 'region': 'shifted_middle3'}, {'start': 1.08, 'end': 5.29, 'text': 'SPONSORED BY VALLEY VIEW', 'region': 'middle3'}, {'start': 5.29, 'end': 6.49, 'text': 'CASINO AND HOTEL.', 'region': 'shifted_middle3'}, {'start': 6.49, 'end': 7.69, 'text': 'IS OUT OF SHELTER ISLAND', 'region': 'shifted_middle3'}, {'start': 7.69, 'end': 9.46, 'text': 'WHERE A MILITARY JET CRASHED', 'region': 'shifted_middle3'}, {'start': 9.46, 'end': 10.63, 'text': \"INTO THE SAN DIEGO BAY. I'M\", 'region': 'shifted_middle3'}, {'start': 10.63, 'end': 11.73, 'text': \"KRISTINA AUDENCIAL AND I'M\", 'region': 'shifted_middle3'}, {'start': 11.73, 'end': 13.6, 'text': 'PHIL BLAUER. THIS HAPPENED', 'region': 'shifted_middle3'}, {'start': 13.6, 'end': 16.53, 'text': 'JUST AFTER 10:00AM ON THE', 'region': 'middle3'}, {'start': 16.53, 'end': 17.43, 'text': 'NORTH SIDE OF SHELTER ISLAND.', 'region': 'shifted_middle3'}, {'start': 17.43, 'end': 18.3, 'text': 'THE KONA KAI RESORT POINT', 'region': 'shifted_middle3'}, {'start': 18.3, 'end': 20.64, 'text': 'LOMA. BOTH PILOTS SAFELY', 'region': 'middle3'}, {'start': 20.64, 'end': 21.8, 'text': 'EJECTED FROM THE DA 18 DRY', 'region': 'shifted_middle3'}, {'start': 21.8, 'end': 23.64, 'text': 'LAIR JUST BEFORE IT CRASHED', 'region': 'shifted_middle3'}, {'start': 23.64, 'end': 24.57, 'text': 'INTO THE WATER. WE DO CREWS AT', 'region': 'shifted_middle3'}, {'start': 24.57, 'end': 25.21, 'text': 'THE SCENE OF THE CRASH AND THE', 'region': 'shifted_middle3'}, {'start': 25.21, 'end': 27.58, 'text': 'HOSPITAL WERE 2 PILOTS ARE', 'region': 'shifted_middle3'}, {'start': 27.58, 'end': 28.74, 'text': 'BEING TREATED RIGHT NOW. WE', 'region': 'shifted_middle3'}, {'start': 28.74, 'end': 31.31, 'text': 'BEGIN WITH OUR ZARA BARKER', 'region': 'shifted_middle3'}, {'start': 31.31, 'end': 31.91, 'text': \"WHO'S GATHERING THE LATEST\", 'region': 'shifted_middle3'}, {'start': 31.91, 'end': 32.55, 'text': 'DETAILS FROM POLICE AND', 'region': 'shifted_middle3'}, {'start': 32.55, 'end': 37.42, 'text': 'FIREFIGHTERS ON SHELTER', 'region': 'shifted_middle3'}, {'start': 37.42, 'end': 38.12, 'text': 'ISLAND. THERE.', 'region': 'shifted_middle3'}, {'start': 38.12, 'end': 39.32, 'text': 'CHRISTINA HILL RIGHT HERE', 'region': 'shifted_middle3'}, {'start': 39.32, 'end': 40.62, 'text': \"WHERE I'M STANDING IS ON THE\", 'region': 'shifted_middle3'}, {'start': 40.62, 'end': 42.36, 'text': 'MOST SOUTHWEST POINT A SHELTER', 'region': 'shifted_middle3'}, {'start': 42.36, 'end': 44.56, 'text': 'ISLAND AND BEHIND ME IS WHERE', 'region': 'shifted_middle3'}, {'start': 44.56, 'end': 47.46, 'text': 'THAT MILITARY JET ENDED UP', 'region': 'shifted_middle3'}, {'start': 47.46, 'end': 48.46, 'text': 'NOSE DIVING INTO THE SAN DIEGO', 'region': 'shifted_middle3'}, {'start': 48.46, 'end': 49.5, 'text': 'BAY. PEOPLE I TALKED TO SAID', 'region': 'shifted_middle3'}, {'start': 49.5, 'end': 50.23, 'text': 'THAT THEY HEARD THIS JET', 'region': 'shifted_middle3'}, {'start': 50.23, 'end': 54.47, 'text': 'FLYING BY AND THEN AS SOON AS', 'region': 'shifted_middle3'}, {'start': 54.47, 'end': 56.54, 'text': 'THEY HEARD A POP JUST WHEN IT', 'region': 'shifted_middle3'}, {'start': 56.54, 'end': 59.37, 'text': 'WENT SILENT AND THAT JET', 'region': 'shifted_middle3'}, {'start': 59.37, 'end': 60.41, 'text': 'NOSEDIVED INTO THE WATER, AS', 'region': 'shifted_middle3'}, {'start': 60.41, 'end': 61.14, 'text': 'YOU SAID, THOSE 2 PILOTS WERE', 'region': 'shifted_middle3'}, {'start': 61.14, 'end': 62.71, 'text': 'ABLE TO EJECT. THEY LANDED', 'region': 'shifted_middle3'}, {'start': 62.71, 'end': 64.68, 'text': 'INTO THE WATER AND WERE TAKEN', 'region': 'shifted_middle3'}, {'start': 64.68, 'end': 65.41, 'text': 'OUT OF THE WATER BY FISHING', 'region': 'shifted_middle3'}, {'start': 65.41, 'end': 68.72, 'text': 'BOAT. THAT JUST HAPPENED TO BE', 'region': 'shifted_middle3'}, {'start': 68.72, 'end': 69.92, 'text': 'IN THE AREA NEARBY WERE ALSO', 'region': 'shifted_middle3'}, {'start': 69.92, 'end': 70.62, 'text': 'TOLD THAT HARBOR POLICE AND', 'region': 'shifted_middle3'}, {'start': 70.62, 'end': 73.66, 'text': 'THE COAST GUARD WERE ACTIVATED', 'region': 'shifted_middle3'}, {'start': 73.66, 'end': 74.89, 'text': 'AND WERE SENT HERE AT THAT', 'region': 'shifted_middle3'}, {'start': 74.89, 'end': 76.69, 'text': 'MOMENT TO HELP. DO WANT TO', 'region': 'shifted_middle3'}, {'start': 76.69, 'end': 77.93, 'text': \"POINT OUT THAT WE DON'T\", 'region': 'shifted_middle3'}, {'start': 77.93, 'end': 80.66, 'text': 'EXACTLY WHAT LED UP TO THIS', 'region': 'shifted_middle3'}, {'start': 80.66, 'end': 81.66, 'text': 'CRASH AT THIS POINT THAT THE', 'region': 'shifted_middle3'}, {'start': 81.66, 'end': 83.33, 'text': 'VISIBILITY AND THE CONDITIONS', 'region': 'shifted_middle3'}, {'start': 83.33, 'end': 86.37, 'text': 'ARE VERY BRUTAL FOR RIGHT NOW.', 'region': 'shifted_middle3'}, {'start': 86.37, 'end': 88.8, 'text': \"OUT HERE. WE'RE EXPERIENCING\", 'region': 'shifted_middle3'}, {'start': 88.8, 'end': 89.91, 'text': 'SOME EXTREMELY HEAVY WIND', 'region': 'shifted_middle3'}, {'start': 89.91, 'end': 90.91, 'text': 'RIGHT NOW. AND WE DID HAVE', 'region': 'shifted_middle3'}, {'start': 90.91, 'end': 92.11, 'text': 'MUCH MORE RAIN WHEN THEY GOT', 'region': 'shifted_middle3'}, {'start': 92.11, 'end': 95.08, 'text': 'HERE ABOUT AN HOUR AND A HALF', 'region': 'shifted_middle3'}, {'start': 95.08, 'end': 96.98, 'text': 'JUST A LITTLE BIT AND WE ARE', 'region': 'shifted_middle3'}, {'start': 96.98, 'end': 101.05, 'text': 'STILL DEALING WITH THAT', 'region': 'shifted_middle3'}, {'start': 101.05, 'end': 102.35, 'text': \"TO SHOW YOU EXACTLY WHAT WE'RE\", 'region': 'shifted_middle3'}, {'start': 102.35, 'end': 106.35, 'text': 'SEEING RIGHT HERE BEHIND ME IS', 'region': 'shifted_middle3'}, {'start': 106.35, 'end': 108.72, 'text': 'WHERE THAT PLANE WENT DOWN.', 'region': 'shifted_middle3'}, {'start': 108.72, 'end': 109.36, 'text': 'AND YOU CAN SEE THOSE THOSE', 'region': 'shifted_middle3'}, {'start': 109.36, 'end': 110.06, 'text': 'CONTAINMENT LINES THAT WE', 'region': 'shifted_middle3'}, {'start': 110.06, 'end': 113.23, 'text': 'PUTTING INTO THE WATER JUST', 'region': 'shifted_middle3'}, {'start': 113.23, 'end': 113.93, 'text': 'ABOUT AN HOUR AGO.', 'region': 'shifted_middle3'}, {'start': 113.93, 'end': 114.66, 'text': \"WE CAN'T SEE THE PLANE IN\", 'region': 'shifted_middle3'}, {'start': 114.66, 'end': 117.43, 'text': 'THE WATER RIGHT NOW, BUT WE DO', 'region': 'shifted_middle3'}, {'start': 117.43, 'end': 120.14, 'text': 'KNOW THAT THEY ARE WITHIN', 'region': 'shifted_middle3'}, {'start': 120.14, 'end': 120.84, 'text': 'ORANGE CONTAINMENT FILM. THEY', 'region': 'shifted_middle3'}, {'start': 120.84, 'end': 121.57, 'text': 'PUT THE FIGURE AT KEEPING THE', 'region': 'shifted_middle3'}, {'start': 121.57, 'end': 124.87, 'text': 'OIL INFLUENCE FROM THE FLAMES', 'region': None}, {'start': 124.87, 'end': 125.87, 'text': 'COASTLINE. ALSO BECAUSE WHERE', 'region': None}, {'start': 125.87, 'end': 128.11, 'text': 'THIS JET WENT DOWN IS JUST', 'region': None}, {'start': 128.11, 'end': 129.74, 'text': 'FEET AWAY FROM WHERE THE', 'region': None}, {'start': 129.74, 'end': 131.08, 'text': \"NAVY'S DOLPHINS AND SEA LIONS\", 'region': None}, {'start': 131.08, 'end': 132.48, 'text': \"STRAIN. THIS IS WHERE THEY'RE\", 'region': None}, {'start': 132.48, 'end': 133.18, 'text': 'HELD IN. THIS IS THEIR', 'region': None}, {'start': 133.18, 'end': 133.82, 'text': 'TRAINING AREA. NOT SURE YOU', 'region': None}, {'start': 133.82, 'end': 138.19, 'text': \"CAN SEE FROM WHERE WE'RE\", 'region': None}, {'start': 138.19, 'end': 139.99, 'text': 'STANDING, BUT BOAT THAT ARE', 'region': None}, {'start': 139.99, 'end': 141.29, 'text': 'FARTHER OFF IN THE DISTANCE.', 'region': None}, {'start': 141.29, 'end': 143.12, 'text': 'THEY ALL TURNED THEIR ENGINES', 'region': None}, {'start': 143.12, 'end': 145.43, 'text': \"ON. AND WE'RE TOLD THAT IT'S\", 'region': None}, {'start': 145.43, 'end': 148.03, 'text': 'LIKELY TO TRY AND KEEP ANY', 'region': None}, {'start': 148.03, 'end': 149.03, 'text': 'OIL, FLUIDS FROM GETTING AS', 'region': None}, {'start': 149.03, 'end': 150.37, 'text': 'CLOSE TO DOLPHINS AND SEA', 'region': None}, {'start': 150.37, 'end': 152.17, 'text': 'LIONS THAT THAT THAT HELP', 'region': None}, {'start': 152.17, 'end': 153.4, 'text': \"TRAIN THE NAVY, THEY'RE\", 'region': None}, {'start': 153.4, 'end': 155.0, 'text': 'TURNING TO. THEY CAN PUSH THE', 'region': None}, {'start': 155.0, 'end': 156.81, 'text': 'AWAY FROM THOSE MARINE LIFE', 'region': None}, {'start': 156.81, 'end': 157.54, 'text': 'THAT WE DID. JUST TALK TO', 'region': None}, {'start': 157.54, 'end': 161.08, 'text': 'SOMEONE WHO AND SAW THIS CRASH', 'region': None}, {'start': 161.08, 'end': 161.81, 'text': 'MOMENTS AGO.', 'region': None}, {'start': 161.81, 'end': 165.91, 'text': 'THE FLY OVERHEAD EVERY DAY.', 'region': None}, {'start': 165.91, 'end': 166.55, 'text': \"HE TAKEN OFF. WE'RE FACED. AND\", 'region': None}, {'start': 166.55, 'end': 170.39, 'text': 'THIS MORNING, THEY LIKE', 'region': None}, {'start': 170.39, 'end': 171.12, 'text': \"THEY'RE AND THIS IS THE FIRST\", 'region': None}, {'start': 171.12, 'end': 174.19, 'text': 'ONE CAME GOT MY ATTENTION. I', 'region': None}, {'start': 174.19, 'end': 177.83, 'text': 'LOOKED AT MY CORE. IN SAVING', 'region': None}, {'start': 177.83, 'end': 178.59, 'text': 'CLOUD COVERAGE. AND THEN THE', 'region': None}, {'start': 178.59, 'end': 181.41, 'text': 'NEXT ONE THAT CAME 15 SECONDS', 'region': None}, {'start': 183.83, 'end': 184.57, 'text': 'LATER. AND HE WAS A LITTLE BIT', 'region': None}, {'start': 184.57, 'end': 188.97, 'text': 'LOWER. AND RIGHT WHEN I TRYING', 'region': None}, {'start': 188.97, 'end': 189.7, 'text': \"TO GET MY CAR SEE POWELL. IT'S\", 'region': None}, {'start': 189.7, 'end': 192.52, 'text': 'I HEARD HIM THE ENGINE, SHIFTY', 'region': None}, {'start': 198.45, 'end': 199.11, 'text': 'THAT, WE DID. PARK. AND TOP', 'region': None}, {'start': 199.11, 'end': 201.12, 'text': 'MANY WAYS THAT CAN STEER. IT', 'region': None}, {'start': 201.12, 'end': 205.19, 'text': \"WASN'T A GUEST. IS A THING\", 'region': None}, {'start': 205.19, 'end': 208.01, 'text': 'STARTED GO UP. BUT THEN THE', 'region': None}, {'start': 212.66, 'end': 213.66, 'text': 'DEBRIS FALLING FROM WHAT ARE', 'region': None}, {'start': 213.66, 'end': 215.0, 'text': 'AND WE DO KNOW THAT ABOUT', 'region': None}, {'start': 215.0, 'end': 216.03, 'text': '60 UNITS OF FIRST RESPONDERS', 'region': None}, {'start': 216.03, 'end': 216.83, 'text': 'HAVE BEEN ASSIGNED TO THIS', 'region': None}, {'start': 216.83, 'end': 218.87, 'text': 'INCIDENT RIGHT NOW. THAT', 'region': None}, {'start': 218.87, 'end': 219.97, 'text': 'INCLUDES THE COAST GUARD NAVY', 'region': None}, {'start': 219.97, 'end': 221.94, 'text': 'LEAVE AND HOW TO U.S. CUSTOMS', 'region': None}, {'start': 221.94, 'end': 224.27, 'text': 'AND BORDER PROTECTION BOAT.', 'region': None}, {'start': 224.27, 'end': 225.01, 'text': 'ARBOR. POLICE HAVE SHUTDOWN', 'region': None}, {'start': 225.01, 'end': 228.31, 'text': 'SHELTER ISLAND DRIVE, WHICH IS', 'region': None}, {'start': 228.31, 'end': 230.05, 'text': 'THE ROVER STANDING RIGHT HERE', 'region': None}, {'start': 230.05, 'end': 231.58, 'text': 'NOW. BUT IT WAS REOPENED JUST', 'region': None}, {'start': 231.58, 'end': 234.15, 'text': 'ABOUT THE LAST 30 MINUTES THAT', 'region': None}, {'start': 234.15, 'end': 236.48, 'text': 'WE SEEING A STEADY FLOW OF', 'region': None}, {'start': 236.48, 'end': 238.15, 'text': 'CARS COMING INTO THIS AREA AT', 'region': None}, {'start': 238.15, 'end': 239.29, 'text': 'THE VERY LATEST HERE LIVE FROM', 'region': None}, {'start': 239.29, 'end': 241.16, 'text': 'SHELTER ISLAND, ZARA BARKER', 'region': None}, {'start': 241.16, 'end': 243.22, 'text': 'FOX, 5 THANK YOU FOR THAT.', 'region': None}, {'start': 243.22, 'end': 244.09, 'text': \"HUSTLE. LET'S CHECK IN NOW.\", 'region': None}, {'start': 244.09, 'end': 246.16, 'text': \"IT'S HERE AND SEE. THIS IS\", 'region': None}, {'start': 246.16, 'end': 246.9, 'text': 'LIVE AT UC SAN DIEGO HILLCREST', 'region': None}, {'start': 246.9, 'end': 248.23, 'text': 'WHERE THE PILOTS ARE BEING', 'region': None}, {'start': 248.23, 'end': 248.96, 'text': 'TREATED AFTER BEING EJECTED', 'region': None}, {'start': 248.96, 'end': 251.78, 'text': \"FROM THE PLANE. CR. WHAT'S THE\", 'region': None}, {'start': 254.67, 'end': 255.37, 'text': 'LATEST?', 'region': None}, {'start': 255.37, 'end': 258.04, 'text': 'PRISTINA, THE NAVY TOLD ME', 'region': None}, {'start': 258.04, 'end': 259.81, 'text': 'THAT THE 2 PILOTS ARE IN', 'region': None}, {'start': 259.81, 'end': 261.91, 'text': 'STABLE CONDITION. DIEGO FIRE', 'region': None}, {'start': 261.91, 'end': 264.75, 'text': 'RESCUE TRANSPORTED THOSE 2', 'region': None}, {'start': 264.75, 'end': 265.55, 'text': 'MEDICAL CENTER HERE HILLCREST.', 'region': None}, {'start': 265.55, 'end': 268.42, 'text': 'WE SPOKE TO A COUPLE OF NURSES', 'region': None}, {'start': 268.42, 'end': 269.38, 'text': 'WALKING DOWN THE STREET HERE', 'region': None}, {'start': 269.38, 'end': 272.39, 'text': 'ABOUT 30 MINUTES TO AN HOUR,', 'region': None}, {'start': 272.39, 'end': 274.19, 'text': 'THOUGH. THEY THINK THAT THEY', 'region': None}, {'start': 274.19, 'end': 275.39, 'text': 'TEND TO GET THE MILITARY', 'region': None}, {'start': 275.39, 'end': 276.59, 'text': 'STRONGEST PATIENTS TRANSPORTED', 'region': None}, {'start': 276.59, 'end': 277.23, 'text': \"OVER HERE. NOW THAT DOESN'T\", 'region': None}, {'start': 277.23, 'end': 278.06, 'text': 'HAVE ANY DETAILS ON THE', 'region': None}, {'start': 278.06, 'end': 279.79, 'text': 'PILOTS, THEY HAVE NOT YET', 'region': None}, {'start': 279.79, 'end': 281.76, 'text': 'RELEASED THE NAMES OF THE', 'region': None}, {'start': 281.76, 'end': 283.83, 'text': 'PILOTS, BUT THEY DO SAY THAT', 'region': None}, {'start': 283.83, 'end': 285.07, 'text': 'THEY WERE INTEL FROM', 'region': None}, {'start': 285.07, 'end': 286.84, 'text': 'WASHINGTON FOR A TRAINING', 'region': None}, {'start': 286.84, 'end': 288.84, 'text': 'EXERCISE AT NAVAL AIR STATION,', 'region': None}, {'start': 288.84, 'end': 290.97, 'text': 'NORTH ISLAND. NO, THEY WERE ON', 'region': None}, {'start': 290.97, 'end': 294.84, 'text': 'GROWLER WHEN IT WENT DOWN. IT', 'region': None}, {'start': 294.84, 'end': 296.11, 'text': 'SAID THERE THAT WERE RESCUED', 'region': None}, {'start': 296.11, 'end': 296.75, 'text': 'BY THAT FISHING BOATS ARE', 'region': None}, {'start': 296.75, 'end': 300.88, 'text': 'STILL WORKING TO GATHER', 'region': None}, {'start': 300.88, 'end': 301.58, 'text': 'DETAILS HERE TODAY. WE DID SEE', 'region': None}, {'start': 301.58, 'end': 302.25, 'text': '70 PERSONNEL WALKING TO THE', 'region': None}, {'start': 302.25, 'end': 304.13, 'text': \"HOSPITAL EARLIER THAT'S THE\", 'region': None}]\n",
            "<tt xmlns=\"http://www.w3.org/ns/ttml\" xmlns:ttm=\"http://www.w3.org/ns/ttml#metadata\" xmlns:ttp=\"http://www.w3.org/ns/ttml#parameter\" xmlns:tts=\"http://www.w3.org/ns/ttml#styling\" ttp:timeBase=\"media\" xml:lang=\"en\">\n",
            "  <head>\n",
            "    <metadata>\n",
            "      <ttm:title />\n",
            "    </metadata>\n",
            "    <styling>\n",
            "      <style xml:id=\"s0\" tts:backgroundColor=\"black\" tts:fontStyle=\"normal\" tts:fontSize=\"16px\" tts:fontFamily=\"sansSerif\" tts:color=\"white\" />\n",
            "    </styling>\n",
            "    <layout>\n",
            "      <region tts:extent=\"80% 40%\" tts:origin=\"10% 10%\" tts:displayAlign=\"before\" tts:textAlign=\"start\" xml:id=\"topLeft\" />\n",
            "      <region tts:extent=\"80% 40%\" tts:origin=\"10% 30%\" tts:displayAlign=\"center\" tts:textAlign=\"start\" xml:id=\"centerLeft\" />\n",
            "      <region tts:extent=\"80% 40%\" tts:origin=\"10% 50%\" tts:displayAlign=\"after\" tts:textAlign=\"start\" xml:id=\"bottomLeft\" />\n",
            "      <region tts:extent=\"80% 40%\" tts:origin=\"10% 10%\" tts:displayAlign=\"before\" tts:textAlign=\"center\" xml:id=\"topCenter\" />\n",
            "      <region tts:extent=\"80% 40%\" tts:origin=\"10% 30%\" tts:displayAlign=\"center\" tts:textAlign=\"center\" xml:id=\"centerСenter\" />\n",
            "      <region tts:extent=\"80% 40%\" tts:origin=\"10% 50%\" tts:displayAlign=\"after\" tts:textAlign=\"center\" xml:id=\"bottomCenter\" />\n",
            "      <region tts:extent=\"80% 40%\" tts:origin=\"10% 10%\" tts:displayAlign=\"before\" tts:textAlign=\"end\" xml:id=\"topRight\" />\n",
            "      <region tts:extent=\"80% 40%\" tts:origin=\"10% 30%\" tts:displayAlign=\"center\" tts:textAlign=\"end\" xml:id=\"centerRight\" />\n",
            "      <region tts:extent=\"80% 40%\" tts:origin=\"10% 50%\" tts:displayAlign=\"after\" tts:textAlign=\"end\" xml:id=\"bottomRight\" />\n",
            "    </layout>\n",
            "  </head>\n",
            "  <body style=\"s0\">\n",
            "    <div>\n",
            "      <p begin=\"0.45s\" xml:id=\"p0\" end=\"1.08s\" region=\"shifted_middle3\">THE FOX 5 NEWS AT ONE</p>\n",
            "      <p begin=\"1.08s\" xml:id=\"p1\" end=\"5.29s\" region=\"shifted_middle3\">SPONSORED BY VALLEY VIEW</p>\n",
            "      <p begin=\"5.29s\" xml:id=\"p2\" end=\"6.49s\" region=\"middle3\">CASINO AND HOTEL.</p>\n",
            "      <p begin=\"6.49s\" xml:id=\"p3\" end=\"7.69s\" region=\"shifted_middle3\">IS OUT OF SHELTER ISLAND</p>\n",
            "      <p begin=\"7.69s\" xml:id=\"p4\" end=\"9.46s\" region=\"shifted_middle3\">WHERE A MILITARY JET CRASHED</p>\n",
            "      <p begin=\"9.46s\" xml:id=\"p5\" end=\"10.63s\" region=\"shifted_middle3\">INTO THE SAN DIEGO BAY. I'M</p>\n",
            "      <p begin=\"10.63s\" xml:id=\"p6\" end=\"11.73s\" region=\"shifted_middle3\">KRISTINA AUDENCIAL AND I'M</p>\n",
            "      <p begin=\"11.73s\" xml:id=\"p7\" end=\"13.6s\" region=\"shifted_middle3\">PHIL BLAUER. THIS HAPPENED</p>\n",
            "      <p begin=\"13.6s\" xml:id=\"p8\" end=\"16.53s\" region=\"shifted_middle3\">JUST AFTER 10:00AM ON THE</p>\n",
            "      <p begin=\"16.53s\" xml:id=\"p9\" end=\"17.43s\" region=\"middle3\">NORTH SIDE OF SHELTER ISLAND.</p>\n",
            "      <p begin=\"17.43s\" xml:id=\"p10\" end=\"18.3s\" region=\"shifted_middle3\">THE KONA KAI RESORT POINT</p>\n",
            "      <p begin=\"18.3s\" xml:id=\"p11\" end=\"20.64s\" region=\"shifted_middle3\">LOMA. BOTH PILOTS SAFELY</p>\n",
            "      <p begin=\"20.64s\" xml:id=\"p12\" end=\"21.8s\" region=\"middle3\">EJECTED FROM THE DA 18 DRY</p>\n",
            "      <p begin=\"21.8s\" xml:id=\"p13\" end=\"23.64s\" region=\"shifted_middle3\">LAIR JUST BEFORE IT CRASHED</p>\n",
            "      <p begin=\"23.64s\" xml:id=\"p14\" end=\"24.57s\" region=\"shifted_middle3\">INTO THE WATER. WE DO CREWS AT</p>\n",
            "      <p begin=\"24.57s\" xml:id=\"p15\" end=\"25.21s\" region=\"shifted_middle3\">THE SCENE OF THE CRASH AND THE</p>\n",
            "      <p begin=\"25.21s\" xml:id=\"p16\" end=\"27.58s\" region=\"shifted_middle3\">HOSPITAL WERE 2 PILOTS ARE</p>\n",
            "      <p begin=\"27.58s\" xml:id=\"p17\" end=\"28.74s\" region=\"shifted_middle3\">BEING TREATED RIGHT NOW. WE</p>\n",
            "      <p begin=\"28.74s\" xml:id=\"p18\" end=\"31.31s\" region=\"shifted_middle3\">BEGIN WITH OUR ZARA BARKER</p>\n",
            "      <p begin=\"31.31s\" xml:id=\"p19\" end=\"31.91s\" region=\"shifted_middle3\">WHO'S GATHERING THE LATEST</p>\n",
            "      <p begin=\"31.91s\" xml:id=\"p20\" end=\"32.55s\" region=\"shifted_middle3\">DETAILS FROM POLICE AND</p>\n",
            "      <p begin=\"32.55s\" xml:id=\"p21\" end=\"37.42s\" region=\"shifted_middle3\">FIREFIGHTERS ON SHELTER</p>\n",
            "      <p begin=\"37.42s\" xml:id=\"p22\" end=\"38.12s\" region=\"shifted_middle3\">ISLAND. THERE.</p>\n",
            "      <p begin=\"38.12s\" xml:id=\"p23\" end=\"39.32s\" region=\"shifted_middle3\">CHRISTINA HILL RIGHT HERE</p>\n",
            "      <p begin=\"39.32s\" xml:id=\"p24\" end=\"40.62s\" region=\"shifted_middle3\">WHERE I'M STANDING IS ON THE</p>\n",
            "      <p begin=\"40.62s\" xml:id=\"p25\" end=\"42.36s\" region=\"shifted_middle3\">MOST SOUTHWEST POINT A SHELTER</p>\n",
            "      <p begin=\"42.36s\" xml:id=\"p26\" end=\"44.56s\" region=\"shifted_middle3\">ISLAND AND BEHIND ME IS WHERE</p>\n",
            "      <p begin=\"44.56s\" xml:id=\"p27\" end=\"47.46s\" region=\"shifted_middle3\">THAT MILITARY JET ENDED UP</p>\n",
            "      <p begin=\"47.46s\" xml:id=\"p28\" end=\"48.46s\" region=\"shifted_middle3\">NOSE DIVING INTO THE SAN DIEGO</p>\n",
            "      <p begin=\"48.46s\" xml:id=\"p29\" end=\"49.5s\" region=\"shifted_middle3\">BAY. PEOPLE I TALKED TO SAID</p>\n",
            "      <p begin=\"49.5s\" xml:id=\"p30\" end=\"50.23s\" region=\"shifted_middle3\">THAT THEY HEARD THIS JET</p>\n",
            "      <p begin=\"50.23s\" xml:id=\"p31\" end=\"54.47s\" region=\"shifted_middle3\">FLYING BY AND THEN AS SOON AS</p>\n",
            "      <p begin=\"54.47s\" xml:id=\"p32\" end=\"56.54s\" region=\"shifted_middle3\">THEY HEARD A POP JUST WHEN IT</p>\n",
            "      <p begin=\"56.54s\" xml:id=\"p33\" end=\"59.37s\" region=\"shifted_middle3\">WENT SILENT AND THAT JET</p>\n",
            "      <p begin=\"59.37s\" xml:id=\"p34\" end=\"60.41s\" region=\"shifted_middle3\">NOSEDIVED INTO THE WATER, AS</p>\n",
            "      <p begin=\"60.41s\" xml:id=\"p35\" end=\"61.14s\" region=\"shifted_middle3\">YOU SAID, THOSE 2 PILOTS WERE</p>\n",
            "      <p begin=\"61.14s\" xml:id=\"p36\" end=\"62.71s\" region=\"shifted_middle3\">ABLE TO EJECT. THEY LANDED</p>\n",
            "      <p begin=\"62.71s\" xml:id=\"p37\" end=\"64.68s\" region=\"shifted_middle3\">INTO THE WATER AND WERE TAKEN</p>\n",
            "      <p begin=\"64.68s\" xml:id=\"p38\" end=\"65.41s\" region=\"shifted_middle3\">OUT OF THE WATER BY FISHING</p>\n",
            "      <p begin=\"65.41s\" xml:id=\"p39\" end=\"68.72s\" region=\"shifted_middle3\">BOAT. THAT JUST HAPPENED TO BE</p>\n",
            "      <p begin=\"68.72s\" xml:id=\"p40\" end=\"69.92s\" region=\"shifted_middle3\">IN THE AREA NEARBY WERE ALSO</p>\n",
            "      <p begin=\"69.92s\" xml:id=\"p41\" end=\"70.62s\" region=\"shifted_middle3\">TOLD THAT HARBOR POLICE AND</p>\n",
            "      <p begin=\"70.62s\" xml:id=\"p42\" end=\"73.66s\" region=\"shifted_middle3\">THE COAST GUARD WERE ACTIVATED</p>\n",
            "      <p begin=\"73.66s\" xml:id=\"p43\" end=\"74.89s\" region=\"shifted_middle3\">AND WERE SENT HERE AT THAT</p>\n",
            "      <p begin=\"74.89s\" xml:id=\"p44\" end=\"76.69s\" region=\"shifted_middle3\">MOMENT TO HELP. DO WANT TO</p>\n",
            "      <p begin=\"76.69s\" xml:id=\"p45\" end=\"77.93s\" region=\"shifted_middle3\">POINT OUT THAT WE DON'T</p>\n",
            "      <p begin=\"77.93s\" xml:id=\"p46\" end=\"80.66s\" region=\"shifted_middle3\">EXACTLY WHAT LED UP TO THIS</p>\n",
            "      <p begin=\"80.66s\" xml:id=\"p47\" end=\"81.66s\" region=\"shifted_middle3\">CRASH AT THIS POINT THAT THE</p>\n",
            "      <p begin=\"81.66s\" xml:id=\"p48\" end=\"83.33s\" region=\"shifted_middle3\">VISIBILITY AND THE CONDITIONS</p>\n",
            "      <p begin=\"83.33s\" xml:id=\"p49\" end=\"86.37s\" region=\"shifted_middle3\">ARE VERY BRUTAL FOR RIGHT NOW.</p>\n",
            "      <p begin=\"86.37s\" xml:id=\"p50\" end=\"88.8s\" region=\"shifted_middle3\">OUT HERE. WE'RE EXPERIENCING</p>\n",
            "      <p begin=\"88.8s\" xml:id=\"p51\" end=\"89.91s\" region=\"shifted_middle3\">SOME EXTREMELY HEAVY WIND</p>\n",
            "      <p begin=\"89.91s\" xml:id=\"p52\" end=\"90.91s\" region=\"shifted_middle3\">RIGHT NOW. AND WE DID HAVE</p>\n",
            "      <p begin=\"90.91s\" xml:id=\"p53\" end=\"92.11s\" region=\"shifted_middle3\">MUCH MORE RAIN WHEN THEY GOT</p>\n",
            "      <p begin=\"92.11s\" xml:id=\"p54\" end=\"95.08s\" region=\"shifted_middle3\">HERE ABOUT AN HOUR AND A HALF</p>\n",
            "      <p begin=\"95.08s\" xml:id=\"p55\" end=\"96.98s\" region=\"shifted_middle3\">JUST A LITTLE BIT AND WE ARE</p>\n",
            "      <p begin=\"96.98s\" xml:id=\"p56\" end=\"101.05s\" region=\"shifted_middle3\">STILL DEALING WITH THAT</p>\n",
            "      <p begin=\"101.05s\" xml:id=\"p57\" end=\"102.35s\" region=\"shifted_middle3\">TO SHOW YOU EXACTLY WHAT WE'RE</p>\n",
            "      <p begin=\"102.35s\" xml:id=\"p58\" end=\"106.35s\" region=\"shifted_middle3\">SEEING RIGHT HERE BEHIND ME IS</p>\n",
            "      <p begin=\"106.35s\" xml:id=\"p59\" end=\"108.72s\" region=\"shifted_middle3\">WHERE THAT PLANE WENT DOWN.</p>\n",
            "      <p begin=\"108.72s\" xml:id=\"p60\" end=\"109.36s\" region=\"shifted_middle3\">AND YOU CAN SEE THOSE THOSE</p>\n",
            "      <p begin=\"109.36s\" xml:id=\"p61\" end=\"110.06s\" region=\"shifted_middle3\">CONTAINMENT LINES THAT WE</p>\n",
            "      <p begin=\"110.06s\" xml:id=\"p62\" end=\"113.23s\" region=\"shifted_middle3\">PUTTING INTO THE WATER JUST</p>\n",
            "      <p begin=\"113.23s\" xml:id=\"p63\" end=\"113.93s\" region=\"shifted_middle3\">ABOUT AN HOUR AGO.</p>\n",
            "      <p begin=\"113.93s\" xml:id=\"p64\" end=\"114.66s\" region=\"shifted_middle3\">WE CAN'T SEE THE PLANE IN</p>\n",
            "      <p begin=\"114.66s\" xml:id=\"p65\" end=\"117.43s\" region=\"shifted_middle3\">THE WATER RIGHT NOW, BUT WE DO</p>\n",
            "      <p begin=\"117.43s\" xml:id=\"p66\" end=\"120.14s\" region=\"shifted_middle3\">KNOW THAT THEY ARE WITHIN</p>\n",
            "      <p begin=\"120.14s\" xml:id=\"p67\" end=\"120.84s\" region=\"shifted_middle3\">ORANGE CONTAINMENT FILM. THEY</p>\n",
            "      <p begin=\"120.84s\" xml:id=\"p68\" end=\"121.57s\" region=\"shifted_middle3\">PUT THE FIGURE AT KEEPING THE</p>\n",
            "      <p begin=\"121.57s\" xml:id=\"p69\" end=\"124.87s\" region=\"shifted_middle3\">OIL INFLUENCE FROM THE FLAMES</p>\n",
            "      <p begin=\"124.87s\" xml:id=\"p70\" end=\"125.87s\">COASTLINE. ALSO BECAUSE WHERE</p>\n",
            "      <p begin=\"125.87s\" xml:id=\"p71\" end=\"128.11s\">THIS JET WENT DOWN IS JUST</p>\n",
            "      <p begin=\"128.11s\" xml:id=\"p72\" end=\"129.74s\">FEET AWAY FROM WHERE THE</p>\n",
            "      <p begin=\"129.74s\" xml:id=\"p73\" end=\"131.08s\">NAVY'S DOLPHINS AND SEA LIONS</p>\n",
            "      <p begin=\"131.08s\" xml:id=\"p74\" end=\"132.48s\">STRAIN. THIS IS WHERE THEY'RE</p>\n",
            "      <p begin=\"132.48s\" xml:id=\"p75\" end=\"133.18s\">HELD IN. THIS IS THEIR</p>\n",
            "      <p begin=\"133.18s\" xml:id=\"p76\" end=\"133.82s\">TRAINING AREA. NOT SURE YOU</p>\n",
            "      <p begin=\"133.82s\" xml:id=\"p77\" end=\"138.19s\">CAN SEE FROM WHERE WE'RE</p>\n",
            "      <p begin=\"138.19s\" xml:id=\"p78\" end=\"139.99s\">STANDING, BUT BOAT THAT ARE</p>\n",
            "      <p begin=\"139.99s\" xml:id=\"p79\" end=\"141.29s\">FARTHER OFF IN THE DISTANCE.</p>\n",
            "      <p begin=\"141.29s\" xml:id=\"p80\" end=\"143.12s\">THEY ALL TURNED THEIR ENGINES</p>\n",
            "      <p begin=\"143.12s\" xml:id=\"p81\" end=\"145.43s\">ON. AND WE'RE TOLD THAT IT'S</p>\n",
            "      <p begin=\"145.43s\" xml:id=\"p82\" end=\"148.03s\">LIKELY TO TRY AND KEEP ANY</p>\n",
            "      <p begin=\"148.03s\" xml:id=\"p83\" end=\"149.03s\">OIL, FLUIDS FROM GETTING AS</p>\n",
            "      <p begin=\"149.03s\" xml:id=\"p84\" end=\"150.37s\">CLOSE TO DOLPHINS AND SEA</p>\n",
            "      <p begin=\"150.37s\" xml:id=\"p85\" end=\"152.17s\">LIONS THAT THAT THAT HELP</p>\n",
            "      <p begin=\"152.17s\" xml:id=\"p86\" end=\"153.4s\">TRAIN THE NAVY, THEY'RE</p>\n",
            "      <p begin=\"153.4s\" xml:id=\"p87\" end=\"155.0s\">TURNING TO. THEY CAN PUSH THE</p>\n",
            "      <p begin=\"155.0s\" xml:id=\"p88\" end=\"156.81s\">AWAY FROM THOSE MARINE LIFE</p>\n",
            "      <p begin=\"156.81s\" xml:id=\"p89\" end=\"157.54s\">THAT WE DID. JUST TALK TO</p>\n",
            "      <p begin=\"157.54s\" xml:id=\"p90\" end=\"161.08s\">SOMEONE WHO AND SAW THIS CRASH</p>\n",
            "      <p begin=\"161.08s\" xml:id=\"p91\" end=\"161.81s\">MOMENTS AGO.</p>\n",
            "      <p begin=\"161.81s\" xml:id=\"p92\" end=\"165.91s\">THE FLY OVERHEAD EVERY DAY.</p>\n",
            "      <p begin=\"165.91s\" xml:id=\"p93\" end=\"166.55s\">HE TAKEN OFF. WE'RE FACED. AND</p>\n",
            "      <p begin=\"166.55s\" xml:id=\"p94\" end=\"170.39s\">THIS MORNING, THEY LIKE</p>\n",
            "      <p begin=\"170.39s\" xml:id=\"p95\" end=\"171.12s\">THEY'RE AND THIS IS THE FIRST</p>\n",
            "      <p begin=\"171.12s\" xml:id=\"p96\" end=\"174.19s\">ONE CAME GOT MY ATTENTION. I</p>\n",
            "      <p begin=\"174.19s\" xml:id=\"p97\" end=\"177.83s\">LOOKED AT MY CORE. IN SAVING</p>\n",
            "      <p begin=\"177.83s\" xml:id=\"p98\" end=\"178.59s\">CLOUD COVERAGE. AND THEN THE</p>\n",
            "      <p begin=\"178.59s\" xml:id=\"p99\" end=\"181.41s\">NEXT ONE THAT CAME 15 SECONDS</p>\n",
            "      <p begin=\"183.83s\" xml:id=\"p100\" end=\"184.57s\">LATER. AND HE WAS A LITTLE BIT</p>\n",
            "      <p begin=\"184.57s\" xml:id=\"p101\" end=\"188.97s\">LOWER. AND RIGHT WHEN I TRYING</p>\n",
            "      <p begin=\"188.97s\" xml:id=\"p102\" end=\"189.7s\">TO GET MY CAR SEE POWELL. IT'S</p>\n",
            "      <p begin=\"189.7s\" xml:id=\"p103\" end=\"192.52s\">I HEARD HIM THE ENGINE, SHIFTY</p>\n",
            "      <p begin=\"198.45s\" xml:id=\"p104\" end=\"199.11s\">THAT, WE DID. PARK. AND TOP</p>\n",
            "      <p begin=\"199.11s\" xml:id=\"p105\" end=\"201.12s\">MANY WAYS THAT CAN STEER. IT</p>\n",
            "      <p begin=\"201.12s\" xml:id=\"p106\" end=\"205.19s\">WASN'T A GUEST. IS A THING</p>\n",
            "      <p begin=\"205.19s\" xml:id=\"p107\" end=\"208.01s\">STARTED GO UP. BUT THEN THE</p>\n",
            "      <p begin=\"212.66s\" xml:id=\"p108\" end=\"213.66s\">DEBRIS FALLING FROM WHAT ARE</p>\n",
            "      <p begin=\"213.66s\" xml:id=\"p109\" end=\"215.0s\">AND WE DO KNOW THAT ABOUT</p>\n",
            "      <p begin=\"215.0s\" xml:id=\"p110\" end=\"216.03s\">60 UNITS OF FIRST RESPONDERS</p>\n",
            "      <p begin=\"216.03s\" xml:id=\"p111\" end=\"216.83s\">HAVE BEEN ASSIGNED TO THIS</p>\n",
            "      <p begin=\"216.83s\" xml:id=\"p112\" end=\"218.87s\">INCIDENT RIGHT NOW. THAT</p>\n",
            "      <p begin=\"218.87s\" xml:id=\"p113\" end=\"219.97s\">INCLUDES THE COAST GUARD NAVY</p>\n",
            "      <p begin=\"219.97s\" xml:id=\"p114\" end=\"221.94s\">LEAVE AND HOW TO U.S. CUSTOMS</p>\n",
            "      <p begin=\"221.94s\" xml:id=\"p115\" end=\"224.27s\">AND BORDER PROTECTION BOAT.</p>\n",
            "      <p begin=\"224.27s\" xml:id=\"p116\" end=\"225.01s\">ARBOR. POLICE HAVE SHUTDOWN</p>\n",
            "      <p begin=\"225.01s\" xml:id=\"p117\" end=\"228.31s\">SHELTER ISLAND DRIVE, WHICH IS</p>\n",
            "      <p begin=\"228.31s\" xml:id=\"p118\" end=\"230.05s\">THE ROVER STANDING RIGHT HERE</p>\n",
            "      <p begin=\"230.05s\" xml:id=\"p119\" end=\"231.58s\">NOW. BUT IT WAS REOPENED JUST</p>\n",
            "      <p begin=\"231.58s\" xml:id=\"p120\" end=\"234.15s\">ABOUT THE LAST 30 MINUTES THAT</p>\n",
            "      <p begin=\"234.15s\" xml:id=\"p121\" end=\"236.48s\">WE SEEING A STEADY FLOW OF</p>\n",
            "      <p begin=\"236.48s\" xml:id=\"p122\" end=\"238.15s\">CARS COMING INTO THIS AREA AT</p>\n",
            "      <p begin=\"238.15s\" xml:id=\"p123\" end=\"239.29s\">THE VERY LATEST HERE LIVE FROM</p>\n",
            "      <p begin=\"239.29s\" xml:id=\"p124\" end=\"241.16s\">SHELTER ISLAND, ZARA BARKER</p>\n",
            "      <p begin=\"241.16s\" xml:id=\"p125\" end=\"243.22s\">FOX, 5 THANK YOU FOR THAT.</p>\n",
            "      <p begin=\"243.22s\" xml:id=\"p126\" end=\"244.09s\">HUSTLE. LET'S CHECK IN NOW.</p>\n",
            "      <p begin=\"244.09s\" xml:id=\"p127\" end=\"246.16s\">IT'S HERE AND SEE. THIS IS</p>\n",
            "      <p begin=\"246.16s\" xml:id=\"p128\" end=\"246.9s\">LIVE AT UC SAN DIEGO HILLCREST</p>\n",
            "      <p begin=\"246.9s\" xml:id=\"p129\" end=\"248.23s\">WHERE THE PILOTS ARE BEING</p>\n",
            "      <p begin=\"248.23s\" xml:id=\"p130\" end=\"248.96s\">TREATED AFTER BEING EJECTED</p>\n",
            "      <p begin=\"248.96s\" xml:id=\"p131\" end=\"251.78s\">FROM THE PLANE. CR. WHAT'S THE</p>\n",
            "      <p begin=\"254.67s\" xml:id=\"p132\" end=\"255.37s\">LATEST?</p>\n",
            "      <p begin=\"255.37s\" xml:id=\"p133\" end=\"258.04s\">PRISTINA, THE NAVY TOLD ME</p>\n",
            "      <p begin=\"258.04s\" xml:id=\"p134\" end=\"259.81s\">THAT THE 2 PILOTS ARE IN</p>\n",
            "      <p begin=\"259.81s\" xml:id=\"p135\" end=\"261.91s\">STABLE CONDITION. DIEGO FIRE</p>\n",
            "      <p begin=\"261.91s\" xml:id=\"p136\" end=\"264.75s\">RESCUE TRANSPORTED THOSE 2</p>\n",
            "      <p begin=\"264.75s\" xml:id=\"p137\" end=\"265.55s\">MEDICAL CENTER HERE HILLCREST.</p>\n",
            "      <p begin=\"265.55s\" xml:id=\"p138\" end=\"268.42s\">WE SPOKE TO A COUPLE OF NURSES</p>\n",
            "      <p begin=\"268.42s\" xml:id=\"p139\" end=\"269.38s\">WALKING DOWN THE STREET HERE</p>\n",
            "      <p begin=\"269.38s\" xml:id=\"p140\" end=\"272.39s\">ABOUT 30 MINUTES TO AN HOUR,</p>\n",
            "      <p begin=\"272.39s\" xml:id=\"p141\" end=\"274.19s\">THOUGH. THEY THINK THAT THEY</p>\n",
            "      <p begin=\"274.19s\" xml:id=\"p142\" end=\"275.39s\">TEND TO GET THE MILITARY</p>\n",
            "      <p begin=\"275.39s\" xml:id=\"p143\" end=\"276.59s\">STRONGEST PATIENTS TRANSPORTED</p>\n",
            "      <p begin=\"276.59s\" xml:id=\"p144\" end=\"277.23s\">OVER HERE. NOW THAT DOESN'T</p>\n",
            "      <p begin=\"277.23s\" xml:id=\"p145\" end=\"278.06s\">HAVE ANY DETAILS ON THE</p>\n",
            "      <p begin=\"278.06s\" xml:id=\"p146\" end=\"279.79s\">PILOTS, THEY HAVE NOT YET</p>\n",
            "      <p begin=\"279.79s\" xml:id=\"p147\" end=\"281.76s\">RELEASED THE NAMES OF THE</p>\n",
            "      <p begin=\"281.76s\" xml:id=\"p148\" end=\"283.83s\">PILOTS, BUT THEY DO SAY THAT</p>\n",
            "      <p begin=\"283.83s\" xml:id=\"p149\" end=\"285.07s\">THEY WERE INTEL FROM</p>\n",
            "      <p begin=\"285.07s\" xml:id=\"p150\" end=\"286.84s\">WASHINGTON FOR A TRAINING</p>\n",
            "      <p begin=\"286.84s\" xml:id=\"p151\" end=\"288.84s\">EXERCISE AT NAVAL AIR STATION,</p>\n",
            "      <p begin=\"288.84s\" xml:id=\"p152\" end=\"290.97s\">NORTH ISLAND. NO, THEY WERE ON</p>\n",
            "      <p begin=\"290.97s\" xml:id=\"p153\" end=\"294.84s\">GROWLER WHEN IT WENT DOWN. IT</p>\n",
            "      <p begin=\"294.84s\" xml:id=\"p154\" end=\"296.11s\">SAID THERE THAT WERE RESCUED</p>\n",
            "      <p begin=\"296.11s\" xml:id=\"p155\" end=\"296.75s\">BY THAT FISHING BOATS ARE</p>\n",
            "      <p begin=\"296.75s\" xml:id=\"p156\" end=\"300.88s\">STILL WORKING TO GATHER</p>\n",
            "      <p begin=\"300.88s\" xml:id=\"p157\" end=\"301.58s\">DETAILS HERE TODAY. WE DID SEE</p>\n",
            "      <p begin=\"301.58s\" xml:id=\"p158\" end=\"302.25s\">70 PERSONNEL WALKING TO THE</p>\n",
            "      <p begin=\"302.25s\" xml:id=\"p159\" end=\"304.13s\">HOSPITAL EARLIER THAT'S THE</p>\n",
            "    </div>\n",
            "  </body>\n",
            "</tt>\n",
            "<layout xmlns=\"http://www.w3.org/ns/ttml\">\n",
            "      <region tts:origin=\"1.09% 93.06%\" tts:extent=\"97.81% 5.00%\" tts:displayAlign=\"center\" tts:textAlign=\"center\" xml:id=\"bottom\" /><region tts:origin=\"1.09% 72.50%\" tts:extent=\"97.81% 5.00%\" tts:displayAlign=\"center\" tts:textAlign=\"center\" xml:id=\"middle3\" /><region tts:origin=\"0.00% 47.50%\" tts:extent=\"60.00% 5.00%\" tts:displayAlign=\"center\" tts:textAlign=\"center\" xml:id=\"shifted_middle2\" /><region tts:origin=\"40.00% 72.50%\" tts:extent=\"60.00% 5.00%\" tts:displayAlign=\"center\" tts:textAlign=\"center\" xml:id=\"shifted_middle3\" /></layout>\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## process frame in time frame only\n",
        "import os\n",
        "import cv2\n",
        "import pysrt\n",
        "import torch\n",
        "import subprocess\n",
        "\n",
        "# ✅ Define file paths in /content/\n",
        "video_input_path = \"/content/optimal_subtitle_copied/test_video_3.mp4\"\n",
        "final_video_path = \"/content/optimal_subtitle_copied/test_video_with_audio.mp4\"\n",
        "# file_path = \"/content/optimal_subtitle_copied/SRT_file/test_long_video_17_eng.srt\"\n",
        "file_path = \"/content/optimal_subtitle_copied/TTML_file/test_video_3_eng.ttml\"\n",
        "json_path = \"/content/optimal_subtitle_copied/subtitle_positions_ttml.json\"\n",
        "\n",
        "# ✅ Create temporary paths inside /content/\n",
        "audio_path = \"/content/temp_audio.aac\"\n",
        "output_video_path = \"/content/temp_video_no_audio.mp4\"\n",
        "\n",
        "# ✅ Extract FPS dynamically\n",
        "fps = get_video_fps(video_input_path)\n",
        "print(f\"✅ Corrected FPS: {fps}\")\n",
        "\n",
        "# ✅ Extract audio from the original video\n",
        "# os.system(f\"ffmpeg -i {video_input_path} -q:a 0 -map a {audio_path}\")\n",
        "\n",
        "# ✅ Load Pre-indexed Subtitles\n",
        "# subtitle_data = parse_srt_file(file_path)\n",
        "subtitle_data = parse_subtitle_file(file_path)\n",
        "\n",
        "# ✅ Load Subtitle Timestamps\n",
        "subtitle_timestamps = get_subtitle_timestamps(file_path)\n",
        "\n",
        "# ✅ Open Video File\n",
        "cap = cv2.VideoCapture(video_input_path)\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "print(f\"Frame Width: {frame_width}, Frame Height: {frame_height}\")\n",
        "# subtitle_height, margin = get_subtitle_size(frame_height)\n",
        "\n",
        "# ✅ Initialize Video Writer\n",
        "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "# ✅ Process Video with Batching\n",
        "batch_size = 128\n",
        "frame_buffer = []\n",
        "timestamp_buffer = []\n",
        "frame_number = 0\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break  # Exit if no more frames\n",
        "\n",
        "    frame_time = frame_number / fps  # Convert frame number to timestamp\n",
        "\n",
        "    # ✅ Only process frames that fall within subtitle timestamps\n",
        "    if should_process_frame(frame_time, subtitle_timestamps, fps):\n",
        "        frame_buffer.append(frame)\n",
        "        timestamp_buffer.append(frame_time)\n",
        "\n",
        "        # ✅ Process in batch when buffer reaches batch_size\n",
        "        if len(frame_buffer) == batch_size:\n",
        "            subtitles = get_subtitles_for_frames(timestamp_buffer, subtitle_data)\n",
        "            # print(subtitles)\n",
        "            # processed_frames = process_frames_batch_3fps(frame_buffer, subtitles, file_path, json_path)\n",
        "            processed_frames = process_frames_batch_3fps_processed(frame_buffer, subtitles)\n",
        "\n",
        "            for processed_frame in processed_frames:\n",
        "                out.write(processed_frame)\n",
        "\n",
        "            frame_buffer.clear()\n",
        "            timestamp_buffer.clear()\n",
        "\n",
        "    frame_number += 1\n",
        "\n",
        "# ✅ Process remaining frames if they exist\n",
        "if frame_buffer:\n",
        "    subtitles = get_subtitles_for_frames(timestamp_buffer, subtitle_data)\n",
        "    # processed_frames = process_frames_batch_3fps(frame_buffer, subtitles, file_path, json_path)\n",
        "    processed_frames = process_frames_batch_3fps_processed(frame_buffer, subtitles)\n",
        "    for processed_frame in processed_frames:\n",
        "        out.write(processed_frame)\n",
        "\n",
        "cap.release()\n",
        "\n",
        "out.release()\n",
        "\n",
        "# print(f\"✅ Video without audio saved at: {output_video_path}\")\n",
        "\n",
        "# # ✅ Check if final_video_path exists\n",
        "# if os.path.exists(final_video_path):\n",
        "#     os.remove(final_video_path)  # ✅ Delete existing file\n",
        "\n",
        "# # ✅ Merge Video & Audio with Correct FPS & Sync Fixes\n",
        "# os.system(f\"ffmpeg -i {output_video_path} -i {audio_path} -map 0:v:0 -map 1:a:0 -c:v libx264 -preset fast -crf 23 -c:a copy -vsync vfr {final_video_path}\")\n",
        "\n",
        "# # ✅ Clean up the temporary files\n",
        "# os.remove(audio_path)\n",
        "# os.remove(output_video_path)\n",
        "\n",
        "# print(f\"✅ Final video with audio saved at: {final_video_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXxaSMDlWGuG",
        "outputId": "cac1de67-ee9a-4403-aef7-7ab38ec15fbb"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Corrected FPS: 29.97\n",
            "Frame Width: 1280, Frame Height: 720\n",
            "\n",
            "0: 384x640 2 faces, 42.2ms\n",
            "1: 384x640 2 faces, 42.2ms\n",
            "2: 384x640 2 faces, 42.2ms\n",
            "3: 384x640 2 faces, 42.2ms\n",
            "4: 384x640 2 faces, 1 text, 42.2ms\n",
            "5: 384x640 2 faces, 1 text, 42.2ms\n",
            "6: 384x640 2 faces, 1 text, 42.2ms\n",
            "7: 384x640 2 faces, 1 text, 42.2ms\n",
            "8: 384x640 2 faces, 42.2ms\n",
            "9: 384x640 2 faces, 1 logo, 1 news-ticker, 1 text, 42.2ms\n",
            "10: 384x640 2 faces, 2 logos, 2 news-tickers, 2 texts, 42.2ms\n",
            "11: 384x640 2 faces, 2 logos, 1 news-ticker, 2 texts, 42.2ms\n",
            "12: 384x640 2 faces, 2 logos, 1 news-ticker, 2 texts, 42.2ms\n",
            "Speed: 5.1ms preprocess, 42.2ms inference, 43.6ms postprocess per image at shape (13, 3, 384, 640)\n",
            "(14, 522, 1266, 558)\n",
            "\n",
            "0: 384x640 2 faces, 2 logos, 1 news-ticker, 2 texts, 3.9ms\n",
            "1: 384x640 2 faces, 2 logos, 1 news-ticker, 1 text, 3.9ms\n",
            "2: 384x640 2 faces, 2 logos, 1 news-ticker, 3 texts, 3.9ms\n",
            "3: 384x640 2 faces, 2 logos, 1 news-ticker, 2 texts, 3.9ms\n",
            "4: 384x640 2 faces, 2 logos, 1 news-ticker, 1 text, 3.9ms\n",
            "5: 384x640 2 faces, 2 logos, 1 news-ticker, 3 texts, 3.9ms\n",
            "6: 384x640 2 faces, 2 logos, 1 news-ticker, 3 texts, 3.9ms\n",
            "7: 384x640 2 faces, 2 logos, 1 news-ticker, 3 texts, 3.9ms\n",
            "8: 384x640 2 faces, 2 logos, 1 news-ticker, 3 texts, 3.9ms\n",
            "9: 384x640 2 faces, 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "10: 384x640 2 faces, 1 logo, 1 news-ticker, 1 text, 3.9ms\n",
            "11: 384x640 3 texts, 3.9ms\n",
            "12: 384x640 2 texts, 3.9ms\n",
            "Speed: 2.3ms preprocess, 3.9ms inference, 0.9ms postprocess per image at shape (13, 3, 384, 640)\n",
            "(14, 522, 1266, 558)\n",
            "\n",
            "0: 384x640 2 texts, 3.9ms\n",
            "1: 384x640 2 texts, 3.9ms\n",
            "2: 384x640 2 texts, 3.9ms\n",
            "3: 384x640 2 texts, 3.9ms\n",
            "4: 384x640 2 texts, 3.9ms\n",
            "5: 384x640 2 texts, 3.9ms\n",
            "6: 384x640 1 news-ticker, 2 texts, 3.9ms\n",
            "7: 384x640 1 news-ticker, 2 texts, 3.9ms\n",
            "8: 384x640 1 news-ticker, 2 texts, 3.9ms\n",
            "9: 384x640 1 news-ticker, 2 texts, 3.9ms\n",
            "10: 384x640 1 news-ticker, 2 texts, 3.9ms\n",
            "11: 384x640 2 news-tickers, 2 texts, 3.9ms\n",
            "12: 384x640 2 news-tickers, 2 texts, 3.9ms\n",
            "Speed: 1.7ms preprocess, 3.9ms inference, 0.8ms postprocess per image at shape (13, 3, 384, 640)\n",
            "(14, 522, 1266, 558)\n",
            "\n",
            "0: 384x640 1 news-ticker, 2 texts, 3.9ms\n",
            "1: 384x640 1 news-ticker, 2 texts, 3.9ms\n",
            "2: 384x640 1 news-ticker, 2 texts, 3.9ms\n",
            "3: 384x640 2 news-tickers, 2 texts, 3.9ms\n",
            "4: 384x640 2 news-tickers, 2 texts, 3.9ms\n",
            "5: 384x640 2 news-tickers, 2 texts, 3.9ms\n",
            "6: 384x640 2 news-tickers, 2 texts, 3.9ms\n",
            "7: 384x640 2 news-tickers, 2 texts, 3.9ms\n",
            "8: 384x640 2 news-tickers, 2 texts, 3.9ms\n",
            "9: 384x640 2 news-tickers, 2 texts, 3.9ms\n",
            "10: 384x640 3 news-tickers, 2 texts, 3.9ms\n",
            "11: 384x640 3 news-tickers, 2 texts, 3.9ms\n",
            "12: 384x640 3 news-tickers, 2 texts, 3.9ms\n",
            "Speed: 1.8ms preprocess, 3.9ms inference, 0.8ms postprocess per image at shape (13, 3, 384, 640)\n",
            "(14, 522, 1266, 558)\n",
            "\n",
            "0: 384x640 3 news-tickers, 2 texts, 3.9ms\n",
            "1: 384x640 2 news-tickers, 2 texts, 3.9ms\n",
            "2: 384x640 2 news-tickers, 2 texts, 3.9ms\n",
            "3: 384x640 3 news-tickers, 2 texts, 3.9ms\n",
            "4: 384x640 1 logo, 2 news-tickers, 1 text, 3.9ms\n",
            "5: 384x640 1 logo, 2 news-tickers, 1 text, 3.9ms\n",
            "6: 384x640 1 news-ticker, 3.9ms\n",
            "7: 384x640 1 news-ticker, 3.9ms\n",
            "8: 384x640 3 faces, 1 logo, 2 news-tickers, 2 texts, 3.9ms\n",
            "9: 384x640 4 faces, 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "10: 384x640 3 faces, 1 logo, 1 news-ticker, 3 texts, 3.9ms\n",
            "11: 384x640 3 faces, 1 logo, 2 news-tickers, 5 texts, 3.9ms\n",
            "12: 384x640 3 faces, 1 logo, 2 news-tickers, 6 texts, 3.9ms\n",
            "Speed: 2.7ms preprocess, 3.9ms inference, 0.9ms postprocess per image at shape (13, 3, 384, 640)\n",
            "(14, 522, 1266, 558)\n",
            "\n",
            "0: 384x640 3 faces, 1 logo, 2 news-tickers, 5 texts, 3.9ms\n",
            "1: 384x640 4 faces, 1 logo, 1 news-ticker, 4 texts, 3.9ms\n",
            "2: 384x640 3 faces, 1 logo, 2 news-tickers, 4 texts, 3.9ms\n",
            "3: 384x640 3 faces, 1 logo, 1 news-ticker, 5 texts, 3.9ms\n",
            "4: 384x640 4 faces, 2 logos, 2 news-tickers, 5 texts, 3.9ms\n",
            "5: 384x640 4 faces, 2 logos, 2 news-tickers, 5 texts, 3.9ms\n",
            "6: 384x640 3 faces, 2 logos, 1 news-ticker, 5 texts, 3.9ms\n",
            "7: 384x640 3 faces, 2 logos, 1 news-ticker, 5 texts, 3.9ms\n",
            "8: 384x640 3 faces, 2 logos, 1 news-ticker, 5 texts, 3.9ms\n",
            "9: 384x640 3 faces, 3 logos, 1 news-ticker, 4 texts, 3.9ms\n",
            "10: 384x640 3 faces, 2 logos, 1 news-ticker, 4 texts, 3.9ms\n",
            "11: 384x640 3 faces, 1 logo, 1 news-ticker, 4 texts, 3.9ms\n",
            "12: 384x640 3 faces, 1 logo, 1 news-ticker, 6 texts, 3.9ms\n",
            "Speed: 1.7ms preprocess, 3.9ms inference, 0.8ms postprocess per image at shape (13, 3, 384, 640)\n",
            "(0, 342, 768, 378)\n",
            "\n",
            "0: 384x640 3 faces, 1 logo, 1 news-ticker, 5 texts, 3.9ms\n",
            "1: 384x640 3 faces, 1 logo, 2 news-tickers, 5 texts, 3.9ms\n",
            "2: 384x640 3 faces, 1 logo, 1 news-ticker, 4 texts, 3.9ms\n",
            "3: 384x640 3 faces, 1 logo, 2 news-tickers, 4 texts, 3.9ms\n",
            "4: 384x640 3 faces, 1 logo, 1 news-ticker, 5 texts, 3.9ms\n",
            "5: 384x640 4 faces, 1 logo, 1 news-ticker, 6 texts, 3.9ms\n",
            "6: 384x640 4 faces, 1 logo, 1 news-ticker, 5 texts, 3.9ms\n",
            "7: 384x640 3 faces, 1 logo, 2 news-tickers, 5 texts, 3.9ms\n",
            "8: 384x640 3 faces, 1 logo, 2 news-tickers, 5 texts, 3.9ms\n",
            "9: 384x640 3 faces, 1 logo, 2 news-tickers, 5 texts, 3.9ms\n",
            "10: 384x640 4 faces, 1 logo, 2 news-tickers, 6 texts, 3.9ms\n",
            "11: 384x640 4 faces, 1 logo, 2 news-tickers, 5 texts, 3.9ms\n",
            "12: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "Speed: 1.7ms preprocess, 3.9ms inference, 0.8ms postprocess per image at shape (13, 3, 384, 640)\n",
            "(0, 342, 768, 378)\n",
            "\n",
            "0: 384x640 1 face, 2 logos, 2 news-tickers, 1 text, 3.9ms\n",
            "1: 384x640 1 face, 2 logos, 2 news-tickers, 3.9ms\n",
            "2: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 3.9ms\n",
            "3: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 3.9ms\n",
            "4: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 3.9ms\n",
            "5: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 3.9ms\n",
            "6: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 3.9ms\n",
            "7: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 3.9ms\n",
            "8: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 3.9ms\n",
            "9: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 3.9ms\n",
            "10: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 3.9ms\n",
            "11: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 3.9ms\n",
            "12: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 3.9ms\n",
            "Speed: 1.6ms preprocess, 3.9ms inference, 0.9ms postprocess per image at shape (13, 3, 384, 640)\n",
            "(435, 522, 1277, 558)\n",
            "\n",
            "0: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 3.9ms\n",
            "1: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 3.9ms\n",
            "2: 384x640 1 face, 2 logos, 3 news-tickers, 2 texts, 3.9ms\n",
            "3: 384x640 1 face, 2 logos, 2 news-tickers, 3.9ms\n",
            "4: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 3.9ms\n",
            "5: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "6: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "7: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "8: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "9: 384x640 1 face, 2 logos, 2 news-tickers, 4 texts, 3.9ms\n",
            "10: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "11: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "12: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "Speed: 2.4ms preprocess, 3.9ms inference, 1.1ms postprocess per image at shape (13, 3, 384, 640)\n",
            "(473, 522, 1278, 558)\n",
            "\n",
            "0: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "1: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "2: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "3: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "4: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "5: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "6: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "7: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "8: 384x640 1 face, 2 logos, 1 news-ticker, 3 texts, 3.9ms\n",
            "9: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "10: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "11: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "12: 384x640 1 face, 2 logos, 3 news-tickers, 3 texts, 3.9ms\n",
            "Speed: 1.6ms preprocess, 3.9ms inference, 0.8ms postprocess per image at shape (13, 3, 384, 640)\n",
            "(512, 522, 1280, 558)\n",
            "\n",
            "0: 384x640 1 face, 2 logos, 2 news-tickers, 4 texts, 3.9ms\n",
            "1: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "2: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "3: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "4: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "5: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 3.9ms\n",
            "6: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "7: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 3.9ms\n",
            "8: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 3.9ms\n",
            "9: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 3.9ms\n",
            "10: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 3.9ms\n",
            "11: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 3.9ms\n",
            "12: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 3.9ms\n",
            "Speed: 1.7ms preprocess, 3.9ms inference, 0.8ms postprocess per image at shape (13, 3, 384, 640)\n",
            "(512, 522, 1280, 558)\n",
            "\n",
            "0: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 3.9ms\n",
            "1: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "2: 384x640 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "3: 384x640 1 face, 2 logos, 3 news-tickers, 3 texts, 3.9ms\n",
            "4: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "5: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "6: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "7: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "8: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "9: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "10: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "11: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "12: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "Speed: 2.0ms preprocess, 3.9ms inference, 1.6ms postprocess per image at shape (13, 3, 384, 640)\n",
            "(512, 522, 1280, 558)\n",
            "\n",
            "0: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "1: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "2: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 3.9ms\n",
            "3: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "4: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 3.9ms\n",
            "5: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "6: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "7: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "8: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "9: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "10: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "11: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "12: 384x640 1 face, 2 logos, 2 news-tickers, 4 texts, 3.9ms\n",
            "Speed: 1.8ms preprocess, 3.9ms inference, 0.8ms postprocess per image at shape (13, 3, 384, 640)\n",
            "(512, 522, 1280, 558)\n",
            "\n",
            "0: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "1: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "2: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "3: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 3.9ms\n",
            "4: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 3.9ms\n",
            "5: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 3.9ms\n",
            "6: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 3.9ms\n",
            "7: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 3.9ms\n",
            "8: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 3.9ms\n",
            "9: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 3.9ms\n",
            "10: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 3.9ms\n",
            "11: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 3.9ms\n",
            "12: 384x640 1 face, 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "Speed: 1.6ms preprocess, 3.9ms inference, 1.7ms postprocess per image at shape (13, 3, 384, 640)\n",
            "(512, 522, 1280, 558)\n",
            "\n",
            "0: 384x640 1 face, 2 logos, 2 news-tickers, 2 texts, 3.9ms\n",
            "1: 384x640 2 logos, 2 news-tickers, 4 texts, 3.9ms\n",
            "2: 384x640 1 logo, 2 news-tickers, 4 texts, 3.9ms\n",
            "3: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "4: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "5: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "6: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "7: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "8: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "9: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "10: 384x640 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "11: 384x640 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "12: 384x640 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "Speed: 1.6ms preprocess, 3.9ms inference, 0.8ms postprocess per image at shape (13, 3, 384, 640)\n",
            "(512, 522, 1280, 558)\n",
            "\n",
            "0: 384x640 2 logos, 2 news-tickers, 4 texts, 3.9ms\n",
            "1: 384x640 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "2: 384x640 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "3: 384x640 2 logos, 2 news-tickers, 2 texts, 3.9ms\n",
            "4: 384x640 2 logos, 2 news-tickers, 2 texts, 3.9ms\n",
            "5: 384x640 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "6: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "7: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "8: 384x640 1 logo, 2 news-tickers, 4 texts, 3.9ms\n",
            "9: 384x640 1 logo, 2 news-tickers, 2 texts, 3.9ms\n",
            "10: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "11: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "12: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "Speed: 1.7ms preprocess, 3.9ms inference, 0.8ms postprocess per image at shape (13, 3, 384, 640)\n",
            "(512, 522, 1280, 558)\n",
            "\n",
            "0: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "1: 384x640 1 logo, 2 news-tickers, 4 texts, 3.9ms\n",
            "2: 384x640 1 logo, 2 news-tickers, 4 texts, 3.9ms\n",
            "3: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "4: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "5: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "6: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "7: 384x640 1 logo, 2 news-tickers, 2 texts, 3.9ms\n",
            "8: 384x640 1 logo, 2 news-tickers, 2 texts, 3.9ms\n",
            "9: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "10: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "11: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "12: 384x640 1 logo, 2 news-tickers, 2 texts, 3.9ms\n",
            "Speed: 1.8ms preprocess, 3.9ms inference, 0.8ms postprocess per image at shape (13, 3, 384, 640)\n",
            "(512, 522, 1280, 558)\n",
            "\n",
            "0: 384x640 1 logo, 2 news-tickers, 2 texts, 3.9ms\n",
            "1: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "2: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "3: 384x640 1 logo, 2 news-tickers, 4 texts, 3.9ms\n",
            "4: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "5: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "6: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "7: 384x640 1 logo, 2 news-tickers, 4 texts, 3.9ms\n",
            "8: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "9: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "10: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "11: 384x640 1 logo, 2 news-tickers, 4 texts, 3.9ms\n",
            "12: 384x640 1 logo, 2 news-tickers, 4 texts, 3.9ms\n",
            "Speed: 1.9ms preprocess, 3.9ms inference, 0.8ms postprocess per image at shape (13, 3, 384, 640)\n",
            "(512, 522, 1280, 558)\n",
            "\n",
            "0: 384x640 1 logo, 2 news-tickers, 4 texts, 3.9ms\n",
            "1: 384x640 1 logo, 2 news-tickers, 4 texts, 3.9ms\n",
            "2: 384x640 1 logo, 1 news-ticker, 4 texts, 3.9ms\n",
            "3: 384x640 1 logo, 1 news-ticker, 4 texts, 3.9ms\n",
            "4: 384x640 1 logo, 1 news-ticker, 4 texts, 3.9ms\n",
            "5: 384x640 1 logo, 2 news-tickers, 4 texts, 3.9ms\n",
            "6: 384x640 1 logo, 2 news-tickers, 4 texts, 3.9ms\n",
            "7: 384x640 1 logo, 2 news-tickers, 4 texts, 3.9ms\n",
            "8: 384x640 1 logo, 1 news-ticker, 4 texts, 3.9ms\n",
            "9: 384x640 1 logo, 2 news-tickers, 4 texts, 3.9ms\n",
            "10: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "11: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "12: 384x640 1 logo, 2 news-tickers, 2 texts, 3.9ms\n",
            "Speed: 1.7ms preprocess, 3.9ms inference, 0.8ms postprocess per image at shape (13, 3, 384, 640)\n",
            "(512, 522, 1280, 558)\n",
            "\n",
            "0: 384x640 1 logo, 2 news-tickers, 4 texts, 3.9ms\n",
            "1: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "2: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "3: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "4: 384x640 1 logo, 2 news-tickers, 4 texts, 3.9ms\n",
            "5: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "6: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "7: 384x640 1 logo, 2 news-tickers, 2 texts, 3.9ms\n",
            "8: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "9: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "10: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "11: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "12: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "Speed: 2.1ms preprocess, 3.9ms inference, 1.1ms postprocess per image at shape (13, 3, 384, 640)\n",
            "(512, 522, 1280, 558)\n",
            "\n",
            "0: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "1: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "2: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "3: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "4: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "5: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "6: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "7: 384x640 1 logo, 2 news-tickers, 4 texts, 3.9ms\n",
            "8: 384x640 1 logo, 2 news-tickers, 4 texts, 3.9ms\n",
            "9: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "10: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "11: 384x640 1 logo, 2 news-tickers, 2 texts, 3.9ms\n",
            "12: 384x640 1 logo, 2 news-tickers, 2 texts, 3.9ms\n",
            "Speed: 1.8ms preprocess, 3.9ms inference, 0.8ms postprocess per image at shape (13, 3, 384, 640)\n",
            "(512, 522, 1280, 558)\n",
            "\n",
            "0: 384x640 1 logo, 2 news-tickers, 2 texts, 3.9ms\n",
            "1: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "2: 384x640 1 logo, 2 news-tickers, 2 texts, 3.9ms\n",
            "3: 384x640 1 logo, 2 news-tickers, 2 texts, 3.9ms\n",
            "4: 384x640 1 logo, 2 news-tickers, 2 texts, 3.9ms\n",
            "5: 384x640 1 logo, 3 news-tickers, 2 texts, 3.9ms\n",
            "6: 384x640 1 logo, 2 news-tickers, 2 texts, 3.9ms\n",
            "7: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "8: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "9: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "10: 384x640 1 logo, 1 news-ticker, 4 texts, 3.9ms\n",
            "11: 384x640 1 logo, 1 news-ticker, 4 texts, 3.9ms\n",
            "12: 384x640 1 logo, 1 news-ticker, 4 texts, 3.9ms\n",
            "Speed: 1.6ms preprocess, 3.9ms inference, 0.8ms postprocess per image at shape (13, 3, 384, 640)\n",
            "(512, 522, 1280, 558)\n",
            "\n",
            "0: 384x640 1 logo, 1 news-ticker, 4 texts, 3.9ms\n",
            "1: 384x640 1 logo, 2 news-tickers, 4 texts, 3.9ms\n",
            "2: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "3: 384x640 1 logo, 2 news-tickers, 4 texts, 3.9ms\n",
            "4: 384x640 1 logo, 2 news-tickers, 4 texts, 3.9ms\n",
            "5: 384x640 1 logo, 2 news-tickers, 4 texts, 3.9ms\n",
            "6: 384x640 1 logo, 2 news-tickers, 4 texts, 3.9ms\n",
            "7: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "8: 384x640 1 logo, 2 news-tickers, 2 texts, 3.9ms\n",
            "9: 384x640 1 logo, 2 news-tickers, 2 texts, 3.9ms\n",
            "10: 384x640 1 logo, 2 news-tickers, 2 texts, 3.9ms\n",
            "11: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "12: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "Speed: 2.2ms preprocess, 3.9ms inference, 1.0ms postprocess per image at shape (13, 3, 384, 640)\n",
            "(512, 522, 1280, 558)\n",
            "\n",
            "0: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "1: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "2: 384x640 1 logo, 2 news-tickers, 4 texts, 3.9ms\n",
            "3: 384x640 1 logo, 1 news-ticker, 4 texts, 3.9ms\n",
            "4: 384x640 1 logo, 2 news-tickers, 3 texts, 3.9ms\n",
            "5: 384x640 1 logo, 2 news-tickers, 4 texts, 3.9ms\n",
            "6: 384x640 1 logo, 2 news-tickers, 4 texts, 3.9ms\n",
            "7: 384x640 1 logo, 2 news-tickers, 4 texts, 3.9ms\n",
            "8: 384x640 1 logo, 2 news-tickers, 4 texts, 3.9ms\n",
            "9: 384x640 1 logo, 2 news-tickers, 4 texts, 3.9ms\n",
            "10: 384x640 1 logo, 1 news-ticker, 4 texts, 3.9ms\n",
            "11: 384x640 1 logo, 2 news-tickers, 4 texts, 3.9ms\n",
            "12: 384x640 2 logos, 1 news-ticker, 4 texts, 3.9ms\n",
            "Speed: 1.6ms preprocess, 3.9ms inference, 0.8ms postprocess per image at shape (13, 3, 384, 640)\n",
            "(512, 522, 1280, 558)\n",
            "\n",
            "0: 384x640 2 logos, 2 news-tickers, 4 texts, 3.9ms\n",
            "1: 384x640 2 logos, 2 news-tickers, 4 texts, 3.9ms\n",
            "2: 384x640 2 logos, 2 news-tickers, 4 texts, 3.9ms\n",
            "3: 384x640 2 logos, 2 news-tickers, 4 texts, 3.9ms\n",
            "4: 384x640 2 logos, 2 news-tickers, 4 texts, 3.9ms\n",
            "5: 384x640 2 logos, 2 news-tickers, 4 texts, 3.9ms\n",
            "6: 384x640 2 logos, 2 news-tickers, 4 texts, 3.9ms\n",
            "7: 384x640 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "8: 384x640 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "9: 384x640 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "10: 384x640 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "11: 384x640 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "12: 384x640 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "Speed: 1.7ms preprocess, 3.9ms inference, 0.8ms postprocess per image at shape (13, 3, 384, 640)\n",
            "(512, 522, 1280, 558)\n",
            "\n",
            "0: 384x640 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "1: 384x640 2 logos, 2 news-tickers, 4 texts, 3.9ms\n",
            "2: 384x640 2 logos, 2 news-tickers, 4 texts, 3.9ms\n",
            "3: 384x640 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "4: 384x640 2 logos, 2 news-tickers, 4 texts, 3.9ms\n",
            "5: 384x640 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "6: 384x640 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "7: 384x640 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "8: 384x640 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "9: 384x640 3 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "10: 384x640 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "11: 384x640 2 logos, 2 news-tickers, 2 texts, 3.9ms\n",
            "12: 384x640 2 logos, 1 news-ticker, 2 texts, 3.9ms\n",
            "Speed: 1.7ms preprocess, 3.9ms inference, 1.3ms postprocess per image at shape (13, 3, 384, 640)\n",
            "(512, 522, 1280, 558)\n",
            "\n",
            "0: 384x640 2 logos, 1 news-ticker, 3 texts, 3.9ms\n",
            "1: 384x640 2 logos, 1 news-ticker, 3 texts, 3.9ms\n",
            "2: 384x640 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "3: 384x640 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "4: 384x640 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "5: 384x640 2 logos, 2 news-tickers, 4 texts, 3.9ms\n",
            "6: 384x640 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "7: 384x640 2 logos, 2 news-tickers, 4 texts, 3.9ms\n",
            "8: 384x640 2 logos, 1 news-ticker, 3 texts, 3.9ms\n",
            "9: 384x640 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "10: 384x640 2 logos, 2 news-tickers, 4 texts, 3.9ms\n",
            "11: 384x640 2 logos, 2 news-tickers, 4 texts, 3.9ms\n",
            "12: 384x640 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "Speed: 1.6ms preprocess, 3.9ms inference, 0.8ms postprocess per image at shape (13, 3, 384, 640)\n",
            "(512, 522, 1280, 558)\n",
            "\n",
            "0: 384x640 2 logos, 2 news-tickers, 4 texts, 3.9ms\n",
            "1: 384x640 2 logos, 2 news-tickers, 4 texts, 3.9ms\n",
            "2: 384x640 2 logos, 2 news-tickers, 4 texts, 3.9ms\n",
            "3: 384x640 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "4: 384x640 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "5: 384x640 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "6: 384x640 2 logos, 2 news-tickers, 4 texts, 3.9ms\n",
            "7: 384x640 2 logos, 2 news-tickers, 3 texts, 3.9ms\n",
            "8: 384x640 2 logos, 2 news-tickers, 4 texts, 3.9ms\n",
            "9: 384x640 2 logos, 2 news-tickers, 2 texts, 3.9ms\n",
            "10: 384x640 2 logos, 2 news-tickers, 2 texts, 3.9ms\n",
            "11: 384x640 2 logos, 2 news-tickers, 2 texts, 3.9ms\n",
            "12: 384x640 2 logos, 2 news-tickers, 4 texts, 3.9ms\n",
            "Speed: 1.6ms preprocess, 3.9ms inference, 0.8ms postprocess per image at shape (13, 3, 384, 640)\n",
            "(512, 522, 1280, 558)\n",
            "\n",
            "0: 384x640 2 logos, 2 news-tickers, 4 texts, 56.7ms\n",
            "1: 384x640 2 logos, 2 news-tickers, 4 texts, 56.7ms\n",
            "2: 384x640 2 logos, 2 news-tickers, 3 texts, 56.7ms\n",
            "3: 384x640 2 logos, 2 news-tickers, 2 texts, 56.7ms\n",
            "4: 384x640 2 logos, 2 news-tickers, 3 texts, 56.7ms\n",
            "5: 384x640 2 logos, 2 news-tickers, 3 texts, 56.7ms\n",
            "6: 384x640 2 logos, 2 news-tickers, 3 texts, 56.7ms\n",
            "7: 384x640 2 logos, 2 news-tickers, 3 texts, 56.7ms\n",
            "8: 384x640 2 logos, 2 news-tickers, 3 texts, 56.7ms\n",
            "Speed: 2.1ms preprocess, 56.7ms inference, 0.8ms postprocess per image at shape (9, 3, 384, 640)\n",
            "(512, 522, 1280, 558)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4yMuKdSOdHbo"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "42kgNBk0Qgif"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}