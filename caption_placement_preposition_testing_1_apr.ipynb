{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emanueltay/Optimal_Subtitle_Placement/blob/main/caption_placement_preposition_testing_1_apr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip /content/optimal_subtitle_copied.zip -d /"
      ],
      "metadata": {
        "id": "5tqdsIMOQ4XH"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install ultralytics"
      ],
      "metadata": {
        "id": "LG33s7ssRHhK"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJUwKTrUQgiY"
      },
      "source": [
        "### Detect Key Objects in the Frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "C5j6zUvEQgib"
      },
      "outputs": [],
      "source": [
        "# ! pip install ultralytics\n",
        "\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import torch\n",
        "\n",
        "# Load the trained model\n",
        "# model = YOLO(\"/content/optimal_subtitle_copied/best_100.pt\")\n",
        "model = YOLO(\"/content/optimal_subtitle_copied/best.pt\")\n",
        "\n",
        "# # ✅ Automatically select GPU if available\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# # ✅ Move model to the selected device\n",
        "model.to(device).float()  # Use FP32 (FP16 can cause issues on CPU)\n",
        "\n",
        "# ✅ Optimize PyTorch settings\n",
        "torch.backends.cudnn.benchmark = True  # Optimize for fixed-size inputs\n",
        "torch.backends.cudnn.enabled = True\n",
        "torch.set_num_threads(torch.get_num_threads())  # Use optimal number of CPU threads\n",
        "\n",
        "\n",
        "def detect_objects(frames):\n",
        "    \"\"\"\n",
        "    Perform batch object detection on multiple frames.\n",
        "\n",
        "    Parameters:\n",
        "        frames (list): List of frames (each a NumPy array).\n",
        "\n",
        "    Returns:\n",
        "        list: A list containing detections for each frame.\n",
        "              Each element is a NumPy array of detections.\n",
        "    \"\"\"\n",
        "    # ✅ Run the model in batch mode\n",
        "    results = model(frames, batch=len(frames), imgsz=640, verbose=False)  # Run batch inference 640\n",
        "\n",
        "    # ✅ Extract detections for each frame\n",
        "    batch_detections = []\n",
        "    for result in results:\n",
        "        detections = result.boxes.data.cpu().numpy()  # Convert detections to NumPy array\n",
        "        batch_detections.append(detections)\n",
        "\n",
        "    return batch_detections  # List of detections per frame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eEdf6AYQgie"
      },
      "source": [
        "### Define Safe Zones for Subtitle Placement"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# ✅ Global in-memory cache for dynamic & shifted safe zones\n",
        "safe_zone_cache = {}\n",
        "used_safe_zones = {}  # Dictionary to store all assigned safe zones\n",
        "\n",
        "def calculate_safe_zone_with_prepositions_test_new(frame_width, frame_height, detections, pre_positions, subtitle_height, margin, shift_x=20):\n",
        "    \"\"\"\n",
        "    Calculate the safe zone for subtitle placement using pre-defined positions.\n",
        "    If blocked, it attempts to shift left/right before moving vertically.\n",
        "    If no predefined position works, falls back to a dynamic safe zone and caches it in memory.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (position_name, coordinates)\n",
        "    \"\"\"\n",
        "\n",
        "    def zones_overlap(zone1, zone2):\n",
        "        \"\"\"Checks if two zones overlap.\"\"\"\n",
        "        x1a, y1a, x2a, y2a = zone1\n",
        "        x1b, y1b, x2b, y2b = zone2\n",
        "        return not (x2a < x1b or x1a > x2b or y2a < y1b or y1a > y2b)\n",
        "\n",
        "    print(subtitle_height)\n",
        "    # print(pre_positions)\n",
        "    # print(detections)\n",
        "    # ✅ Step 1: Try Predefined Positions\n",
        "    for position_name, position in sorted(pre_positions.items(), key=lambda x: x[1].get(\"priority\", 0), reverse=True):\n",
        "        x1, y1, x2, y2 = position[\"coordinates\"]\n",
        "\n",
        "        if not any(zones_overlap((x1, y1, x2, y2), detection[:4]) for detection in detections):\n",
        "            used_safe_zones[position_name] = {\n",
        "                \"coordinates\": [x1, y1, x2, y2]\n",
        "            }\n",
        "            return (position_name, (x1, y1, x2, y2))\n",
        "\n",
        "        # ✅ Step 2: Try shifting left and right\n",
        "        min_width = max(0.6 * frame_width, 600)\n",
        "        for shift_dir in [\"left\", \"right\"]:\n",
        "            attempts = 0\n",
        "            shift_value = shift_x\n",
        "            while attempts < 10:\n",
        "                if shift_dir == \"left\":\n",
        "                    new_x1 = max(0, x1 - shift_value)\n",
        "                    new_x2 = max(min_width, x2 - shift_value)\n",
        "                else:\n",
        "                    new_x1 = min(frame_width - min_width, x1 + shift_value)\n",
        "                    new_x2 = min(frame_width, x2 + shift_value)\n",
        "\n",
        "                shifted_zone = (new_x1, y1, new_x2, y2)\n",
        "                if new_x2 > new_x1 and not any(zones_overlap(shifted_zone, detection[:4]) for detection in detections):\n",
        "                    shifted_name = f\"shifted_{position_name}\"\n",
        "                    used_safe_zones[shifted_name] = {\n",
        "                        \"coordinates\": [new_x1, y1, new_x2, y2]\n",
        "                    }\n",
        "                    return (shifted_name, shifted_zone)\n",
        "\n",
        "                shift_value *= 1.5\n",
        "                attempts += 1\n",
        "\n",
        "    # ✅ Step 3: Try Cached Safe Zone (if exists)\n",
        "    cache_key = (frame_width, frame_height, tuple(tuple(d) for d in detections))\n",
        "    if cache_key in safe_zone_cache:\n",
        "        return safe_zone_cache[cache_key]\n",
        "\n",
        "    # ✅ Step 4: Dynamic fallback position (bottom-up shifting)\n",
        "    fallback_position_name = \"dynamic_position\"\n",
        "    proposed = (0, frame_height - subtitle_height - margin, frame_width, frame_height - margin)\n",
        "    while True:\n",
        "        if all(not zones_overlap(proposed, detection[:4]) for detection in detections):\n",
        "            safe_zone_cache[cache_key] = (fallback_position_name, proposed)\n",
        "            used_safe_zones[fallback_position_name] = {\n",
        "                \"coordinates\": list(proposed)\n",
        "            }\n",
        "            return (fallback_position_name, proposed)\n",
        "\n",
        "        # Shift upwards\n",
        "        x1, y1, x2, y2 = proposed\n",
        "\n",
        "        new_y1 = y1 - subtitle_height - margin\n",
        "        new_y2 = y2 - subtitle_height - margin\n",
        "\n",
        "        if new_y1 < 0:\n",
        "            break\n",
        "        proposed = (x1, new_y1, x2, new_y2)\n",
        "\n",
        "    # ✅ Step 5: Final Fallback to Top\n",
        "    fallback_position_name = \"fallback_top\"\n",
        "    final_safe_zone = (0, margin, frame_width, subtitle_height + margin)\n",
        "    safe_zone_cache[cache_key] = (fallback_position_name, final_safe_zone)\n",
        "    used_safe_zones[fallback_position_name] = {\n",
        "        \"coordinates\": list(final_safe_zone)\n",
        "    }\n",
        "    return (fallback_position_name, final_safe_zone)\n",
        "\n",
        "def get_used_safe_zones():\n",
        "    \"\"\"\n",
        "    Returns the used safe zones as a dictionary without the \"priority\" field.\n",
        "    This can be directly used for updating the TTML layout.\n",
        "    \"\"\"\n",
        "    return {\n",
        "        key: {\"coordinates\": value[\"coordinates\"]}\n",
        "        for key, value in used_safe_zones.items()\n",
        "    }"
      ],
      "metadata": {
        "id": "RaWDhrEmYXq5"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42kgNBk0Qgif"
      },
      "source": [
        "### Subtitle size and margin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "8mVacuTdQgif"
      },
      "outputs": [],
      "source": [
        "def get_subtitle_size(frame_height):\n",
        "    \"\"\"\n",
        "    Dynamically calculate subtitle height and margin based on frame resolution.\n",
        "\n",
        "    Parameters:\n",
        "        frame_height (int): Height of the video frame.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (subtitle_height, margin)\n",
        "    \"\"\"\n",
        "    subtitle_height = max(0.15 * frame_height, 30)  # Minimum 18px for readability\n",
        "    margin = max(0.02 * frame_height, 5)  # Minimum 5px to avoid text touching edges\n",
        "\n",
        "    return int(subtitle_height), int(margin)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7LgkgGkQgij"
      },
      "source": [
        "### Complete Pipeline for frames batch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def get_pixel_pre_positions_from_json(json_path, frame_width, frame_height):\n",
        "    \"\"\"\n",
        "    Reads percentage-based layout from a JSON file and converts to pixel coordinates.\n",
        "\n",
        "    Args:\n",
        "        json_path (str): Path to the JSON file containing percentages.\n",
        "        frame_width (int): Width of the video frame.\n",
        "        frame_height (int): Height of the video frame.\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary of region names mapped to pixel coordinates and priority.\n",
        "    \"\"\"\n",
        "    with open(json_path, 'r') as f:\n",
        "        percentage_data = json.load(f)\n",
        "\n",
        "    pixel_positions = {}\n",
        "    for region, data in percentage_data.items():\n",
        "        x1_pct, y1_pct, x2_pct, y2_pct = data[\"percentages\"]\n",
        "        pixel_positions[region] = {\n",
        "            \"coordinates\": [\n",
        "                int(x1_pct * frame_width),\n",
        "                int(y1_pct * frame_height),\n",
        "                int(x2_pct * frame_width),\n",
        "                int(y2_pct * frame_height)\n",
        "            ],\n",
        "            \"priority\": data[\"priority\"]\n",
        "        }\n",
        "\n",
        "    return pixel_positions"
      ],
      "metadata": {
        "id": "hLl2SRmwqJNC"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from collections import Counter, deque\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "safe_zone_history = deque(maxlen=4)  # Stores past safe zones for consistency (4)\n",
        "region_json_path = \"/content/optimal_subtitle_copied/news_video_subtitle_positions.json\"\n",
        "\n",
        "def process_frames_batch_3fps_processed(frames, process_fps=3, video_fps=30):\n",
        "    \"\"\"\n",
        "    Process a batch of frames at 3 FPS:\n",
        "    - Detects objects in frames sampled at 3 FPS\n",
        "    - Computes one safe zone for the batch\n",
        "    - Overlays subtitles using the same safe zone\n",
        "\n",
        "    Parameters:\n",
        "        frames (list): List of frames (NumPy arrays).\n",
        "        subtitles (list): List of subtitles corresponding to each frame.\n",
        "        video_fps (int): Original FPS of the video.\n",
        "        process_fps (int): FPS at which YOLO will run.\n",
        "\n",
        "    Returns:\n",
        "        list: Processed frames with subtitles.\n",
        "    \"\"\"\n",
        "\n",
        "    # ✅ Step 1: Select Frames at 3 FPS for YOLO Detection\n",
        "    frame_interval = video_fps // process_fps  # Process every `frame_interval` frames\n",
        "    selected_indices = list(range(0, len(frames), frame_interval))\n",
        "\n",
        "    if not selected_indices:  # Prevent empty selection\n",
        "        selected_indices = [0]  # Process at least one frame\n",
        "\n",
        "    selected_frames = [frames[i] for i in selected_indices]  # Sampled frames for YOLO\n",
        "\n",
        "    # ✅ Step 2: Batch Object Detection on Selected Frames\n",
        "    batch_detections = detect_objects(selected_frames)  # YOLO runs only on sampled frames\n",
        "    frame_height, frame_width = frames[0].shape[:2]\n",
        "    # print(frame_height, frame_width)\n",
        "\n",
        "    pre_positions = get_pixel_pre_positions_from_json(region_json_path, frame_width, frame_height)\n",
        "\n",
        "    # # ✅ Load Predefined Safe Zones (JSON file loaded once)\n",
        "    # with open(\"/content/optimal_subtitle_copied/news_video_subtitle_positions.json\", \"r\") as file:\n",
        "    #     pre_positions = json.load(file).get(f\"{frame_width}x{frame_height}\", {})\n",
        "\n",
        "    # ✅ Step 3: Compute Safe Zone for Each Sampled Frame\n",
        "    subtitle_height, margin = get_subtitle_size(frame_height)\n",
        "\n",
        "    # ✅ Step 3: Collect Safe Zone Positions for Each Frame in Batch\n",
        "    batch_safe_zones = [\n",
        "        calculate_safe_zone_with_prepositions_test_new(\n",
        "        #  calculate_safe_zone_with_prepositions_numpy(\n",
        "            frame_width, frame_height, batch_detections[i], pre_positions, subtitle_height, margin\n",
        "        )[0]  # ✅ Extract only the position name\n",
        "        for i in range(len(selected_frames))\n",
        "    ]\n",
        "\n",
        "    # ✅ Step 4: Determine the Most Used Safe Zone\n",
        "    combined_safe_zones = batch_safe_zones + list(safe_zone_history)  # Merge with history\n",
        "    # combined_safe_zones = batch_safe_zones\n",
        "    # print(f\"✅ Combined Safe Zones: {combined_safe_zones}\")\n",
        "    print(combined_safe_zones)\n",
        "    zone_counts = Counter(combined_safe_zones)  # Count occurrences\n",
        "    # zone_counts = Counter(batch_safe_zones)\n",
        "\n",
        "    # ✅ Assign the most frequently used zone\n",
        "    if zone_counts:\n",
        "        most_common_zones = zone_counts.most_common()  # Get all zones sorted by frequency\n",
        "        highest_frequency = most_common_zones[0][1]  # Find the highest occurrence count\n",
        "\n",
        "        # ✅ Get all zones with the highest frequency\n",
        "        top_zones = [zone for zone, count in most_common_zones if count == highest_frequency]\n",
        "\n",
        "        # ✅ If there's a tie, choose the last used zone from combined_safe_zones\n",
        "        final_safe_zone = next((zone for zone in reversed(combined_safe_zones) if zone in top_zones), \"bottom\")\n",
        "    else:\n",
        "        final_safe_zone = \"bottom\"  # ✅ Default fallback\n",
        "    # print(f\"✅ Final Safe Zone: {final_safe_zone}\")\n",
        "\n",
        "\n",
        "    # ✅ Store the final safe zone for future frames\n",
        "    safe_zone_history.append(final_safe_zone)\n",
        "\n",
        "    return final_safe_zone"
      ],
      "metadata": {
        "id": "FAPdtoMltqAT"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from collections import Counter, deque\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "safe_zone_history = deque(maxlen=2)\n",
        "region_json_path = \"/content/optimal_subtitle_copied/news_video_subtitle_positions.json\"\n",
        "\n",
        "def process_frames_batch_3fps_processed_test(frames, process_fps=3, video_fps=30):\n",
        "    frame_interval = video_fps // process_fps\n",
        "    selected_indices = list(range(0, len(frames), frame_interval))\n",
        "    if not selected_indices:\n",
        "        selected_indices = [0]\n",
        "    selected_frames = [frames[i] for i in selected_indices]\n",
        "\n",
        "    batch_detections = detect_objects(selected_frames)\n",
        "    frame_height, frame_width = frames[0].shape[:2]\n",
        "    pre_positions = get_pixel_pre_positions_from_json(region_json_path, frame_width, frame_height)\n",
        "    subtitle_height, margin = get_subtitle_size(frame_height)\n",
        "\n",
        "    batch_safe_zones = [\n",
        "        calculate_safe_zone_with_prepositions_test_new(\n",
        "            frame_width, frame_height, batch_detections[i], pre_positions, subtitle_height, margin\n",
        "        )[0]\n",
        "        for i in range(len(selected_frames))\n",
        "    ]\n",
        "    print(batch_safe_zones)\n",
        "\n",
        "    # ✅ Detect sudden change in safe zones\n",
        "    if len(set(batch_safe_zones)) > 1:\n",
        "        final_safe_zone = batch_safe_zones[-1]  # Use most recent zone\n",
        "    else:\n",
        "        final_safe_zone = batch_safe_zones[0]  # All zones consistent\n",
        "\n",
        "    safe_zone_history.append(final_safe_zone)\n",
        "    return final_safe_zone"
      ],
      "metadata": {
        "id": "oe6vevL-qK36"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "def print_ttml_with_updated_regions(ttml_file_path, subtitle_data):\n",
        "    \"\"\"\n",
        "    Prints the TTML <p> elements with updated regions, removing 'region' if it's None.\n",
        "\n",
        "    Parameters:\n",
        "        ttml_file_path (str): Path to the TTML file.\n",
        "        subtitle_data (list): List of subtitles in the format:\n",
        "            [{\"start\": start_time, \"end\": end_time, \"text\": text, \"region\": \"region_id\"}]\n",
        "    \"\"\"\n",
        "\n",
        "    # ✅ Load TTML File\n",
        "    tree = ET.parse(ttml_file_path)\n",
        "    root = tree.getroot()\n",
        "    ns = {'ttml': 'http://www.w3.org/ns/ttml'}\n",
        "\n",
        "    # ✅ Find All <p> Elements (Subtitles) and Update Regions\n",
        "    for p in root.findall('.//ttml:p', ns):\n",
        "        start_time = convert_ttml_time_to_seconds(p.attrib.get(\"begin\", \"0.0s\"))\n",
        "        end_time = convert_ttml_time_to_seconds(p.attrib.get(\"end\", \"0.0s\"))\n",
        "\n",
        "        # ✅ Find Matching Subtitle\n",
        "        matched_subtitle = next((sub for sub in subtitle_data if sub[\"start\"] <= start_time <= sub[\"end\"]), None)\n",
        "\n",
        "        if matched_subtitle:\n",
        "            if matched_subtitle[\"region\"] is not None:\n",
        "                p.attrib[\"region\"] = matched_subtitle[\"region\"]  # ✅ Assign Correct Region\n",
        "            elif \"region\" in p.attrib:\n",
        "                del p.attrib[\"region\"]  # ✅ Remove `region` if it's None\n",
        "\n",
        "    # ✅ Print Updated TTML Content\n",
        "    updated_ttml = ET.tostring(root, encoding=\"utf-8\").decode(\"utf-8\")\n",
        "    print(updated_ttml)  # ✅ Print instead of writing to a file"
      ],
      "metadata": {
        "id": "gqHAFmFGkCY1"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import json\n",
        "import math\n",
        "\n",
        "def generate_updated_ttml(ttml_file_path, output_ttml_path, json_data, subtitle_data, frame_width, frame_height):\n",
        "    \"\"\"\n",
        "    Generates a new TTML file with updated subtitle styles, layout regions, and assigned regions for subtitles.\n",
        "\n",
        "    Parameters:\n",
        "        ttml_file_path (str): Path to the input TTML file.\n",
        "        output_ttml_path (str): Path to save the updated TTML file.\n",
        "        json_data (dict): JSON data containing subtitle positions.\n",
        "        subtitle_data (list): List of subtitles with timestamps and regions.\n",
        "        frame_width (int): Width of the video frame.\n",
        "        frame_height (int): Height of the video frame.\n",
        "\n",
        "    Returns:\n",
        "        None (Writes updated TTML file to disk)\n",
        "    \"\"\"\n",
        "\n",
        "    # ✅ Load TTML File\n",
        "    tree = ET.parse(ttml_file_path)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    # # ✅ Define Namespace for TTML\n",
        "    # ns = {'ttml': 'http://www.w3.org/ns/ttml'}\n",
        "    # ET.register_namespace(\"\", ns[\"ttml\"])\n",
        "\n",
        "    # # ✅ Find or Create the <head> Element\n",
        "    # head_element = root.find('.//ttml:head', ns)\n",
        "    # if head_element is None:\n",
        "    #     head_element = ET.Element(\"{http://www.w3.org/ns/ttml}head\")\n",
        "    #     root.insert(0, head_element)  # Insert <head> at the top\n",
        "\n",
        "    # ✅ Load TTML File\n",
        "    tree = ET.parse(ttml_file_path)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    # ✅ Preserve All Original Root Attributes (Ensuring All Namespaces Remain)\n",
        "    root_attribs = root.attrib.copy()  # Copy attributes before modification\n",
        "\n",
        "    # ✅ Extract Namespace (from <tt> root tag)\n",
        "    namespace_uri = root.tag.split(\"}\")[0].strip(\"{\")  # Extracts URI from \"{namespace}tag\"\n",
        "    ns = {\"ttml\": namespace_uri} if namespace_uri else {}\n",
        "\n",
        "    # ✅ Restore All Root Attributes (Explicitly Add Missing Namespaces)\n",
        "    root.attrib.clear()\n",
        "    root.attrib.update(root_attribs)  # ✅ Restore original attributes\n",
        "\n",
        "    # ✅ Ensure `xmlns:tts` is Explicitly Set (if missing)\n",
        "    if \"xmlns:tts\" not in root.attrib:\n",
        "        root.set(\"xmlns:tts\", \"http://www.w3.org/ns/ttml#styling\")  # ✅ Add missing styling namespace\n",
        "\n",
        "    # ✅ Find or Create the <head> Element (Using Preserved Namespace)\n",
        "    head_element = root.find(f'.//{{{namespace_uri}}}head', ns)\n",
        "    if head_element is None:\n",
        "        head_element = ET.Element(f\"{{{namespace_uri}}}head\")\n",
        "        root.insert(0, head_element)  # Insert <head> as the first child\n",
        "\n",
        "    # ✅ Find or Create the <styling> Element\n",
        "    styling_element = head_element.find('.//ttml:styling', ns)\n",
        "    if styling_element is None:\n",
        "        styling_element = ET.Element(\"{http://www.w3.org/ns/ttml}styling\")\n",
        "        head_element.insert(0, styling_element)  # Insert before layout\n",
        "\n",
        "    # ✅ Remove Any Existing <style> Elements (Always Replacing)\n",
        "    for style in styling_element.findall('.//ttml:style', ns):\n",
        "        styling_element.remove(style)\n",
        "\n",
        "    # ✅ Define and Add the New Style Element\n",
        "    new_style = ET.Element(\"{http://www.w3.org/ns/ttml}style\", attrib={\n",
        "        \"xml:id\": \"s0\",\n",
        "        \"tts:color\": \"white\",\n",
        "        \"tts:fontSize\": \"70%\",\n",
        "        \"tts:fontFamily\": \"sansSerif\",\n",
        "        \"tts:backgroundColor\": \"black\",\n",
        "        \"tts:displayAlign\": \"center\",\n",
        "        \"tts:wrapOption\": \"wrap\"\n",
        "    })\n",
        "    styling_element.append(new_style)\n",
        "\n",
        "    # ✅ Find or Create the <layout> Element\n",
        "    layout_element = head_element.find('.//ttml:layout', ns)\n",
        "    if layout_element is None:\n",
        "        layout_element = ET.Element(\"{http://www.w3.org/ns/ttml}layout\")\n",
        "        head_element.append(layout_element)\n",
        "\n",
        "    # ✅ Remove ALL existing <region> elements inside <layout>\n",
        "    for region in list(layout_element):\n",
        "        layout_element.remove(region)\n",
        "\n",
        "    # ✅ Insert Subtitle Regions from JSON\n",
        "    for region_name, region_data in json_data.items():\n",
        "        x1, y1, x2, y2 = region_data[\"coordinates\"]\n",
        "\n",
        "        print(frame_height,frame_width)\n",
        "\n",
        "        # Convert absolute pixel values to TTML percentages\n",
        "        origin_x = (x1 / frame_width) * 100\n",
        "        origin_y = (y1 / frame_height) * 100\n",
        "        extent_x = ((x2 - x1) / frame_width) * 100\n",
        "        extent_y = ((y2 - y1) / frame_height) * 100\n",
        "\n",
        "        # Construct the region XML element\n",
        "        region_element = ET.Element(\"{http://www.w3.org/ns/ttml}region\", attrib={\n",
        "            \"tts:origin\": f\"{math.ceil(origin_x)}% {math.ceil(origin_y)}%\",\n",
        "            \"tts:extent\": f\"{math.ceil(extent_x)}% {math.ceil(extent_y)}%\",\n",
        "            \"tts:displayAlign\": \"center\",\n",
        "            \"tts:textAlign\": \"center\",\n",
        "            \"xml:id\": region_name\n",
        "        })\n",
        "\n",
        "        # Add to <layout>\n",
        "        layout_element.append(region_element)\n",
        "\n",
        "    # ✅ Find All <p> Elements (Subtitles) and Update Regions\n",
        "    for p in root.findall('.//ttml:p', ns):\n",
        "        start_time = convert_ttml_time_to_seconds(p.attrib.get(\"begin\", \"0.0s\"))\n",
        "        end_time = convert_ttml_time_to_seconds(p.attrib.get(\"end\", \"0.0s\"))\n",
        "\n",
        "        # ✅ Find Matching Subtitle\n",
        "        matched_subtitle = next((sub for sub in subtitle_data if sub[\"start\"] <= start_time <= sub[\"end\"]), None)\n",
        "\n",
        "        if matched_subtitle:\n",
        "            if matched_subtitle[\"region\"] is not None:\n",
        "                p.attrib[\"region\"] = matched_subtitle[\"region\"]  # ✅ Assign Correct Region\n",
        "            elif \"region\" in p.attrib:\n",
        "                del p.attrib[\"region\"]  # ✅ Remove `region` if it's None\n",
        "\n",
        "    # ✅ Save Updated TTML File\n",
        "    # tree.write(output_ttml_path, encoding=\"utf-8\", xml_declaration=True)\n",
        "    # print(f\"✅ Updated TTML file saved: {output_ttml_path}\")\n",
        "    updated_ttml = ET.tostring(root, encoding=\"utf-8\").decode(\"utf-8\")\n",
        "    print(updated_ttml)"
      ],
      "metadata": {
        "id": "f4hGUUJB-B_F"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDwa2goMQgik"
      },
      "source": [
        "## Testing the Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoWr2HYHQgik"
      },
      "source": [
        "### Integrate with srt file and video fps"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install pysrt"
      ],
      "metadata": {
        "id": "fc0SuEOLTtPo"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_subtitles_for_frames(frame_times, subtitle_data):\n",
        "    \"\"\"\n",
        "    Retrieves subtitle texts for a batch of frame timestamps.\n",
        "\n",
        "    Parameters:\n",
        "        frame_times (list): List of timestamps (in seconds).\n",
        "        subtitle_data (list): List of subtitles in the format:\n",
        "            [{\"start\": start_time, \"end\": end_time, \"text\": text, \"region\": region}, ...]\n",
        "\n",
        "    Returns:\n",
        "        list: List of subtitle texts corresponding to each frame timestamp.\n",
        "    \"\"\"\n",
        "    frame_subtitles = []\n",
        "\n",
        "    for time in frame_times:\n",
        "        subtitle_text = \"\"  # Default to empty string\n",
        "\n",
        "        for subtitle in subtitle_data:\n",
        "            if subtitle[\"start\"] <= time <= subtitle[\"end\"]:\n",
        "                subtitle_text = subtitle[\"text\"].replace(\"\\n\", \" \")  # Remove newlines\n",
        "                break  # Stop once we find a match\n",
        "\n",
        "        frame_subtitles.append(subtitle_text)\n",
        "\n",
        "    return frame_subtitles"
      ],
      "metadata": {
        "id": "g8EqZoCLY49C"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "\n",
        "def get_video_fps(video_path):\n",
        "    \"\"\"Extracts FPS from a video using FFmpeg.\"\"\"\n",
        "    cmd = [\"ffmpeg\", \"-i\", video_path]\n",
        "\n",
        "    # ✅ Use stdout and stderr explicitly\n",
        "    result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "\n",
        "    # ✅ Parse FPS from FFmpeg output\n",
        "    for line in result.stderr.split(\"\\n\"):\n",
        "        if \"Stream\" in line and \"Video\" in line and \"fps\" in line:\n",
        "            fps_value = float(line.split(\"fps\")[0].strip().split()[-1])  # Extract FPS\n",
        "            return fps_value\n",
        "\n",
        "    return 30  # Default to 30 FPS if not found"
      ],
      "metadata": {
        "id": "bDPjN9-7b5sS"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## combined srt and ttml timestamp\n",
        "\n",
        "import pysrt\n",
        "import xml.etree.ElementTree as ET\n",
        "import re\n",
        "\n",
        "def get_subtitle_timestamps(subtitle_file, file_type=\"auto\"):\n",
        "    \"\"\"\n",
        "    Extracts subtitle timestamps from an SRT or TTML file.\n",
        "\n",
        "    Parameters:\n",
        "        subtitle_file (str): Path to the subtitle file.\n",
        "        file_type (str): \"srt\" for SRT, \"ttml\" for TTML, or \"auto\" to detect from extension.\n",
        "\n",
        "    Returns:\n",
        "        list of tuples: Each tuple contains (start_time, end_time) in seconds.\n",
        "    \"\"\"\n",
        "    # Auto-detect file type\n",
        "    if file_type == \"auto\":\n",
        "        if subtitle_file.endswith(\".srt\"):\n",
        "            file_type = \"srt\"\n",
        "        elif subtitle_file.endswith(\".ttml\") or subtitle_file.endswith(\".xml\"):\n",
        "            file_type = \"ttml\"\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported subtitle file format. Use 'srt' or 'ttml'.\")\n",
        "\n",
        "    # Process SRT\n",
        "    if file_type == \"srt\":\n",
        "        return get_srt_timestamps(subtitle_file)\n",
        "\n",
        "    # Process TTML\n",
        "    elif file_type == \"ttml\":\n",
        "        return get_ttml_timestamps(subtitle_file)\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"Invalid file type specified. Use 'srt' or 'ttml'.\")\n",
        "\n",
        "def get_srt_timestamps(srt_file):\n",
        "    \"\"\"Extracts subtitle timestamps from an SRT file.\"\"\"\n",
        "    subs = pysrt.open(srt_file)\n",
        "    subtitle_timestamps = []\n",
        "\n",
        "    for sub in subs:\n",
        "        start_time = sub.start.hours * 3600 + sub.start.minutes * 60 + sub.start.seconds + sub.start.milliseconds / 1000\n",
        "        end_time = sub.end.hours * 3600 + sub.end.minutes * 60 + sub.end.seconds + sub.end.milliseconds / 1000\n",
        "        subtitle_timestamps.append((start_time, end_time))\n",
        "\n",
        "    return subtitle_timestamps\n",
        "\n",
        "def get_ttml_timestamps(ttml_file):\n",
        "    \"\"\"Extracts subtitle timestamps from a TTML file.\"\"\"\n",
        "    tree = ET.parse(ttml_file)\n",
        "    root = tree.getroot()\n",
        "    ns = {'ttml': 'http://www.w3.org/ns/ttml'}\n",
        "\n",
        "    subtitle_timestamps = []\n",
        "\n",
        "    for p in root.findall('.//ttml:p', ns):\n",
        "        start_time = p.attrib.get(\"begin\", \"0.0s\")\n",
        "        end_time = p.attrib.get(\"end\", \"0.0s\")\n",
        "\n",
        "        start_seconds = convert_ttml_time_to_seconds(start_time)\n",
        "        end_seconds = convert_ttml_time_to_seconds(end_time)\n",
        "\n",
        "        subtitle_timestamps.append((start_seconds, end_seconds))\n",
        "\n",
        "    return subtitle_timestamps\n",
        "\n",
        "# def convert_ttml_time_to_seconds(ttml_time):\n",
        "#     \"\"\"\n",
        "#     Converts TTML time format (HH:MM:SS.mmm or MM:SS.mmm or SS.mmm or SS.mmm's') to seconds.\n",
        "\n",
        "#     Parameters:\n",
        "#         ttml_time (str): TTML-formatted time.\n",
        "\n",
        "#     Returns:\n",
        "#         float: Time in seconds.\n",
        "#     \"\"\"\n",
        "#     ttml_time = ttml_time.rstrip('s')  # Remove trailing 's' if present\n",
        "#     parts = ttml_time.split(\":\")\n",
        "\n",
        "#     if len(parts) == 3:  # HH:MM:SS.mmm\n",
        "#         hours, minutes, seconds = map(float, parts)\n",
        "#     elif len(parts) == 2:  # MM:SS.mmm\n",
        "#         hours, minutes, seconds = 0, *map(float, parts)\n",
        "#     else:  # SS.mmm\n",
        "#         hours, minutes, seconds = 0, 0, float(parts[0])\n",
        "\n",
        "#     return hours * 3600 + minutes * 60 + seconds\n",
        "\n",
        "def convert_ttml_time_to_seconds(ttml_time):\n",
        "    \"\"\"\n",
        "    Converts TTML time format (HH:MM:SS.mmm, MM:SS.mmm, SS.mmm, or SS,mmm) to seconds.\n",
        "\n",
        "    Parameters:\n",
        "        ttml_time (str): TTML-formatted time.\n",
        "\n",
        "    Returns:\n",
        "        float: Time in seconds (with millisecond precision).\n",
        "    \"\"\"\n",
        "\n",
        "    # ✅ Remove trailing 's' if present and replace ',' with '.'\n",
        "    ttml_time = ttml_time.rstrip('s').replace(',', '.')\n",
        "\n",
        "    # ✅ Use regex to extract time components\n",
        "    match = re.match(r\"(?:(\\d+):)?(?:(\\d+):)?(\\d+)(?:\\.(\\d+))?\", ttml_time)\n",
        "\n",
        "    if not match:\n",
        "        raise ValueError(f\"Invalid TTML time format: {ttml_time}\")\n",
        "\n",
        "    # ✅ Extract components safely\n",
        "    hours = int(match.group(1)) if match.group(1) else 0\n",
        "    minutes = int(match.group(2)) if match.group(2) else 0\n",
        "    seconds = int(match.group(3)) if match.group(3) else 0\n",
        "    milliseconds = int(match.group(4)) if match.group(4) else 0\n",
        "\n",
        "    return hours * 3600 + minutes * 60 + seconds + milliseconds / 1000.0"
      ],
      "metadata": {
        "id": "bUdSYW-RZTx4"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xml.etree.ElementTree as ET\n",
        "import pysrt\n",
        "import os\n",
        "\n",
        "def parse_subtitle_file(file_path):\n",
        "    \"\"\"\n",
        "    Parses either an SRT or TTML subtitle file and extracts subtitles.\n",
        "\n",
        "    Parameters:\n",
        "        file_path (str): Path to the subtitle file.\n",
        "\n",
        "    Returns:\n",
        "        list: List of subtitles in the format:\n",
        "            [\n",
        "                {\"start\": start_time, \"end\": end_time, \"text\": \"subtitle text\", \"region\": \"region_id\"}\n",
        "            ]\n",
        "    \"\"\"\n",
        "    extension = os.path.splitext(file_path)[-1].lower()\n",
        "    subtitle_data = []\n",
        "\n",
        "    if extension == \".srt\":\n",
        "        subs = pysrt.open(file_path)\n",
        "        for sub in subs:\n",
        "            start_time = (\n",
        "                sub.start.hours * 3600 + sub.start.minutes * 60 + sub.start.seconds + sub.start.milliseconds / 1000\n",
        "            )\n",
        "            end_time = (\n",
        "                sub.end.hours * 3600 + sub.end.minutes * 60 + sub.end.seconds + sub.end.milliseconds / 1000\n",
        "            )\n",
        "            text = sub.text.replace(\"\\n\", \" \")  # Convert newlines to spaces\n",
        "\n",
        "            subtitle_data.append({\n",
        "                \"start\": start_time,\n",
        "                \"end\": end_time,\n",
        "                \"text\": text,\n",
        "                \"region\": None  # SRT doesn't support regions\n",
        "            })\n",
        "\n",
        "    elif extension == \".ttml\":\n",
        "        # ✅ Register TTML Namespaces\n",
        "        ET.register_namespace('', \"http://www.w3.org/ns/ttml\")  # Default TTML namespace\n",
        "        ET.register_namespace('ttp', \"http://www.w3.org/ns/ttml#parameter\")\n",
        "        ET.register_namespace('tts', \"http://www.w3.org/ns/ttml#styling\")\n",
        "        ET.register_namespace('ttm', \"http://www.w3.org/ns/ttml#metadata\")\n",
        "\n",
        "        # ✅ Parse TTML File\n",
        "        tree = ET.parse(file_path)\n",
        "        root = tree.getroot()\n",
        "        ns = {'ttml': 'http://www.w3.org/ns/ttml'}\n",
        "\n",
        "        # ✅ Extract Subtitle Data\n",
        "        for p in root.findall('.//ttml:p', ns):\n",
        "            start_time = convert_ttml_time_to_seconds(p.attrib.get(\"begin\", \"0.0s\"))\n",
        "            end_time = convert_ttml_time_to_seconds(p.attrib.get(\"end\", \"0.0s\"))\n",
        "            text = \" \".join(p.itertext()).strip()\n",
        "            region = p.attrib.get(\"region\", None)\n",
        "\n",
        "            subtitle_data.append({\n",
        "                \"start\": start_time,\n",
        "                \"end\": end_time,\n",
        "                \"text\": text,\n",
        "                \"region\": region\n",
        "            })\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported subtitle format. Only SRT and TTML are supported.\")\n",
        "\n",
        "    return subtitle_data"
      ],
      "metadata": {
        "id": "GgMktVeZcXhH"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import time\n",
        "\n",
        "# ✅ Optional Resize Parameter (None = no resize)\n",
        "# resize_resolution = (640, 360)  # Example: downscale to 640x360; set to None to disable resizing\n",
        "# resize_resolution = (1280, 720)\n",
        "# resize_resolution = (854, 480)\n",
        "resize_resolution = None\n",
        "\n",
        "# ✅ Start Load Timer\n",
        "start_load_time = time.time()\n",
        "\n",
        "# ✅ Define file paths\n",
        "video_input_path = \"/content/optimal_subtitle_copied/test_video_4.mp4\"\n",
        "file_path = \"/content/optimal_subtitle_copied/TTML_file/test_video_4_eng.ttml\"\n",
        "output_path = \"/content/output.ttml\"\n",
        "\n",
        "# ✅ Load Video Metadata\n",
        "fps = get_video_fps(video_input_path)\n",
        "print(f\"✅ Corrected FPS: {fps}\")\n",
        "\n",
        "subtitle_data = parse_subtitle_file(file_path)\n",
        "subtitle_timestamps = get_subtitle_timestamps(file_path)\n",
        "\n",
        "cap = cv2.VideoCapture(video_input_path)\n",
        "\n",
        "# ✅ Original Resolution for TTML generation\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "print(f\"🎞 Frame Dimensions: {frame_width}x{frame_height}\")\n",
        "\n",
        "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "video_duration = total_frames / fps\n",
        "\n",
        "# ✅ End Load Timer\n",
        "end_load_time = time.time()\n",
        "load_duration = end_load_time - start_load_time\n",
        "print(f\"📦 Total Load Time: {load_duration:.2f} seconds\")\n",
        "\n",
        "# ✅ Start Run Timer\n",
        "start_run_time = time.time()\n",
        "\n",
        "frame_buffer = []\n",
        "timestamp_buffer = []\n",
        "subtitle_index = 0\n",
        "frame_number = 0\n",
        "total_video_read_time = 0\n",
        "total_yolo_time = 0\n",
        "total_region_assign_time = 0\n",
        "\n",
        "while cap.isOpened():\n",
        "    read_start = time.time()\n",
        "    ret, frame = cap.read()\n",
        "    read_end = time.time()\n",
        "\n",
        "    total_video_read_time += (read_end - read_start)\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # ✅ Resize frame for faster processing\n",
        "    if resize_resolution:\n",
        "        frame = cv2.resize(frame, resize_resolution)\n",
        "        frame_width, frame_height = resize_resolution\n",
        "\n",
        "    frame_time = frame_number / fps\n",
        "\n",
        "    if subtitle_index < len(subtitle_data):\n",
        "        current_subtitle = subtitle_data[subtitle_index]\n",
        "        current_start = current_subtitle[\"start\"]\n",
        "        current_end = current_subtitle[\"end\"]\n",
        "\n",
        "        if current_start <= frame_time <= current_end:\n",
        "            frame_buffer.append(frame)\n",
        "            timestamp_buffer.append(frame_time)\n",
        "\n",
        "        if frame_time > current_end:\n",
        "            if frame_buffer:\n",
        "                subtitles = [current_subtitle]\n",
        "\n",
        "                detect_start = time.time()\n",
        "                processed_frames = process_frames_batch_3fps_processed_test(frame_buffer)\n",
        "                detect_end = time.time()\n",
        "                total_yolo_time += (detect_end - detect_start)\n",
        "\n",
        "                region_start = time.time()\n",
        "                current_subtitle[\"region\"] = processed_frames\n",
        "                region_end = time.time()\n",
        "                total_region_assign_time += (region_end - region_start)\n",
        "\n",
        "                frame_buffer.clear()\n",
        "                timestamp_buffer.clear()\n",
        "                subtitle_index += 1\n",
        "\n",
        "    frame_number += 1\n",
        "\n",
        "# ✅ Final batch\n",
        "if frame_buffer and subtitle_index < len(subtitle_data):\n",
        "    subtitles = [subtitle_data[subtitle_index]]\n",
        "    detect_start = time.time()\n",
        "    processed_frames = process_frames_batch_3fps_processed_test(frame_buffer)\n",
        "    detect_end = time.time()\n",
        "    total_yolo_time += (detect_end - detect_start)\n",
        "    subtitle_data[subtitle_index][\"region\"] = processed_frames\n",
        "\n",
        "cap.release()\n",
        "\n",
        "# ✅ End Run Timer\n",
        "end_run_time = time.time()\n",
        "run_duration = end_run_time - start_run_time\n",
        "run_minutes, run_seconds = divmod(run_duration, 60)\n",
        "\n",
        "# ✅ Generate TTML Layout using original resolution\n",
        "ttml_gen_start = time.time()\n",
        "layout = get_used_safe_zones()\n",
        "generate_updated_ttml(file_path, output_path, layout, subtitle_data, frame_width, frame_height)\n",
        "ttml_gen_end = time.time()\n",
        "ttml_generation_time = ttml_gen_end - ttml_gen_start\n",
        "\n",
        "minutes, seconds = divmod(video_duration, 60)\n",
        "\n",
        "# ✅ Final Timing Summary\n",
        "print(\"\\n📊 PROFILING SUMMARY\")\n",
        "print(f\"🎬 Video Duration: {int(minutes)}m {int(seconds)}s\")\n",
        "print(f\"📦 Load Time: {load_duration:.2f}s\")\n",
        "print(f\"🚀 Run Time: {int(run_minutes)}m {int(run_seconds)}s\")\n",
        "print(f\"📥 Video Read Time: {total_video_read_time:.2f}s\")\n",
        "print(f\"🔍 YOLO Detection Time: {total_yolo_time:.2f}s\")\n",
        "print(f\"📐 Region Assignment Time: {total_region_assign_time:.2f}s\")\n",
        "print(f\"📝 TTML Generation Time: {ttml_generation_time:.2f}s\")\n",
        "print(f\"✅ Output TTML saved to: {output_path}\")"
      ],
      "metadata": {
        "id": "U5l2J2rXkb4X",
        "outputId": "ac755ce6-e074-4c5f-f65a-b980a0b615bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Corrected FPS: 29.97\n",
            "🎞 Frame Dimensions: 1280x720\n",
            "📦 Total Load Time: 0.11 seconds\n",
            "108\n",
            "108\n",
            "108\n",
            "108\n",
            "108\n",
            "108\n",
            "108\n",
            "['between_m3_m2_1', 'between_m3_m2_1', 'between_m3_m2_1', 'between_m3_m2_1', 'between_m3_m2_1', 'between_m3_m2_1', 'between_m3_m2_1']\n",
            "108\n",
            "108\n",
            "108\n",
            "108\n",
            "108\n",
            "108\n",
            "108\n",
            "108\n",
            "108\n",
            "108\n",
            "108\n",
            "108\n",
            "['between_m3_m2_1', 'between_m3_m2_1', 'between_m3_m2_1', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3']\n",
            "108\n",
            "108\n",
            "108\n",
            "108\n",
            "108\n",
            "108\n",
            "108\n",
            "['middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3']\n",
            "108\n",
            "108\n",
            "108\n",
            "108\n",
            "108\n",
            "108\n",
            "108\n",
            "['middle3', 'middle3', 'between_m3_m2_1', 'middle3', 'between_m3_m2_1', 'between_m3_m2_1', 'between_m3_m2_1']\n",
            "108\n",
            "108\n",
            "108\n",
            "108\n",
            "108\n",
            "108\n",
            "108\n",
            "108\n",
            "108\n",
            "['between_m3_m2_1', 'between_m3_m2_1', 'between_m3_m2_1', 'between_m3_m2_1', 'between_m3_m2_1', 'between_m3_m2_1', 'between_m3_m2_1', 'shifted_between_m3_m2_1', 'shifted_between_m3_m2_1']\n",
            "108\n",
            "108\n",
            "108\n",
            "108\n",
            "108\n",
            "108\n",
            "108\n",
            "108\n",
            "108\n",
            "['shifted_between_m3_m2_1', 'shifted_between_m3_m2_1', 'shifted_between_m3_m2_1', 'shifted_between_m3_m2_1', 'shifted_between_m3_m2_1', 'shifted_between_m3_m2_1', 'shifted_between_m3_m2_1', 'shifted_between_m3_m2_1', 'shifted_between_m3_m2_1']\n",
            "108\n",
            "108\n",
            "108\n",
            "108\n",
            "108\n",
            "108\n",
            "['shifted_between_m3_m2_1', 'shifted_between_m3_m2_1', 'shifted_between_m3_m2_1', 'shifted_between_m3_m2_1', 'shifted_between_m3_m2_1', 'shifted_between_m3_m2_1']\n",
            "108\n",
            "108\n",
            "108\n",
            "['shifted_between_m3_m2_1', 'shifted_between_m3_m2_1', 'shifted_between_m3_m2_1']\n",
            "108\n",
            "108\n",
            "108\n",
            "108\n",
            "108\n",
            "108\n",
            "['shifted_between_m3_m2_1', 'shifted_between_m3_m2_1', 'shifted_between_m3_m2_1', 'shifted_between_m3_m2_1', 'shifted_between_m3_m2_1', 'between_m3_m2_1']\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-91-5479b315fa0b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0mdetect_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m                 \u001b[0mprocessed_frames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_frames_batch_3fps_processed_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m                 \u001b[0mdetect_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0mtotal_yolo_time\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdetect_end\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdetect_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-90-77940d74fb24>\u001b[0m in \u001b[0;36mprocess_frames_batch_3fps_processed_test\u001b[0;34m(frames, process_fps, video_fps)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mselected_frames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mselected_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mbatch_detections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected_frames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mframe_height\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mpre_positions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_pixel_pre_positions_from_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregion_json_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_height\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-55-12c1ebe27bfe>\u001b[0m in \u001b[0;36mdetect_objects\u001b[0;34m(frames)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \"\"\"\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# ✅ Run the model in batch mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgsz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m640\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Run batch inference 640\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m# ✅ Extract detections for each frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;34m...\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Detected {len(r)} objects in image\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \"\"\"\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprompts\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"set_prompts\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# for SAM-type models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_prompts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_cli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_cli\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m     def track(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# merge list of Result into one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_cli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mgenerator_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;31m# Issuing `None` to a generator fires it up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36mstream_inference\u001b[0;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m                 \u001b[0;31m# Preprocess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mprofilers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m                     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim0s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m                 \u001b[0;31m# Inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(self, im)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mnot_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnot_tensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m             \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m             \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# BGR to RGB, BHWC to BCHW, (n, 3, h, w)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mascontiguousarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# contiguous\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36mpre_transform\u001b[0;34m(self, im)\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         )\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mletterbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_imgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         )\n\u001b[0;32m--> 189\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mletterbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpostprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_imgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ultralytics/data/augment.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, labels, image)\u001b[0m\n\u001b[1;32m   1587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1588\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnew_unpad\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# resize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1589\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_unpad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINTER_LINEAR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1590\u001b[0m         \u001b[0mtop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbottom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdh\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcenter\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdh\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1591\u001b[0m         \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdw\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcenter\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdw\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## CV2\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "# ✅ Optional Resize Parameter for YOLO detection (None = no resize)\n",
        "resize_resolution = (854, 480)  # or None\n",
        "# resize_resolution = (640, 360)\n",
        "stream_fps = 5  # Optional frame skipping (not implemented in this script)\n",
        "\n",
        "# ✅ Define file paths\n",
        "video_input_path = \"/content/optimal_subtitle_copied/test_video_4.mp4\"\n",
        "file_path = \"/content/optimal_subtitle_copied/TTML_file/test_video_4_eng.ttml\"\n",
        "output_path = \"/content/output.ttml\"\n",
        "\n",
        "# ⏳ Load metadata\n",
        "start_load_time = time.time()\n",
        "fps = get_video_fps(video_input_path)\n",
        "subtitle_data = parse_subtitle_file(file_path)\n",
        "subtitle_timestamps = get_subtitle_timestamps(file_path)\n",
        "cap = cv2.VideoCapture(video_input_path)\n",
        "\n",
        "# ⏳ Get original resolution for TTML output\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "video_duration = total_frames / fps\n",
        "end_load_time = time.time()\n",
        "\n",
        "# ⏱ Profiling stats\n",
        "load_duration = end_load_time - start_load_time\n",
        "total_video_read_time = 0\n",
        "total_yolo_time = 0\n",
        "total_region_assign_time = 0\n",
        "\n",
        "print(f\"🎞 Frame Dimensions: {frame_width}x{frame_height}\")\n",
        "print(f\"📦 Total Load Time: {load_duration:.2f} seconds\")\n",
        "\n",
        "# ⏱ Start processing\n",
        "start_run_time = time.time()\n",
        "\n",
        "frame_buffer = []\n",
        "subtitle_index = 0\n",
        "frame_number = 0\n",
        "\n",
        "while cap.isOpened():\n",
        "    read_start = time.time()\n",
        "    ret, frame = cap.read()\n",
        "    read_end = time.time()\n",
        "    total_video_read_time += (read_end - read_start)\n",
        "\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # ✅ Resize frame only for YOLO, not TTML\n",
        "    detection_frame = cv2.resize(frame, resize_resolution) if resize_resolution else frame\n",
        "    frame_time = frame_number / fps\n",
        "\n",
        "    if subtitle_index < len(subtitle_data):\n",
        "        sub = subtitle_data[subtitle_index]\n",
        "        if sub[\"start\"] <= frame_time <= sub[\"end\"]:\n",
        "            frame_buffer.append(detection_frame)\n",
        "\n",
        "        if frame_time > sub[\"end\"]:\n",
        "            if frame_buffer:\n",
        "                detect_start = time.time()\n",
        "                region = process_frames_batch_3fps_processed_test(frame_buffer)\n",
        "                detect_end = time.time()\n",
        "                total_yolo_time += (detect_end - detect_start)\n",
        "\n",
        "                assign_start = time.time()\n",
        "                subtitle_data[subtitle_index][\"region\"] = region\n",
        "                assign_end = time.time()\n",
        "                total_region_assign_time += (assign_end - assign_start)\n",
        "\n",
        "            frame_buffer.clear()\n",
        "            subtitle_index += 1\n",
        "\n",
        "    frame_number += 1\n",
        "\n",
        "# ⏳ Final frame batch\n",
        "if frame_buffer and subtitle_index < len(subtitle_data):\n",
        "    detect_start = time.time()\n",
        "    region = process_frames_batch_3fps_processed_test(frame_buffer)\n",
        "    detect_end = time.time()\n",
        "    total_yolo_time += (detect_end - detect_start)\n",
        "    subtitle_data[subtitle_index][\"region\"] = region\n",
        "\n",
        "cap.release()\n",
        "end_run_time = time.time()\n",
        "\n",
        "# ✅ TTML Generation\n",
        "ttml_gen_start = time.time()\n",
        "layout = get_used_safe_zones()\n",
        "generate_updated_ttml(file_path, output_path, layout, subtitle_data, frame_width, frame_height)\n",
        "ttml_gen_end = time.time()\n",
        "ttml_generation_time = ttml_gen_end - ttml_gen_start\n",
        "\n",
        "# ✅ Summary\n",
        "run_minutes, run_seconds = divmod(end_run_time - start_run_time, 60)\n",
        "minutes, seconds = divmod(video_duration, 60)\n",
        "\n",
        "print(\"\\n📊 PROFILING SUMMARY\")\n",
        "print(f\"🎬 Video Duration: {int(minutes)}m {int(seconds)}s\")\n",
        "print(f\"📦 Load Time: {load_duration:.2f}s\")\n",
        "print(f\"🚀 Run Time: {int(run_minutes)}m {int(run_seconds)}s\")\n",
        "print(f\"📥 Video Read Time: {total_video_read_time:.2f}s\")\n",
        "print(f\"🔍 YOLO Detection Time: {total_yolo_time:.2f}s\")\n",
        "print(f\"📐 Region Assignment Time: {total_region_assign_time:.5f}s\")\n",
        "print(f\"📝 TTML Generation Time: {ttml_generation_time:.5f}s\")\n",
        "print(f\"✅ Output TTML saved to: {output_path}\")"
      ],
      "metadata": {
        "id": "Yu5KfTqZFjgJ",
        "outputId": "61ab9ffd-2768-42fe-81f8-bd977eaabc0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🎞 Frame Dimensions: 1280x720\n",
            "📦 Total Load Time: 0.11 seconds\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "['between_m3_m2_1', 'between_m3_m2_1', 'between_m3_m2_1', 'between_m3_m2_1', 'middle3', 'middle3', 'between_m3_m2_1']\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "['between_m3_m2_1', 'between_m3_m2_1', 'between_m3_m2_1', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3']\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "['middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3']\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "['middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'between_m3_m2_1', 'middle3']\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "['between_m3_m2_1', 'between_m3_m2_1', 'between_m3_m2_1', 'between_m3_m2_1', 'between_m3_m2_1', 'between_m3_m2_1', 'between_m3_m2_1', 'fallback_top', 'fallback_top']\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "['fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top']\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "['fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top']\n",
            "72\n",
            "72\n",
            "72\n",
            "['fallback_top', 'fallback_top', 'fallback_top']\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "['fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'middle3']\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "['between_m3_m2_1', 'between_m3_m2_1', 'middle3', 'between_m3_m2_1', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3']\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "['fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top']\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "['fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top']\n",
            "72\n",
            "72\n",
            "72\n",
            "['fallback_top', 'fallback_top', 'fallback_top']\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "['fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top']\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "['fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'dynamic_position']\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "['fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top']\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "['fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top']\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "72\n",
            "['fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3']\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-92-f4a593be33a3>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misOpened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mread_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0mread_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mtotal_video_read_time\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mread_end\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mread_start\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## ffmpeg\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import time\n",
        "import subprocess\n",
        "import numpy as np\n",
        "\n",
        "# ✅ Optional Resize and FPS Reduction Parameters\n",
        "resize_resolution = (854, 480)  # (width, height)\n",
        "stream_fps = 5\n",
        "\n",
        "# ✅ Define file paths\n",
        "video_input_path = \"/content/optimal_subtitle_copied/test_video_4.mp4\"\n",
        "file_path = \"/content/optimal_subtitle_copied/TTML_file/test_video_4_eng.ttml\"\n",
        "output_path = \"/content/output.ttml\"\n",
        "\n",
        "# ✅ Start Load Timer\n",
        "start_load_time = time.time()\n",
        "\n",
        "fps = get_video_fps(video_input_path)\n",
        "subtitle_data = parse_subtitle_file(file_path)\n",
        "subtitle_timestamps = get_subtitle_timestamps(file_path)\n",
        "\n",
        "# ✅ Get original resolution\n",
        "cap = cv2.VideoCapture(video_input_path)\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "video_duration = total_frames / fps\n",
        "cap.release()\n",
        "\n",
        "end_load_time = time.time()\n",
        "load_duration = end_load_time - start_load_time\n",
        "\n",
        "# ✅ Start FFmpeg Setup + Conversion Timer\n",
        "ffmpeg_setup_start = time.time()\n",
        "\n",
        "width, height = resize_resolution\n",
        "frame_size = width * height * 3\n",
        "ffmpeg_cmd = [\n",
        "    'ffmpeg',\n",
        "    '-i', video_input_path,\n",
        "    '-vf', f'fps={stream_fps},scale={width}:{height}',\n",
        "    '-f', 'rawvideo',\n",
        "    '-pix_fmt', 'bgr24',\n",
        "    '-loglevel', 'quiet',\n",
        "    '-'\n",
        "]\n",
        "pipe = subprocess.Popen(ffmpeg_cmd, stdout=subprocess.PIPE, bufsize=10**8)\n",
        "\n",
        "ffmpeg_conversion_start = time.time()  # ✅ Conversion begins (after setup)\n",
        "ffmpeg_setup_time = ffmpeg_conversion_start - ffmpeg_setup_start\n",
        "\n",
        "# ✅ Start Frame Processing Timer\n",
        "processing_start = time.time()\n",
        "\n",
        "frame_buffer = []\n",
        "subtitle_index = 0\n",
        "frame_number = 0\n",
        "frame_time = 0\n",
        "\n",
        "total_video_read_time = 0\n",
        "total_yolo_time = 0\n",
        "total_region_assign_time = 0\n",
        "\n",
        "while True:\n",
        "    read_start = time.time()\n",
        "    raw_frame = pipe.stdout.read(frame_size)\n",
        "    read_end = time.time()\n",
        "\n",
        "    total_video_read_time += (read_end - read_start)\n",
        "    if not raw_frame:\n",
        "        break\n",
        "\n",
        "    frame = np.frombuffer(raw_frame, dtype=np.uint8).reshape((height, width, 3))\n",
        "    frame_time = frame_number * (1 / stream_fps)\n",
        "    original_frame_index = int(frame_time * fps)\n",
        "    frame_time = original_frame_index / fps\n",
        "\n",
        "    if subtitle_index < len(subtitle_data):\n",
        "        current_subtitle = subtitle_data[subtitle_index]\n",
        "        current_start = current_subtitle[\"start\"]\n",
        "        current_end = current_subtitle[\"end\"]\n",
        "\n",
        "        if current_start <= frame_time <= current_end:\n",
        "            frame_buffer.append(frame)\n",
        "\n",
        "        if frame_time > current_end:\n",
        "            if frame_buffer:\n",
        "                detect_start = time.time()\n",
        "                processed_frames = process_frames_batch_3fps_processed_test(\n",
        "                    frame_buffer, process_fps=3, video_fps=stream_fps)\n",
        "                detect_end = time.time()\n",
        "                total_yolo_time += (detect_end - detect_start)\n",
        "\n",
        "                region_start = time.time()\n",
        "                current_subtitle[\"region\"] = processed_frames\n",
        "                region_end = time.time()\n",
        "                total_region_assign_time += (region_end - region_start)\n",
        "\n",
        "                frame_buffer.clear()\n",
        "                subtitle_index += 1\n",
        "            else:\n",
        "                subtitle_index += 1\n",
        "\n",
        "    frame_number += 1\n",
        "\n",
        "# ✅ Final batch\n",
        "if frame_buffer and subtitle_index < len(subtitle_data):\n",
        "    detect_start = time.time()\n",
        "    processed_frames = process_frames_batch_3fps_processed_test(frame_buffer, process_fps=3, video_fps=stream_fps)\n",
        "    detect_end = time.time()\n",
        "    total_yolo_time += (detect_end - detect_start)\n",
        "    subtitle_data[subtitle_index][\"region\"] = processed_frames\n",
        "\n",
        "pipe.stdout.close()\n",
        "pipe.wait()\n",
        "\n",
        "ffmpeg_conversion_end = time.time()\n",
        "ffmpeg_conversion_duration = ffmpeg_conversion_end - ffmpeg_conversion_start\n",
        "\n",
        "processing_end = time.time()\n",
        "processing_duration = processing_end - processing_start\n",
        "\n",
        "# ✅ TTML Generation\n",
        "ttml_gen_start = time.time()\n",
        "layout = get_used_safe_zones()\n",
        "generate_updated_ttml(file_path, output_path, layout, subtitle_data, width, height)\n",
        "ttml_gen_end = time.time()\n",
        "ttml_generation_time = ttml_gen_end - ttml_gen_start\n",
        "\n",
        "minutes, seconds = divmod(video_duration, 60)\n",
        "\n",
        "# ✅ Profiling Summary\n",
        "print(\"\\n📊 PROFILING SUMMARY\")\n",
        "print(f\"🎬 Video Duration: {int(minutes)}m {int(seconds)}s\")\n",
        "print(f\"📦 Load Time: {load_duration:.2f}s\")\n",
        "print(f\"⚙️ FFmpeg Setup Time: {ffmpeg_setup_time:.2f}s\")\n",
        "print(f\"🎞 FFmpeg Conversion Time: {ffmpeg_conversion_duration:.2f}s\")\n",
        "print(f\"🚀 Frame Processing Time: {processing_duration:.2f}s\")\n",
        "print(f\"📥 Video Read Time: {total_video_read_time:.2f}s\")\n",
        "print(f\"🔍 YOLO Detection Time: {total_yolo_time:.2f}s\")\n",
        "print(f\"📐 Region Assignment Time: {total_region_assign_time:.4f}s\")\n",
        "print(f\"📝 TTML Generation Time: {ttml_generation_time:.4f}s\")\n",
        "print(f\"✅ Output TTML saved to: {output_path}\")"
      ],
      "metadata": {
        "id": "__iWqomThZg-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 769
        },
        "outputId": "ed19303b-e9c5-4950-e5a7-6ce020b1abe7"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3']\n",
            "['middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3']\n",
            "['middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3']\n",
            "['middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3']\n",
            "['between_m3_m2_1', 'between_m3_m2_1', 'between_m3_m2_1', 'between_m3_m2_1', 'between_m3_m2_1', 'between_m3_m2_1', 'between_m3_m2_1', 'middle3', 'middle3', 'middle3', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top']\n",
            "['fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top']\n",
            "['fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top']\n",
            "['fallback_top', 'fallback_top', 'fallback_top', 'fallback_top']\n",
            "['fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'middle3', 'between_m3_m2_1']\n",
            "['middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'between_m3_m2_1', 'middle3', 'middle3']\n",
            "['fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top']\n",
            "['fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top']\n",
            "['fallback_top', 'fallback_top', 'fallback_top', 'fallback_top']\n",
            "['fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top']\n",
            "['fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'dynamic_position', 'fallback_top', 'fallback_top']\n",
            "['fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top']\n",
            "['fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top']\n",
            "['fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3']\n",
            "['middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3']\n",
            "['middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'between_m3_m2_1', 'middle3']\n",
            "['fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top']\n",
            "['fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top']\n",
            "['fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top']\n",
            "['fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top']\n",
            "['fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top']\n",
            "['middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'middle3', 'between_m3_m2_1', 'between_m3_m2_1', 'between_m3_m2_1', 'between_m3_m2_1', 'between_m3_m2_1']\n",
            "['between_m3_m2_1', 'between_m3_m2_1', 'between_m3_m2_1', 'between_m3_m2_1', 'between_m3_m2_1', 'between_m3_m2_1', 'between_m3_m2_1', 'between_m3_m2_1', 'between_m3_m2_1']\n",
            "['between_m3_m2_1', 'fallback_top', 'between_m3_m2_1', 'between_m3_m2_1', 'between_m3_m2_1', 'between_m3_m2_1', 'between_m3_m2_1', 'between_m3_m2_1', 'between_m3_m2_1']\n",
            "['between_m3_m2_1', 'between_m3_m2_1', 'between_m3_m2_1', 'between_m3_m2_1']\n",
            "['between_m3_m2_1', 'between_m3_m2_1', 'between_m3_m2_1', 'between_m3_m2_1', 'between_m3_m2_1', 'between_m3_m2_1', 'between_m3_m2_1', 'between_m3_m2_1', 'middle3', 'middle3', 'middle3', 'middle3', 'between_m3_m2_1', 'between_m3_m2_1', 'between_m3_m2_1', 'between_m3_m2_1', 'between_m3_m2_1', 'between_m3_m2_1', 'between_m3_m2_1', 'between_m3_m2_1', 'between_m3_m2_1', 'between_m3_m2_1', 'between_m3_m2_1', 'between_m3_m2_1', 'between_m3_m2_1']\n",
            "['between_m3_m2_1', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top', 'fallback_top']\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-4c831ad748ee>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0mread_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mraw_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m     \u001b[0mread_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/optimal_subtitle_copied.zip /content/optimal_subtitle_copied"
      ],
      "metadata": {
        "id": "V4Y53h3hjmuy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "664cfb69-ead3-475d-88a0-fe446b75e156"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/optimal_subtitle_copied/ (stored 0%)\n",
            "  adding: content/optimal_subtitle_copied/test_video_4.mp4 (deflated 1%)\n",
            "  adding: content/optimal_subtitle_copied/subtitle_pre_positions(updated).json (deflated 85%)\n",
            "  adding: content/optimal_subtitle_copied/subtitle_regions_scaled_test.json (deflated 48%)\n",
            "  adding: content/optimal_subtitle_copied/news_video_subtitle_positions.json (deflated 74%)\n",
            "  adding: content/optimal_subtitle_copied/CBS_news.mp4 (deflated 0%)\n",
            "  adding: content/optimal_subtitle_copied/best.pt (deflated 11%)\n",
            "  adding: content/optimal_subtitle_copied/test_video_2.mp4 (deflated 2%)\n",
            "  adding: content/optimal_subtitle_copied/test_video_3.mp4 (deflated 0%)\n",
            "  adding: content/optimal_subtitle_copied/TTML_file/ (stored 0%)\n",
            "  adding: content/optimal_subtitle_copied/TTML_file/test_long_video_17_eng.ttml (deflated 75%)\n",
            "  adding: content/optimal_subtitle_copied/TTML_file/NBC_news.ttml (deflated 74%)\n",
            "  adding: content/optimal_subtitle_copied/TTML_file/CBS_News.ttml (deflated 72%)\n",
            "  adding: content/optimal_subtitle_copied/TTML_file/test_long_video(48)_eng.ttml (deflated 72%)\n",
            "  adding: content/optimal_subtitle_copied/TTML_file/CNN_news.ttml (deflated 73%)\n",
            "  adding: content/optimal_subtitle_copied/TTML_file/Fox_news.ttml (deflated 72%)\n",
            "  adding: content/optimal_subtitle_copied/TTML_file/BBC_news.ttml (deflated 71%)\n",
            "  adding: content/optimal_subtitle_copied/TTML_file/test_video_3_eng.ttml (deflated 70%)\n",
            "  adding: content/optimal_subtitle_copied/TTML_file/ABC_News.ttml (deflated 72%)\n",
            "  adding: content/optimal_subtitle_copied/TTML_file/test_video_4_eng.ttml (deflated 70%)\n",
            "  adding: content/optimal_subtitle_copied/TTML_file/MSNBC_news.ttml (deflated 71%)\n",
            "  adding: content/optimal_subtitle_copied/MSNBC_news.mp4 (deflated 0%)\n",
            "  adding: content/optimal_subtitle_copied/requirements.txt (deflated 5%)\n",
            "  adding: content/optimal_subtitle_copied/best_100.pt (deflated 11%)\n",
            "  adding: content/optimal_subtitle_copied/subtitle_positions_updated.json (deflated 85%)\n",
            "  adding: content/optimal_subtitle_copied/optimal_subtitle_placement.py (deflated 72%)\n",
            "  adding: content/optimal_subtitle_copied/.ipynb_checkpoints/ (stored 0%)\n",
            "  adding: content/optimal_subtitle_copied/Fox_news.mp4 (deflated 1%)\n",
            "  adding: content/optimal_subtitle_copied/BBC.mp4 (deflated 1%)\n",
            "  adding: content/optimal_subtitle_copied/SRT_file/ (stored 0%)\n",
            "  adding: content/optimal_subtitle_copied/SRT_file/test_video_4_korea.srt (deflated 59%)\n",
            "  adding: content/optimal_subtitle_copied/SRT_file/test_video_4_thai.srt (deflated 72%)\n",
            "  adding: content/optimal_subtitle_copied/SRT_file/test_video_3_eng.srt (deflated 64%)\n",
            "  adding: content/optimal_subtitle_copied/SRT_file/test_video_4_hebrew.srt (deflated 65%)\n",
            "  adding: content/optimal_subtitle_copied/SRT_file/test_video_4_japan.srt (deflated 60%)\n",
            "  adding: content/optimal_subtitle_copied/SRT_file/test_video_4_arabic.srt (deflated 64%)\n",
            "  adding: content/optimal_subtitle_copied/SRT_file/test_long_video_17_eng.srt (deflated 70%)\n",
            "  adding: content/optimal_subtitle_copied/SRT_file/test_video_4_eng.srt (deflated 58%)\n",
            "  adding: content/optimal_subtitle_copied/SRT_file/test_video_4_chinese.srt (deflated 53%)\n",
            "  adding: content/optimal_subtitle_copied/CNA_news.mp4 (deflated 0%)\n",
            "  adding: content/optimal_subtitle_copied/test_video_1.mp4 (deflated 2%)\n",
            "  adding: content/optimal_subtitle_copied/ABC_News.mp4 (deflated 1%)\n",
            "  adding: content/optimal_subtitle_copied/Font/ (stored 0%)\n",
            "  adding: content/optimal_subtitle_copied/Font/GoNotoKurrent-Regular.ttf (deflated 50%)\n",
            "  adding: content/optimal_subtitle_copied/Font/OpenSans-Italic-VariableFont_wdth,wght.ttf (deflated 33%)\n",
            "  adding: content/optimal_subtitle_copied/Font/OpenSans-VariableFont_wdth,wght.ttf (deflated 35%)\n",
            "  adding: content/optimal_subtitle_copied/Font/NotoNaskhArabic-Regular.ttf (deflated 45%)\n",
            "  adding: content/optimal_subtitle_copied/Font/NotoSansCJK-Regular.ttc (deflated 20%)\n",
            "  adding: content/optimal_subtitle_copied/Font/DejaVuSans-Bold.ttf (deflated 50%)\n",
            "  adding: content/optimal_subtitle_copied/Font/NotoSans-Regular.ttf (deflated 42%)\n",
            "  adding: content/optimal_subtitle_copied/Font/NotoSansThai-Regular.ttf (deflated 50%)\n",
            "  adding: content/optimal_subtitle_copied/Font/NotoSansDevanagari-Regular.ttf (deflated 58%)\n",
            "  adding: content/optimal_subtitle_copied/subtitle_positions_ttml.json (deflated 94%)\n",
            "  adding: content/optimal_subtitle_copied/test_video_5.mp4 (deflated 0%)\n",
            "  adding: content/optimal_subtitle_copied/caption_placement_preposition.ipynb (deflated 96%)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "42kgNBk0Qgif"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}